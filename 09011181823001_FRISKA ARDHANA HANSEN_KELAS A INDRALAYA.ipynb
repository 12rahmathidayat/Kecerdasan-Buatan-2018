{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_vector(minmax):\n",
    "    vector = list()\n",
    "    for i in range(len(minmax)):\n",
    "        rand = minmax[i][0] + ((minmax[i][1] - minmax[i][0]) * random.random())\n",
    "        vector.append(rand)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(num_weights):\n",
    "    minmax = list()\n",
    "    for i in range(num_weights):\n",
    "        minmax.append([0, 0.5])\n",
    "    return random_vector(minmax)"
   ]
  },
  {
   "attachments": {
    "index.png": {
     "image/png": "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"
    },
    "oii.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Sigmoid Activation\n",
    "Activate\n",
    "\n",
    "An activation value is calculated by summing each input value times it's corresponding weight (plus a bias value)\n",
    "Transfer\n",
    "\n",
    "Runs the activation value through the log-sigmoid function to determine the neuron's output \n",
    "![index.png](attachment:index.png)\n",
    "Transfer Derivative\n",
    "\n",
    "Returns the derivative of the log-sigmoid function which is used in error calculation during back-propagation \n",
    "![oii.png](attachment:oii.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(weights, vector, bias=1.0):\n",
    "    # initialize sum with output's weight * bias\n",
    "    _sum = weights[-1] * bias\n",
    "    for i in range(len(vector)):\n",
    "        _sum += weights[i] * vector[i]\n",
    "    return _sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer(activation):\n",
    "    return 1.0 / (1.0 + math.exp(-activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Porpagation\n",
    "Inputs\n",
    "\n",
    "    network: Neural Network\n",
    "    vector: The problem set (does not include the solution)\n",
    "\n",
    "Process\n",
    "\n",
    "Forward propagation passes the vector (problem set) through each layer of the network and returns the overall output\n",
    "\n",
    "    Hidden Layers\n",
    "        Each Neuron \"activates\" the vector\n",
    "        The activation's value is then evaluated to produce an output\n",
    "\n",
    "    Output Layer\n",
    "        Collects the output from every neuron in the network\n",
    "        Neuron \"activates\" the collected outputs\n",
    "        Produces an overall output for the network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, vector):\n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        _input = None\n",
    "        \n",
    "        # Hidden Layers\n",
    "        if (i != (len(network) - 1)):\n",
    "            _input = vector\n",
    "            \n",
    "        # Output Layer\n",
    "        else:\n",
    "            hidden_layer_outputs = list()\n",
    "            previous_layer = network[i - 1]\n",
    "            for k in range(len(previous_layer)):\n",
    "                hidden_layer_outputs.append(previous_layer[k][\"output\"])\n",
    "            _input = hidden_layer_outputs\n",
    "        \n",
    "        # Activation and Output\n",
    "        for neuron in layer:\n",
    "            neuron[\"activation\"] = activate(neuron[\"weights\"], _input)\n",
    "            neuron[\"output\"] = transfer(neuron[\"activation\"])\n",
    "            \n",
    "    # Return the overall output\n",
    "    return network[-1][0][\"output\"] # Assumes one node for output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Propagation\n",
    "\n",
    "Backward propagation calculates the level error in each neuron's output\n",
    "Inputs\n",
    "\n",
    "    network: Neural Network\n",
    "    expected_output: Known solution to the problem\n",
    "\n",
    "Process\n",
    "\n",
    "    Output Layer\n",
    "        Calculate error for the network based on the known solution\n",
    "        Set \"delta\" to the error times the derivative of the log-sigmoid output\n",
    "    Hidden Layers\n",
    "        Looks at each neuron in the layer\n",
    "            Calculates the error attributed to that neuron based on how it effected the next layer of the network\n",
    "            Each neuron in the next layer's corresponding wheight and \"delta\" add to the error value\n",
    "            Set \"delta\" to the error times the derivative of the log-sigmoid output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagate_error(network, expected_output):\n",
    "    for i in range(len(network)):\n",
    "        index = len(network) - 1 - i\n",
    "        layer = network[index]\n",
    "        \n",
    "        # Output Layer\n",
    "        if (index == (len(network) - 1)):\n",
    "            neuron = layer[0] # assume one node in output layer\n",
    "            error = (expected_output - neuron[\"output\"])\n",
    "            neuron[\"delta\"] = error * transfer_derivative(neuron[\"output\"])\n",
    "            \n",
    "        # Hidden Layers\n",
    "        else:\n",
    "            next_layer = network[index + 1]\n",
    "            for j in range(len(layer)):\n",
    "                err_sum = 0.0\n",
    "                neuron = layer[j]\n",
    "                for next_neuron in next_layer:\n",
    "                    err_sum += next_neuron[\"weights\"][j] * next_neuron[\"delta\"]\n",
    "                neuron[\"delta\"] = err_sum * transfer_derivative(neuron[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error_derivatives_for_weights(network, vector):\n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        _input = None\n",
    "        \n",
    "        # Hidden Layers\n",
    "        if (i != (len(network) - 1)):\n",
    "            _input = vector\n",
    "            \n",
    "        # Output Layer\n",
    "        else:\n",
    "            hidden_layer_outputs = list()\n",
    "            previous_layer = network[i - 1]\n",
    "            for k in range(len(previous_layer)):\n",
    "                hidden_layer_outputs.append(previous_layer[k][\"output\"])\n",
    "            _input = hidden_layer_outputs\n",
    "            \n",
    "        # Calculate error derivative for weights\n",
    "        for neuron in layer:\n",
    "            signal = None\n",
    "            for k in range(len(_input)):\n",
    "                signal = _input[k]\n",
    "                neuron[\"deriv\"][k] += neuron[\"delta\"] * signal\n",
    "            # Bias's weight\n",
    "            neuron[\"deriv\"][-1] += neuron[\"delta\"] * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(network, learning_rate, mom=0.8):\n",
    "    for layer in network:\n",
    "        for neuron in layer:\n",
    "            for i in range(len(neuron[\"weights\"])):\n",
    "                delta = (learning_rate * neuron[\"deriv\"][i]) + (neuron[\"last_delta\"][i] * mom)\n",
    "                neuron[\"weights\"][i] += delta\n",
    "                neuron[\"last_delta\"][i] = delta\n",
    "                neuron[\"deriv\"][i] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(network, training_data, num_inputs, iterations, learning_rate, benchmark):\n",
    "    correct = 0\n",
    "    for epoch in range(iterations):\n",
    "        for pattern in training_data:\n",
    "            vector = list()\n",
    "            for k in range(num_inputs):\n",
    "                vector.append(float(pattern[k]))\n",
    "            expected = pattern[-1]\n",
    "            output = forward_propagate(network, vector)\n",
    "            if (round(output) == expected):\n",
    "                correct += 1\n",
    "            backward_propagate_error(network, expected)\n",
    "            calculate_error_derivatives_for_weights(network, vector)\n",
    "        update_weights(network, learning_rate)\n",
    "        \n",
    "        # Collect data throught iterations\n",
    "        if (((epoch + 1) % benchmark) == 0):\n",
    "            print(\"> epoch = \" + str(epoch+1) + \", Correct = \" + str(correct / (benchmark * len(training_data))))\n",
    "            correct = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(network, domain, num_inputs):\n",
    "    correct = 0\n",
    "    for pattern in domain:\n",
    "        input_vector = list()\n",
    "        for i in range(num_inputs):\n",
    "            input_vector.append(float(pattern[i]))\n",
    "        output = forward_propagate(network, input_vector)\n",
    "        if (round(output) == pattern[-1]):\n",
    "            correct += 1\n",
    "    print(\"Finished test with a score of \" + str(correct / len(domain)))\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neuron(num_inputs):\n",
    "    neuron = {}\n",
    "    neuron[\"weights\"] = initialize_weights(num_inputs + 1)\n",
    "    neuron[\"last_delta\"] = [0.0] * (num_inputs + 1)\n",
    "    neuron[\"deriv\"] = [0.0] * (num_inputs + 1)\n",
    "    return neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(layer_pattern, num_inputs):\n",
    "    network = []\n",
    "    \n",
    "    #Build each layer of the network\n",
    "    for i in range(len(layer_pattern)):\n",
    "        num_nodes = layer_pattern[i]\n",
    "        layer = []\n",
    "        if (i == 0):\n",
    "            for j in range(num_nodes):\n",
    "                layer.append(create_neuron(num_inputs))\n",
    "        else:\n",
    "            for j in range(num_nodes):\n",
    "                layer.append(create_neuron(len(network[i-1])))\n",
    "        network.append(layer)\n",
    "    \n",
    "    # Create Output Node\n",
    "    network.append([create_neuron(len(network[-1]))])\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Testing a Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(network, training_data, num_inputs, iterations, learning_rate, benchmark):\n",
    "    print(\"Topology: inputs = \" + str(num_inputs) + \"  layers = \" + str(len(network)))\n",
    "    train_network(network, training_data, num_inputs, iterations, learning_rate, benchmark)\n",
    "    test_network(network, training_data, num_inputs)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology: inputs = 2  layers = 3\n",
      "> epoch = 100, Correct = 0.49\n",
      "> epoch = 200, Correct = 0.5\n",
      "> epoch = 300, Correct = 0.575\n",
      "> epoch = 400, Correct = 0.75\n",
      "> epoch = 500, Correct = 0.75\n",
      "> epoch = 600, Correct = 0.785\n",
      "> epoch = 700, Correct = 1.0\n",
      "> epoch = 800, Correct = 1.0\n",
      "> epoch = 900, Correct = 1.0\n",
      "> epoch = 1000, Correct = 1.0\n",
      "Finished test with a score of 1.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # problem configuration\n",
    "    xor = [[0,0,0], [0,1,1], [1,0,1], [1,1,0]]\n",
    "    inputs = 2\n",
    "    \n",
    "    # algorithm configuration\n",
    "    learning_rate = 0.3\n",
    "    hidden_layer_pattern = [2, 2]\n",
    "    iterations = 1000\n",
    "    benchmark = 100\n",
    "    \n",
    "    # execute the algorithm\n",
    "    network = build_network(hidden_layer_pattern, inputs)\n",
    "    execute(network, xor, inputs, iterations, learning_rate, benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  XOR Single-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology: inputs = 2  layers = 2\n",
      "> epoch = 100, Correct = 0.5075\n",
      "> epoch = 200, Correct = 0.5\n",
      "> epoch = 300, Correct = 0.5\n",
      "> epoch = 400, Correct = 0.6225\n",
      "> epoch = 500, Correct = 0.75\n",
      "> epoch = 600, Correct = 0.75\n",
      "> epoch = 700, Correct = 0.75\n",
      "> epoch = 800, Correct = 0.75\n",
      "> epoch = 900, Correct = 0.75\n",
      "> epoch = 1000, Correct = 0.75\n",
      "Finished test with a score of 0.75\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # problem configuration\n",
    "    xor = [[0,0,0], [0,1,1], [1,0,1], [1,1,0]]\n",
    "    inputs = 2\n",
    "    \n",
    "    # algorithm configuration\n",
    "    learning_rate = 0.3\n",
    "    hidden_layer_pattern = [1]\n",
    "    iterations = 1000\n",
    "    benchmark = 100\n",
    "    \n",
    "    # execute the algorithm\n",
    "    network = build_network(hidden_layer_pattern, inputs)\n",
    "    execute(network, xor, inputs, iterations, learning_rate, benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Basic Truth Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology: inputs = 3  layers = 3\n",
      "> epoch = 10, Correct = 0.575\n",
      "> epoch = 20, Correct = 0.625\n",
      "> epoch = 30, Correct = 0.625\n",
      "> epoch = 40, Correct = 0.625\n",
      "> epoch = 50, Correct = 0.625\n",
      "> epoch = 60, Correct = 0.7125\n",
      "> epoch = 70, Correct = 0.75\n",
      "> epoch = 80, Correct = 0.9625\n",
      "> epoch = 90, Correct = 1.0\n",
      "> epoch = 100, Correct = 1.0\n",
      "Finished test with a score of 1.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # problem configuration\n",
    "    orAndNot = [[1,1,1,0],[1,1,0,1],[1,0,1,0],[0,1,1,0],[1,0,0,1],[0,1,0,1],[0,0,1,0],[0,0,0,0]]\n",
    "    inputs = 3\n",
    "    \n",
    "    # algorithm configuration\n",
    "    learning_rate = 0.3\n",
    "    hidden_layer_pattern = [2, 2]\n",
    "    iterations = 100\n",
    "    benchmark = 10\n",
    "    \n",
    "    # execute the algorithm\n",
    "    network = build_network(hidden_layer_pattern, inputs)\n",
    "    execute(network, orAndNot, inputs, iterations, learning_rate, benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Partial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology: inputs = 3  layers = 3\n",
      "> epoch = 10, Correct = 0.54\n",
      "> epoch = 20, Correct = 0.6\n",
      "> epoch = 30, Correct = 0.6\n",
      "> epoch = 40, Correct = 0.6\n",
      "> epoch = 50, Correct = 0.78\n",
      "> epoch = 60, Correct = 1.0\n",
      "> epoch = 70, Correct = 1.0\n",
      "> epoch = 80, Correct = 1.0\n",
      "> epoch = 90, Correct = 1.0\n",
      "> epoch = 100, Correct = 1.0\n",
      "Finished test with a score of 1.0\n",
      "Finished test with a score of 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # problem configuration\n",
    "    orAndNot = [[1,1,1,0],[1,1,0,1],[1,0,1,0],[0,1,1,0],[1,0,0,1]] # [0,1,0,1],[0,0,1,0],[0,0,0,0]\n",
    "    inputs = 3\n",
    "    \n",
    "    # algorithm configuration\n",
    "    learning_rate = 0.3\n",
    "    hidden_layer_pattern = [2, 2]\n",
    "    iterations = 100\n",
    "    benchmark = 10\n",
    "    \n",
    "    # execute the algorithm\n",
    "    network = build_network(hidden_layer_pattern, inputs)\n",
    "    execute(network, orAndNot, inputs, iterations, learning_rate, benchmark)\n",
    "    \n",
    "    # test on data it was not trained on\n",
    "    test_set = [[0,1,0,1],[0,0,1,0],[0,0,0,0]]\n",
    "    test_network(network, test_set, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology: inputs = 2  layers = 3\n",
      "> epoch = 100, Correct = 0.76\n",
      "> epoch = 200, Correct = 1.0\n",
      "> epoch = 300, Correct = 1.0\n",
      "> epoch = 400, Correct = 1.0\n",
      "> epoch = 500, Correct = 1.0\n",
      "> epoch = 600, Correct = 1.0\n",
      "> epoch = 700, Correct = 1.0\n",
      "> epoch = 800, Correct = 1.0\n",
      "> epoch = 900, Correct = 1.0\n",
      "> epoch = 1000, Correct = 1.0\n",
      "Finished test with a score of 1.0\n",
      "Finished test with a score of 0.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # problem configuration\n",
    "    xor = [[0,0,0], [0,1,1], [1,0,1]] # [1,1,0]\n",
    "    inputs = 2\n",
    "    \n",
    "    # algorithm configuration\n",
    "    learning_rate = 0.3\n",
    "    hidden_layer_pattern = [2, 2]\n",
    "    iterations = 1000\n",
    "    benchmark = 100\n",
    "    \n",
    "    # execute the algorithm\n",
    "    network = build_network(hidden_layer_pattern, inputs)\n",
    "    execute(network, xor, inputs, iterations, learning_rate, benchmark)\n",
    "    \n",
    "     # test on data it was not trained on\n",
    "    test_set = [[1,1,0]]\n",
    "    test_network(network, test_set, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology: inputs = 3  layers = 3\n",
      "> epoch = 200, Correct = 0.775625\n",
      "> epoch = 400, Correct = 0.875\n",
      "> epoch = 600, Correct = 0.875\n",
      "> epoch = 800, Correct = 0.875\n",
      "> epoch = 1000, Correct = 0.875\n",
      "> epoch = 1200, Correct = 0.875\n",
      "> epoch = 1400, Correct = 0.875\n",
      "> epoch = 1600, Correct = 0.875\n",
      "> epoch = 1800, Correct = 0.875\n",
      "> epoch = 2000, Correct = 0.875\n",
      "Finished test with a score of 0.875\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # problem configuration\n",
    "    xorComplex = [[1,1,1,1],[1,1,0,0],[1,0,1,1],[0,1,1,1],[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]\n",
    "    inputs = 3\n",
    "    \n",
    "    # algorithm configuration\n",
    "    learning_rate = 0.3\n",
    "    hidden_layer_pattern = [2, 2]\n",
    "    iterations = 2000\n",
    "    benchmark = 200\n",
    "    \n",
    "    # execute the algorithm\n",
    "    network = build_network(hidden_layer_pattern, inputs)\n",
    "    execute(network, xorComplex, inputs, iterations, learning_rate, benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Complex 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology: inputs = 3  layers = 3\n",
      "> epoch = 100, Correct = 0.76375\n",
      "> epoch = 200, Correct = 0.875\n",
      "> epoch = 300, Correct = 0.99\n",
      "> epoch = 400, Correct = 1.0\n",
      "> epoch = 500, Correct = 1.0\n",
      "> epoch = 600, Correct = 1.0\n",
      "> epoch = 700, Correct = 1.0\n",
      "> epoch = 800, Correct = 1.0\n",
      "> epoch = 900, Correct = 1.0\n",
      "> epoch = 1000, Correct = 1.0\n",
      "Finished test with a score of 1.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # problem configuration\n",
    "    xorComplex2 = [[1,1,1,1],[1,1,0,0],[1,0,1,1],[0,1,1,1],[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]\n",
    "    inputs = 3\n",
    "    \n",
    "    # algorithm configuration\n",
    "    learning_rate = 0.3\n",
    "    hidden_layer_pattern = [2, 2]\n",
    "    iterations = 1000\n",
    "    benchmark = 100\n",
    "    \n",
    "    # execute the algorithm\n",
    "    network = build_network(hidden_layer_pattern, inputs)\n",
    "    execute(network, xorComplex2, inputs, iterations, learning_rate, benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMBER : https://github.com/KeithCissell/Back-Propagation/tree/master/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
