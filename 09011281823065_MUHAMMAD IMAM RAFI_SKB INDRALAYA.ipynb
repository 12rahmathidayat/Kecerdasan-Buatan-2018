{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56208fe89efb43d31d498ae556f125c038eae949"
   },
   "source": [
    "## **Breast Cancer Prediction with Artificial Neural Network (ANN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6cc6b63aa5ed6877f76f82fb7f0fed47a0e9b81c"
   },
   "source": [
    "   Jaringan saraf tiruan adalah salah satu alat utama yang digunakan dalam pembelajaran mesin. Seperti yang ditunjukkan oleh bagian \"saraf\" dari namanya, mereka adalah sistem yang diilhami oleh otak yang dimaksudkan untuk meniru cara kita sebagai manusia belajar.\n",
    "\n",
    "  Jaringan saraf terdiri dari lapisan masukan dan keluaran, serta (dalam banyak kasus) lapisan tersembunyi yang terdiri dari unit yang mengubah masukan menjadi sesuatu yang dapat digunakan lapisan keluaran. Mereka adalah alat yang sangat baik untuk menemukan pola yang terlalu kompleks atau banyak bagi programmer manusia untuk mengekstrak dan mengajarkan mesin untuk mengenali.Jaringan saraf juga disebut \"perceptrons\".\n",
    "    \n",
    "   Jaringan saraf telah menjadi bagian utama dari kecerdasan buatan dalam beberapa dekade terakhir. Hal ini disebabkan oleh munculnya teknik yang disebut \"propagasi mundur\", yang memungkinkan jaringan menyesuaikan lapisan neuron tersembunyi mereka dalam situasi di mana hasilnya tidak sesuai dengan apa yang diharapkan pembuatnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a534da28925b12f76af564b836995d60bf63a68a"
   },
   "source": [
    "**In this kernel, artificial neural network (ANN) concept has been explained and implemented by using Keras.\n",
    "Link Dataset https://www.kaggle.com/armagansarikey/prediction-with-artificial-neural-network-keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tugas ini, Saya menggunakan Model Artifcial Neural Network (ANN) untuk membuat prediksi dari Breast Cancer dengan menggunakan library keras dalam membantu memprediksi seseorang yang memiliki kemungkinan terkena kanker payudara."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Breast_cancer_data.csv', 'Churn_Modelling.csv', 'seattleWeather_1948-2017.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library yang digunakan\n",
    "\n",
    "**Library Numpy**\n",
    "\n",
    "* NumPy berfungsi untuk mengolah angka dalam bentuk array .\n",
    "\n",
    "**Library pandas**\n",
    "* Pandas berfungsi untuk membaca, mengelola data yang terdapat pada dataset.\n",
    "\n",
    "**Library Matplotlib**\n",
    "* Matplotlib dapat membantu dalam memvisualisasikan ke dalam bentuk plot grafik agar mudah untuk dipahami# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     diagnosis  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "..         ...  \n",
       "564          0  \n",
       "565          0  \n",
       "566          0  \n",
       "567          0  \n",
       "568          1  \n",
       "\n",
       "[569 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('input/Breast_cancer_data.csv')\n",
    "data.head(569)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Mengambil data dari Dataset yang selanjutnya akan diproses. Pada bagian ini kita dapat dapat menentukan jumlah data yang ingin kita proses, dengan mengubah angka pada data.head()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "3e995f86c2492db985b48c0cd019b4fb3b1b3a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   mean_radius      569 non-null    float64\n",
      " 1   mean_texture     569 non-null    float64\n",
      " 2   mean_perimeter   569 non-null    float64\n",
      " 3   mean_area        569 non-null    float64\n",
      " 4   mean_smoothness  569 non-null    float64\n",
      " 5   diagnosis        569 non-null    int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 26.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Menampilkan informasi yang terdapat pada dataset seperti pada data diatas terdapat 6 kolom dan juga tipe data dari setiap kolom dari dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0e33d74d5c0b80f4200fade8e697bb3d576b03d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothness = data['mean_smoothness'] > 1.0\n",
    "smoothness.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "14412c7eec7cfeeaace146a0b9be2e38cf7ea135"
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:,0:5].values\n",
    "Y = data.iloc[:,5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "43c972b5e654346c81b75de5e176bca7ffda96c9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0ceb0f171dd8a75e47ad0245f51ed6e0bc60288"
   },
   "source": [
    "## Features Scaling\n",
    "* Sekarang mari terapkan penskalaan fitur. Penskalaan memastikan bahwa hanya karena beberapa fitur berukuran besar, model tidak akan menggunakannya sebagai prediktor utama.\n",
    "* **Dalam metode jaringan syaraf tiruan (Artificial Neural Network), variabel bebas yaitu data masukan harus dalam interval [0,1].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "a4c979fd00d4959b782b27f7e68ada3011b9c4b4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile ANN\n",
    "**Menyusun classifier.** Menggunakan adam optimizer. Menggunakan **binary_crossentropy untuk fungsi kerugian**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "ba4232969be3345307a7d3bda8d7f6f8664e80ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\M_ImamR\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "381/381 [==============================] - 0s 920us/step - loss: 0.6927 - accuracy: 0.5722\n",
      "Epoch 2/50\n",
      "381/381 [==============================] - 0s 73us/step - loss: 0.6913 - accuracy: 0.6194\n",
      "Epoch 3/50\n",
      "381/381 [==============================] - 0s 80us/step - loss: 0.6897 - accuracy: 0.6194\n",
      "Epoch 4/50\n",
      "381/381 [==============================] - 0s 81us/step - loss: 0.6879 - accuracy: 0.6194\n",
      "Epoch 5/50\n",
      "381/381 [==============================] - 0s 78us/step - loss: 0.6858 - accuracy: 0.6194\n",
      "Epoch 6/50\n",
      "381/381 [==============================] - 0s 89us/step - loss: 0.6825 - accuracy: 0.6194\n",
      "Epoch 7/50\n",
      "381/381 [==============================] - 0s 80us/step - loss: 0.6781 - accuracy: 0.6194\n",
      "Epoch 8/50\n",
      "381/381 [==============================] - 0s 74us/step - loss: 0.6721 - accuracy: 0.6194\n",
      "Epoch 9/50\n",
      "381/381 [==============================] - 0s 76us/step - loss: 0.6640 - accuracy: 0.6194\n",
      "Epoch 10/50\n",
      "381/381 [==============================] - 0s 82us/step - loss: 0.6536 - accuracy: 0.6194\n",
      "Epoch 11/50\n",
      "381/381 [==============================] - 0s 79us/step - loss: 0.6405 - accuracy: 0.6194\n",
      "Epoch 12/50\n",
      "381/381 [==============================] - 0s 83us/step - loss: 0.6252 - accuracy: 0.6273\n",
      "Epoch 13/50\n",
      "381/381 [==============================] - 0s 80us/step - loss: 0.6073 - accuracy: 0.6430\n",
      "Epoch 14/50\n",
      "381/381 [==============================] - 0s 75us/step - loss: 0.5873 - accuracy: 0.6719\n",
      "Epoch 15/50\n",
      "381/381 [==============================] - 0s 85us/step - loss: 0.5655 - accuracy: 0.7690\n",
      "Epoch 16/50\n",
      "381/381 [==============================] - 0s 88us/step - loss: 0.5420 - accuracy: 0.8294\n",
      "Epoch 17/50\n",
      "381/381 [==============================] - 0s 90us/step - loss: 0.5181 - accuracy: 0.8661\n",
      "Epoch 18/50\n",
      "381/381 [==============================] - 0s 90us/step - loss: 0.4935 - accuracy: 0.8793\n",
      "Epoch 19/50\n",
      "381/381 [==============================] - 0s 77us/step - loss: 0.4693 - accuracy: 0.8871\n",
      "Epoch 20/50\n",
      "381/381 [==============================] - 0s 84us/step - loss: 0.4456 - accuracy: 0.9108\n",
      "Epoch 21/50\n",
      "381/381 [==============================] - 0s 80us/step - loss: 0.4229 - accuracy: 0.9160\n",
      "Epoch 22/50\n",
      "381/381 [==============================] - 0s 83us/step - loss: 0.4011 - accuracy: 0.9213\n",
      "Epoch 23/50\n",
      "381/381 [==============================] - 0s 80us/step - loss: 0.3810 - accuracy: 0.9186\n",
      "Epoch 24/50\n",
      "381/381 [==============================] - 0s 77us/step - loss: 0.3620 - accuracy: 0.9239\n",
      "Epoch 25/50\n",
      "381/381 [==============================] - 0s 83us/step - loss: 0.3442 - accuracy: 0.9213\n",
      "Epoch 26/50\n",
      "381/381 [==============================] - 0s 80us/step - loss: 0.3284 - accuracy: 0.9186\n",
      "Epoch 27/50\n",
      "381/381 [==============================] - 0s 80us/step - loss: 0.3134 - accuracy: 0.9186\n",
      "Epoch 28/50\n",
      "381/381 [==============================] - 0s 84us/step - loss: 0.3005 - accuracy: 0.9160\n",
      "Epoch 29/50\n",
      "381/381 [==============================] - 0s 72us/step - loss: 0.2878 - accuracy: 0.9186\n",
      "Epoch 30/50\n",
      "381/381 [==============================] - 0s 77us/step - loss: 0.2774 - accuracy: 0.9213\n",
      "Epoch 31/50\n",
      "381/381 [==============================] - 0s 80us/step - loss: 0.2674 - accuracy: 0.9213\n",
      "Epoch 32/50\n",
      "381/381 [==============================] - 0s 81us/step - loss: 0.2586 - accuracy: 0.9239\n",
      "Epoch 33/50\n",
      "381/381 [==============================] - 0s 86us/step - loss: 0.2503 - accuracy: 0.9213\n",
      "Epoch 34/50\n",
      "381/381 [==============================] - 0s 83us/step - loss: 0.2435 - accuracy: 0.9186\n",
      "Epoch 35/50\n",
      "381/381 [==============================] - 0s 77us/step - loss: 0.2368 - accuracy: 0.9186\n",
      "Epoch 36/50\n",
      "381/381 [==============================] - 0s 79us/step - loss: 0.2310 - accuracy: 0.9160\n",
      "Epoch 37/50\n",
      "381/381 [==============================] - 0s 87us/step - loss: 0.2257 - accuracy: 0.9160\n",
      "Epoch 38/50\n",
      "381/381 [==============================] - 0s 76us/step - loss: 0.2210 - accuracy: 0.9186\n",
      "Epoch 39/50\n",
      "381/381 [==============================] - 0s 82us/step - loss: 0.2165 - accuracy: 0.9213\n",
      "Epoch 40/50\n",
      "381/381 [==============================] - 0s 77us/step - loss: 0.2129 - accuracy: 0.9213\n",
      "Epoch 41/50\n",
      "381/381 [==============================] - 0s 76us/step - loss: 0.2092 - accuracy: 0.9213\n",
      "Epoch 42/50\n",
      "381/381 [==============================] - 0s 90us/step - loss: 0.2060 - accuracy: 0.9239\n",
      "Epoch 43/50\n",
      "381/381 [==============================] - 0s 87us/step - loss: 0.2030 - accuracy: 0.9265\n",
      "Epoch 44/50\n",
      "381/381 [==============================] - 0s 79us/step - loss: 0.2001 - accuracy: 0.9265\n",
      "Epoch 45/50\n",
      "381/381 [==============================] - 0s 74us/step - loss: 0.1976 - accuracy: 0.9291\n",
      "Epoch 46/50\n",
      "381/381 [==============================] - 0s 68us/step - loss: 0.1954 - accuracy: 0.9291\n",
      "Epoch 47/50\n",
      "381/381 [==============================] - 0s 79us/step - loss: 0.1933 - accuracy: 0.9318\n",
      "Epoch 48/50\n",
      "381/381 [==============================] - 0s 79us/step - loss: 0.1914 - accuracy: 0.9318\n",
      "Epoch 49/50\n",
      "381/381 [==============================] - 0s 81us/step - loss: 0.1896 - accuracy: 0.9318\n",
      "Epoch 50/50\n",
      "381/381 [==============================] - 0s 76us/step - loss: 0.1881 - accuracy: 0.9318\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "# Hidden layers and input layer are  added.\n",
    "classifier.add(Dense(3, kernel_initializer=\"uniform\", activation = 'relu', input_dim = 5))\n",
    "\n",
    "classifier.add(Dense(3, kernel_initializer=\"uniform\", activation = 'relu'))\n",
    "\n",
    "# Output layer\n",
    "classifier.add(Dense(1, kernel_initializer=\"uniform\", activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, y_train, epochs = 50)\n",
    "\n",
    "# Prediction\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "5b57b3fcee2e814e48fc64746a2d3df24cb44933"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27575248],\n",
       "       [0.7948176 ],\n",
       "       [0.964008  ],\n",
       "       [0.9751274 ],\n",
       "       [0.94538885],\n",
       "       [0.94672894],\n",
       "       [0.98458976],\n",
       "       [0.9768889 ],\n",
       "       [0.9967948 ],\n",
       "       [0.98985755],\n",
       "       [0.5383309 ],\n",
       "       [0.30659416],\n",
       "       [0.9954089 ],\n",
       "       [0.328563  ],\n",
       "       [0.2085185 ],\n",
       "       [0.13196343],\n",
       "       [0.98974633],\n",
       "       [0.01917669],\n",
       "       [0.02933773],\n",
       "       [0.01556399],\n",
       "       [0.8713334 ],\n",
       "       [0.11338428],\n",
       "       [0.8459732 ],\n",
       "       [0.9742149 ],\n",
       "       [0.02385882],\n",
       "       [0.9919205 ],\n",
       "       [0.9978354 ],\n",
       "       [0.17178407],\n",
       "       [0.9718044 ],\n",
       "       [0.06032223],\n",
       "       [0.98201734],\n",
       "       [0.0449872 ],\n",
       "       [0.9253778 ],\n",
       "       [0.11911711],\n",
       "       [0.9970855 ],\n",
       "       [0.28322202],\n",
       "       [0.962945  ],\n",
       "       [0.08290741],\n",
       "       [0.7818792 ],\n",
       "       [0.1307317 ],\n",
       "       [0.17545676],\n",
       "       [0.99839   ],\n",
       "       [0.19388875],\n",
       "       [0.99045515],\n",
       "       [0.9433503 ],\n",
       "       [0.00912625],\n",
       "       [0.9979292 ],\n",
       "       [0.7222156 ],\n",
       "       [0.95523   ],\n",
       "       [0.10013771],\n",
       "       [0.03102526],\n",
       "       [0.1480354 ],\n",
       "       [0.05974007],\n",
       "       [0.98414785],\n",
       "       [0.96568286],\n",
       "       [0.9850764 ],\n",
       "       [0.98316056],\n",
       "       [0.91990745],\n",
       "       [0.9771273 ],\n",
       "       [0.01457715],\n",
       "       [0.15089515],\n",
       "       [0.17494941],\n",
       "       [0.99735063],\n",
       "       [0.951165  ],\n",
       "       [0.07294178],\n",
       "       [0.8915994 ],\n",
       "       [0.00395003],\n",
       "       [0.02831557],\n",
       "       [0.02872258],\n",
       "       [0.97696185],\n",
       "       [0.667848  ],\n",
       "       [0.07815585],\n",
       "       [0.97295475],\n",
       "       [0.46980584],\n",
       "       [0.0448786 ],\n",
       "       [0.9035819 ],\n",
       "       [0.9962437 ],\n",
       "       [0.67079186],\n",
       "       [0.99300766],\n",
       "       [0.99241126],\n",
       "       [0.11051217],\n",
       "       [0.00755948],\n",
       "       [0.07939541],\n",
       "       [0.988636  ],\n",
       "       [0.22893429],\n",
       "       [0.96645355],\n",
       "       [0.9892965 ],\n",
       "       [0.9984194 ],\n",
       "       [0.08896539],\n",
       "       [0.00737512],\n",
       "       [0.9945283 ],\n",
       "       [0.675414  ],\n",
       "       [0.45830917],\n",
       "       [0.08220753],\n",
       "       [0.9750687 ],\n",
       "       [0.98128474],\n",
       "       [0.10369793],\n",
       "       [0.9749385 ],\n",
       "       [0.98199075],\n",
       "       [0.9378228 ],\n",
       "       [0.99572206],\n",
       "       [0.9738623 ],\n",
       "       [0.7116318 ],\n",
       "       [0.18732911],\n",
       "       [0.0634141 ],\n",
       "       [0.5070716 ],\n",
       "       [0.02947056],\n",
       "       [0.29625124],\n",
       "       [0.6821992 ],\n",
       "       [0.05887726],\n",
       "       [0.76208997],\n",
       "       [0.01937574],\n",
       "       [0.04648367],\n",
       "       [0.37202132],\n",
       "       [0.98447466],\n",
       "       [0.97948074],\n",
       "       [0.26231307],\n",
       "       [0.9235819 ],\n",
       "       [0.9629555 ],\n",
       "       [0.97807145],\n",
       "       [0.99454856],\n",
       "       [0.91321003],\n",
       "       [0.17441157],\n",
       "       [0.9228324 ],\n",
       "       [0.01916507],\n",
       "       [0.8258041 ],\n",
       "       [0.83493835],\n",
       "       [0.9858669 ],\n",
       "       [0.9932802 ],\n",
       "       [0.99249876],\n",
       "       [0.06511036],\n",
       "       [0.9938388 ],\n",
       "       [0.969473  ],\n",
       "       [0.5795076 ],\n",
       "       [0.9716835 ],\n",
       "       [0.9950142 ],\n",
       "       [0.40921432],\n",
       "       [0.43452466],\n",
       "       [0.00553474],\n",
       "       [0.9319148 ],\n",
       "       [0.9858259 ],\n",
       "       [0.35290936],\n",
       "       [0.02645808],\n",
       "       [0.98512644],\n",
       "       [0.9378668 ],\n",
       "       [0.01859924],\n",
       "       [0.96333396],\n",
       "       [0.32954216],\n",
       "       [0.9788551 ],\n",
       "       [0.94113725],\n",
       "       [0.9584048 ],\n",
       "       [0.9084966 ],\n",
       "       [0.98752975],\n",
       "       [0.5332231 ],\n",
       "       [0.97722113],\n",
       "       [0.10699531],\n",
       "       [0.9465344 ],\n",
       "       [0.5401001 ],\n",
       "       [0.98035324],\n",
       "       [0.10710928],\n",
       "       [0.03328618],\n",
       "       [0.97625864],\n",
       "       [0.98740476],\n",
       "       [0.10548002],\n",
       "       [0.9804863 ],\n",
       "       [0.06734601],\n",
       "       [0.17261165],\n",
       "       [0.06036884],\n",
       "       [0.7305567 ],\n",
       "       [0.9181178 ],\n",
       "       [0.9891697 ],\n",
       "       [0.9681579 ],\n",
       "       [0.9646462 ],\n",
       "       [0.97488785],\n",
       "       [0.10136926],\n",
       "       [0.9961816 ],\n",
       "       [0.97896934],\n",
       "       [0.83432937],\n",
       "       [0.9877701 ],\n",
       "       [0.25797147],\n",
       "       [0.03008941],\n",
       "       [0.93420494],\n",
       "       [0.8625053 ],\n",
       "       [0.41575393],\n",
       "       [0.9593053 ],\n",
       "       [0.95094764],\n",
       "       [0.8932531 ],\n",
       "       [0.7548592 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat Prediksi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "0820de8701138657e0808aadea1af74f786a6261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 63   4]\n",
      " [ 10 111]]\n",
      "Accuracy in % : 92.5531914893617%\n",
      "Accuracy score:  0.925531914893617\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = [ 1 if y>=0.5 else 0 for y in y_pred ]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "print(\"Accuracy in % : \"+ str(accuracy*100)+\"%\")\n",
    "print ('Accuracy score: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f9ca2c9f2587dc069fda2efc324d4ab1e399fcc3"
   },
   "source": [
    "# Kesimpulan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c685bd8b9febf8961e96a4b5817e5207510906a4"
   },
   "source": [
    "Berdasarkan hasil dari confusion matrix, prediksi kanker payudara cukup berhasil dengan menghasilkan tingkat akurasi dalam memprediksi kanker yaitu **0.92 atau 92%.** \n",
    "\n",
    "**Sumber : https://www.kaggle.com/armagansarikey/prediction-with-artificial-neural-network-keras**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
