{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks\n",
    "- Disini kita akan membuat jaringan saraf tiruan.\n",
    "- Faktanya, Jaringan Syaraf Tiruan mirip dengan Regresi Logistik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Jaringan Neural Network\n",
    "- Pertama, lihat jaringan syaraf tiruan 2 lapis dengan beberapa tahapan\n",
    "- Kita menggunakan 1 layer tersembunyi dan 3 neuron buatan\n",
    "\n",
    "### Tahapan\n",
    "- Inisialisasi parameter\n",
    "- Forward Propagation\n",
    "- Compute Loss and Cost Function.\n",
    "- Backward Propagation\n",
    "- Update weight and bias\n",
    "- Repeat n times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # Linear algebra.\n",
    "import pandas as pd # Data processing.\n",
    "import matplotlib.pyplot as plt # Visualize\n",
    "\n",
    "from sklearn.model_selection import train_test_split # For data split.\n",
    "from sklearn.model_selection import cross_val_score # For find accuracy.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data.drop([\"id\"],axis = 1,inplace = True)\n",
    "\n",
    "data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis] # M = 1, B = 0\n",
    "\n",
    "x_data = data.drop([\"diagnosis\",\"Unnamed: 32\"],axis = 1)\n",
    "\n",
    "x = (x_data - np.min(x_data))/(np.max(x_data)-np.min(x_data)).values # Normalize data\n",
    "y = data.diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.15, random_state = 42) # 85% Train, 15% Test\n",
    "\n",
    "x_train = x_train.values.T\n",
    "x_test = x_test.values.T\n",
    "y_test = y_test.values.reshape(1,y_test.shape[0])\n",
    "y_train = y_train.values.reshape(1,y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Parameters\n",
    "- Untuk memulai perulangan kita perlu memberikan nilai awal secara intuitif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(dimension):\n",
    "    w = np.full((dimension,1),0.01)\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fungsi Aktivasi\n",
    "- Kami akan menggunakan fungsi sigmoid\n",
    "- Faktanya, tidak logis menggunakan fungsi sigmoid di jaringan saraf tiruan kecuali antara lapisan tersembunyi dan keluaran.\n",
    "- Kita mengabaikannya karena tujuan kita saat ini adalah untuk belajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z)) # It is the formule of sigmoid function\n",
    "    return y_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward - Backward Propagation\n",
    "- Pertama kita akan memperkirakan dengan nilai bias dan bobot kemudian kita akan kembali dan memperbarui bobot dan bias kita jika hasilnya salah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward_propagation(w,b,x_train,y_train):\n",
    "    y_head = sigmoid(np.dot(w.T,x_train) + b) # We multiply features with our weight values, add bias and send it to sigmoid function\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head) # It is the formule of loss function\n",
    "    cost = (np.sum(loss))/x_train.shape[1] # Calculate cost function\n",
    "    \n",
    "    derivative_weight = (np.dot(x_train, ((y_head-y_train).T)))/x_train.shape[1] # Calculate derivative of weights\n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1] # Calculate derivative of bias\n",
    "    \n",
    "    gradients = {\"derivative_weight\":derivative_weight,\"derivative_bias\":derivative_bias}\n",
    "    return cost,gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "\n",
    "    for i in range(number_of_iterarion):\n",
    "        # Start learning\n",
    "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train) # Make forward and backward propagation and calculate cost and derivatives\n",
    "        cost_list.append(cost)\n",
    "        # Updating weight and bias\n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
    "        if i % 250 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    parameters = {\"w\": w,\"b\": b}\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(w,b,x_test):\n",
    "    z = sigmoid(np.dot(w.T,x_test)+b) # z -> Estimates of our model\n",
    "    y_prediction = np.zeros((1,x_test.shape[1])) # We create an array, we will set the array.\n",
    "    \n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i]<= 0.5:\n",
    "            y_prediction[0,i] = 0\n",
    "        else:\n",
    "            y_prediction[0,i] = 1\n",
    "\n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artificial_neural_networks(x_train,x_test,y_train,y_test,learning_rate,number_of_iteration):\n",
    "    dimension = x_train.shape[0]\n",
    "    w,b = initialize_weights_and_bias(dimension) # Initialize Parameters\n",
    "    parameters,gradients, cost_list = update(w,b,x_train,y_train,learning_rate,number_of_iteration) # Update parameters\n",
    "    \n",
    "    train_prediction = prediction(parameters[\"w\"],parameters[\"b\"],x_train) # Estimates of our model\n",
    "    test_prediction = prediction(parameters[\"w\"],parameters[\"b\"],x_test) # Estimates of our model\n",
    "    \n",
    "    print(\"Train accuracy: {} %\".format(100 - np.mean(np.abs(train_prediction - y_train)) * 100))\n",
    "    print(\"Test accuracy: {} %\".format(100 - np.mean(np.abs(test_prediction - y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692836\n",
      "Cost after iteration 250: 0.158517\n",
      "Cost after iteration 500: 0.125103\n",
      "Cost after iteration 750: 0.109693\n",
      "Cost after iteration 1000: 0.100409\n",
      "Cost after iteration 1250: 0.094055\n",
      "Cost after iteration 1500: 0.089353\n",
      "Cost after iteration 1750: 0.085686\n",
      "Cost after iteration 2000: 0.082714\n",
      "Cost after iteration 2250: 0.080237\n",
      "Cost after iteration 2500: 0.078126\n",
      "Cost after iteration 2750: 0.076295\n",
      "Cost after iteration 3000: 0.074683\n",
      "Cost after iteration 3250: 0.073248\n",
      "Cost after iteration 3500: 0.071958\n",
      "Cost after iteration 3750: 0.070789\n",
      "Cost after iteration 4000: 0.069721\n",
      "Cost after iteration 4250: 0.068740\n",
      "Cost after iteration 4500: 0.067835\n",
      "Cost after iteration 4750: 0.066995\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 98.34368530020704 %\n",
      "Test accuracy: 97.67441860465117 %\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "number_of_iteration = 5000\n",
    "ann = artificial_neural_networks(x_train,x_test,y_train,y_test,learning_rate,number_of_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L Layer Neural Network\n",
    "\n",
    "- kita akan menggunakan 3 hidden layer.\n",
    "- kita akan menggunakan 'keras'. karena cara ini mudah untuk membuat ANN model\n",
    "- Dalam model ini, kita akan menghitung akurasi dengan skor validasi silang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology\n",
    "- units -> Number of Neuron\n",
    "- kernel_initializer (uniform) -> initialize values\n",
    "- activation -> Our activation function. We use tanh\n",
    "- input_dim -> Number of Feature\n",
    "- optimizer (adam) -> adaptive moment estimation. (You can search in Google)\n",
    "- loss -> Our loss function\n",
    "- metrics -> Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = \"uniform\", activation = \"tanh\", input_dim = x_train.shape[1]))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = \"uniform\", activation = \"tanh\"))\n",
    "    classifier.add(Dense(units = 2, kernel_initializer = \"uniform\", activation = \"tanh\"))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = \"uniform\", activation = \"sigmoid\"))\n",
    "    classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.6118\n",
      "Epoch 2/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.6916 - accuracy: 0.6118\n",
      "Epoch 3/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.6905 - accuracy: 0.6118\n",
      "Epoch 4/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.6893 - accuracy: 0.6118\n",
      "Epoch 5/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.6883 - accuracy: 0.6118\n",
      "Epoch 6/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.6872 - accuracy: 0.6118\n",
      "Epoch 7/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.6853 - accuracy: 0.6118\n",
      "Epoch 8/100\n",
      "322/322 [==============================] - 0s 106us/step - loss: 0.6822 - accuracy: 0.6118\n",
      "Epoch 9/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.6778 - accuracy: 0.6118\n",
      "Epoch 10/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.6710 - accuracy: 0.6149\n",
      "Epoch 11/100\n",
      "322/322 [==============================] - 0s 103us/step - loss: 0.6623 - accuracy: 0.6242\n",
      "Epoch 12/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.6499 - accuracy: 0.6615\n",
      "Epoch 13/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.6343 - accuracy: 0.7702\n",
      "Epoch 14/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.6170 - accuracy: 0.8540\n",
      "Epoch 15/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.5989 - accuracy: 0.8758\n",
      "Epoch 16/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.5798 - accuracy: 0.8696\n",
      "Epoch 17/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.5603 - accuracy: 0.8789\n",
      "Epoch 18/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.5414 - accuracy: 0.8851\n",
      "Epoch 19/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.5234 - accuracy: 0.9006\n",
      "Epoch 20/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.5068 - accuracy: 0.9068\n",
      "Epoch 21/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.4915 - accuracy: 0.9193\n",
      "Epoch 22/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.4769 - accuracy: 0.9161\n",
      "Epoch 23/100\n",
      "322/322 [==============================] - 0s 103us/step - loss: 0.4643 - accuracy: 0.9130\n",
      "Epoch 24/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.4526 - accuracy: 0.9130\n",
      "Epoch 25/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.4404 - accuracy: 0.9255\n",
      "Epoch 26/100\n",
      "322/322 [==============================] - 0s 95us/step - loss: 0.4295 - accuracy: 0.9286\n",
      "Epoch 27/100\n",
      "322/322 [==============================] - 0s 98us/step - loss: 0.4187 - accuracy: 0.9193\n",
      "Epoch 28/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.4093 - accuracy: 0.9161\n",
      "Epoch 29/100\n",
      "322/322 [==============================] - 0s 113us/step - loss: 0.3997 - accuracy: 0.9317\n",
      "Epoch 30/100\n",
      "322/322 [==============================] - 0s 127us/step - loss: 0.3914 - accuracy: 0.9379\n",
      "Epoch 31/100\n",
      "322/322 [==============================] - 0s 115us/step - loss: 0.3831 - accuracy: 0.9379\n",
      "Epoch 32/100\n",
      "322/322 [==============================] - 0s 79us/step - loss: 0.3748 - accuracy: 0.9348\n",
      "Epoch 33/100\n",
      "322/322 [==============================] - 0s 103us/step - loss: 0.3672 - accuracy: 0.9286\n",
      "Epoch 34/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.3612 - accuracy: 0.9286\n",
      "Epoch 35/100\n",
      "322/322 [==============================] - 0s 106us/step - loss: 0.3532 - accuracy: 0.9317\n",
      "Epoch 36/100\n",
      "322/322 [==============================] - 0s 109us/step - loss: 0.3475 - accuracy: 0.9379\n",
      "Epoch 37/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.3411 - accuracy: 0.9379\n",
      "Epoch 38/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.3325 - accuracy: 0.9472\n",
      "Epoch 39/100\n",
      "322/322 [==============================] - 0s 115us/step - loss: 0.3277 - accuracy: 0.9379\n",
      "Epoch 40/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.3219 - accuracy: 0.9441\n",
      "Epoch 41/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.3160 - accuracy: 0.9441\n",
      "Epoch 42/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.3104 - accuracy: 0.9503\n",
      "Epoch 43/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.3052 - accuracy: 0.9503\n",
      "Epoch 44/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.3023 - accuracy: 0.9441\n",
      "Epoch 45/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.2947 - accuracy: 0.9472\n",
      "Epoch 46/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.2934 - accuracy: 0.9348\n",
      "Epoch 47/100\n",
      "322/322 [==============================] - 0s 115us/step - loss: 0.2869 - accuracy: 0.9472\n",
      "Epoch 48/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.2810 - accuracy: 0.9565\n",
      "Epoch 49/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.2766 - accuracy: 0.9534\n",
      "Epoch 50/100\n",
      "322/322 [==============================] - 0s 103us/step - loss: 0.2725 - accuracy: 0.9534\n",
      "Epoch 51/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.2681 - accuracy: 0.9596\n",
      "Epoch 52/100\n",
      "322/322 [==============================] - 0s 115us/step - loss: 0.2632 - accuracy: 0.9596\n",
      "Epoch 53/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.2596 - accuracy: 0.9565\n",
      "Epoch 54/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.2551 - accuracy: 0.9565\n",
      "Epoch 55/100\n",
      "322/322 [==============================] - 0s 109us/step - loss: 0.2518 - accuracy: 0.9658\n",
      "Epoch 56/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.2478 - accuracy: 0.9627\n",
      "Epoch 57/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.2432 - accuracy: 0.9596\n",
      "Epoch 58/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.2430 - accuracy: 0.9596\n",
      "Epoch 59/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.2385 - accuracy: 0.9596\n",
      "Epoch 60/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.2339 - accuracy: 0.9627\n",
      "Epoch 61/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.2307 - accuracy: 0.9658\n",
      "Epoch 62/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.2263 - accuracy: 0.9658\n",
      "Epoch 63/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.2252 - accuracy: 0.9658\n",
      "Epoch 64/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.2207 - accuracy: 0.9658\n",
      "Epoch 65/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.2171 - accuracy: 0.9689\n",
      "Epoch 66/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.2142 - accuracy: 0.9689\n",
      "Epoch 67/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.2112 - accuracy: 0.9689\n",
      "Epoch 68/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.2088 - accuracy: 0.9689\n",
      "Epoch 69/100\n",
      "322/322 [==============================] - 0s 103us/step - loss: 0.2056 - accuracy: 0.9689\n",
      "Epoch 70/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.2028 - accuracy: 0.9689\n",
      "Epoch 71/100\n",
      "322/322 [==============================] - 0s 121us/step - loss: 0.2079 - accuracy: 0.9534\n",
      "Epoch 72/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.2025 - accuracy: 0.9596\n",
      "Epoch 73/100\n",
      "322/322 [==============================] - 0s 103us/step - loss: 0.2012 - accuracy: 0.9689\n",
      "Epoch 74/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1985 - accuracy: 0.9720\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 99us/step - loss: 0.1920 - accuracy: 0.9658\n",
      "Epoch 76/100\n",
      "322/322 [==============================] - 0s 103us/step - loss: 0.1881 - accuracy: 0.9720\n",
      "Epoch 77/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1887 - accuracy: 0.9720\n",
      "Epoch 78/100\n",
      "322/322 [==============================] - 0s 131us/step - loss: 0.1868 - accuracy: 0.9689\n",
      "Epoch 79/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1797 - accuracy: 0.9783\n",
      "Epoch 80/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1778 - accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.1754 - accuracy: 0.9783\n",
      "Epoch 82/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1733 - accuracy: 0.9814\n",
      "Epoch 83/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1711 - accuracy: 0.9752\n",
      "Epoch 84/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.1712 - accuracy: 0.9720\n",
      "Epoch 85/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.1674 - accuracy: 0.9752\n",
      "Epoch 86/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1667 - accuracy: 0.9783\n",
      "Epoch 87/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1648 - accuracy: 0.9752\n",
      "Epoch 88/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.1721 - accuracy: 0.9689\n",
      "Epoch 89/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.1647 - accuracy: 0.9720\n",
      "Epoch 90/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1603 - accuracy: 0.9783\n",
      "Epoch 91/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1578 - accuracy: 0.9783\n",
      "Epoch 92/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1566 - accuracy: 0.9752\n",
      "Epoch 93/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.1701 - accuracy: 0.9658\n",
      "Epoch 94/100\n",
      "322/322 [==============================] - 0s 103us/step - loss: 0.1581 - accuracy: 0.9752\n",
      "Epoch 95/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1592 - accuracy: 0.9752\n",
      "Epoch 96/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1523 - accuracy: 0.9783\n",
      "Epoch 97/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1497 - accuracy: 0.9783\n",
      "Epoch 98/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1482 - accuracy: 0.9752\n",
      "Epoch 99/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1475 - accuracy: 0.9783\n",
      "Epoch 100/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1457 - accuracy: 0.9783\n",
      "161/161 [==============================] - 0s 640us/step\n",
      "Epoch 1/100\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.6242\n",
      "Epoch 2/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.6912 - accuracy: 0.6242\n",
      "Epoch 3/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.6899 - accuracy: 0.6242\n",
      "Epoch 4/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.6883 - accuracy: 0.6242\n",
      "Epoch 5/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.6866 - accuracy: 0.6242\n",
      "Epoch 6/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.6845 - accuracy: 0.6242\n",
      "Epoch 7/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.6818 - accuracy: 0.6242\n",
      "Epoch 8/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.6779 - accuracy: 0.6242\n",
      "Epoch 9/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.6725 - accuracy: 0.6242\n",
      "Epoch 10/100\n",
      "322/322 [==============================] - 0s 109us/step - loss: 0.6646 - accuracy: 0.6335\n",
      "Epoch 11/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.6535 - accuracy: 0.6615\n",
      "Epoch 12/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.6390 - accuracy: 0.7081\n",
      "Epoch 13/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.6226 - accuracy: 0.7702\n",
      "Epoch 14/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.6053 - accuracy: 0.8416\n",
      "Epoch 15/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.5875 - accuracy: 0.8820\n",
      "Epoch 16/100\n",
      "322/322 [==============================] - 0s 103us/step - loss: 0.5685 - accuracy: 0.8913\n",
      "Epoch 17/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.5496 - accuracy: 0.8820\n",
      "Epoch 18/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.5316 - accuracy: 0.9130\n",
      "Epoch 19/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.5146 - accuracy: 0.9255\n",
      "Epoch 20/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.4985 - accuracy: 0.9161\n",
      "Epoch 21/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.4824 - accuracy: 0.9255\n",
      "Epoch 22/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.4682 - accuracy: 0.9255\n",
      "Epoch 23/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.4545 - accuracy: 0.9286\n",
      "Epoch 24/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.4418 - accuracy: 0.9193\n",
      "Epoch 25/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.4316 - accuracy: 0.9130\n",
      "Epoch 26/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.4212 - accuracy: 0.9224\n",
      "Epoch 27/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.4118 - accuracy: 0.9317\n",
      "Epoch 28/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.4044 - accuracy: 0.9286\n",
      "Epoch 29/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.3935 - accuracy: 0.9286\n",
      "Epoch 30/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.3842 - accuracy: 0.9255\n",
      "Epoch 31/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.3761 - accuracy: 0.9255\n",
      "Epoch 32/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.3682 - accuracy: 0.9317\n",
      "Epoch 33/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.3614 - accuracy: 0.9348\n",
      "Epoch 34/100\n",
      "322/322 [==============================] - 0s 103us/step - loss: 0.3587 - accuracy: 0.9348\n",
      "Epoch 35/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.3487 - accuracy: 0.9379\n",
      "Epoch 36/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.3406 - accuracy: 0.9410\n",
      "Epoch 37/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.3346 - accuracy: 0.9441\n",
      "Epoch 38/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.3299 - accuracy: 0.9410\n",
      "Epoch 39/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.3234 - accuracy: 0.9410\n",
      "Epoch 40/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.3160 - accuracy: 0.9534\n",
      "Epoch 41/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.3098 - accuracy: 0.9472\n",
      "Epoch 42/100\n",
      "322/322 [==============================] - 0s 103us/step - loss: 0.3042 - accuracy: 0.9596\n",
      "Epoch 43/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.2981 - accuracy: 0.9534\n",
      "Epoch 44/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.2927 - accuracy: 0.9565\n",
      "Epoch 45/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.2879 - accuracy: 0.9596\n",
      "Epoch 46/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.2819 - accuracy: 0.9596\n",
      "Epoch 47/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.2770 - accuracy: 0.9596\n",
      "Epoch 48/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.2770 - accuracy: 0.9503\n",
      "Epoch 49/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.2709 - accuracy: 0.9472\n",
      "Epoch 50/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.2628 - accuracy: 0.9627\n",
      "Epoch 51/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.2579 - accuracy: 0.9658\n",
      "Epoch 52/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.2553 - accuracy: 0.9565\n",
      "Epoch 53/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.2526 - accuracy: 0.9596\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 96us/step - loss: 0.2461 - accuracy: 0.9658\n",
      "Epoch 55/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.2413 - accuracy: 0.9689\n",
      "Epoch 56/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.2370 - accuracy: 0.9658\n",
      "Epoch 57/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.2335 - accuracy: 0.9627\n",
      "Epoch 58/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.2318 - accuracy: 0.9658\n",
      "Epoch 59/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.2290 - accuracy: 0.9627\n",
      "Epoch 60/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.2225 - accuracy: 0.9720\n",
      "Epoch 61/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.2181 - accuracy: 0.9658\n",
      "Epoch 62/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.2184 - accuracy: 0.9689\n",
      "Epoch 63/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.2123 - accuracy: 0.9689\n",
      "Epoch 64/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.2107 - accuracy: 0.9720\n",
      "Epoch 65/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.2047 - accuracy: 0.9658\n",
      "Epoch 66/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.2027 - accuracy: 0.9689\n",
      "Epoch 67/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.2028 - accuracy: 0.9752\n",
      "Epoch 68/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1988 - accuracy: 0.9720\n",
      "Epoch 69/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.1937 - accuracy: 0.9689\n",
      "Epoch 70/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1908 - accuracy: 0.9658\n",
      "Epoch 71/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1878 - accuracy: 0.9689\n",
      "Epoch 72/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1934 - accuracy: 0.9658\n",
      "Epoch 73/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1864 - accuracy: 0.9752\n",
      "Epoch 74/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1807 - accuracy: 0.9783\n",
      "Epoch 75/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1788 - accuracy: 0.9689\n",
      "Epoch 76/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1744 - accuracy: 0.9752\n",
      "Epoch 77/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.1728 - accuracy: 0.9814\n",
      "Epoch 78/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1700 - accuracy: 0.9814\n",
      "Epoch 79/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1682 - accuracy: 0.9752\n",
      "Epoch 80/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.1670 - accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1630 - accuracy: 0.9783\n",
      "Epoch 82/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1625 - accuracy: 0.9752\n",
      "Epoch 83/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1590 - accuracy: 0.9814\n",
      "Epoch 84/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1585 - accuracy: 0.9814\n",
      "Epoch 85/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1562 - accuracy: 0.9814\n",
      "Epoch 86/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1533 - accuracy: 0.9814\n",
      "Epoch 87/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.1512 - accuracy: 0.9814\n",
      "Epoch 88/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1507 - accuracy: 0.9814\n",
      "Epoch 89/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1473 - accuracy: 0.9814\n",
      "Epoch 90/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1462 - accuracy: 0.9814\n",
      "Epoch 91/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.1449 - accuracy: 0.9783\n",
      "Epoch 92/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1437 - accuracy: 0.9814\n",
      "Epoch 93/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.1421 - accuracy: 0.9814\n",
      "Epoch 94/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.1392 - accuracy: 0.9814\n",
      "Epoch 95/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.1380 - accuracy: 0.9814\n",
      "Epoch 96/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1364 - accuracy: 0.9814\n",
      "Epoch 97/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1368 - accuracy: 0.9783\n",
      "Epoch 98/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1334 - accuracy: 0.9814\n",
      "Epoch 99/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1321 - accuracy: 0.9814\n",
      "Epoch 100/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1309 - accuracy: 0.9814\n",
      "161/161 [==============================] - 0s 777us/step\n",
      "Epoch 1/100\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.6460\n",
      "Epoch 2/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.6910 - accuracy: 0.6460\n",
      "Epoch 3/100\n",
      "322/322 [==============================] - 0s 65us/step - loss: 0.6895 - accuracy: 0.6460\n",
      "Epoch 4/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.6876 - accuracy: 0.6460\n",
      "Epoch 5/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.6858 - accuracy: 0.6460\n",
      "Epoch 6/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.6832 - accuracy: 0.6460\n",
      "Epoch 7/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.6806 - accuracy: 0.6460\n",
      "Epoch 8/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.6769 - accuracy: 0.6460\n",
      "Epoch 9/100\n",
      "322/322 [==============================] - 0s 71us/step - loss: 0.6721 - accuracy: 0.6460\n",
      "Epoch 10/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.6654 - accuracy: 0.6460\n",
      "Epoch 11/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.6559 - accuracy: 0.6460\n",
      "Epoch 12/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.6442 - accuracy: 0.6584\n",
      "Epoch 13/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.6289 - accuracy: 0.7174\n",
      "Epoch 14/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.6115 - accuracy: 0.7981\n",
      "Epoch 15/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.5927 - accuracy: 0.8758\n",
      "Epoch 16/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.5735 - accuracy: 0.8789\n",
      "Epoch 17/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.5548 - accuracy: 0.8696\n",
      "Epoch 18/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.5347 - accuracy: 0.9006\n",
      "Epoch 19/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.5173 - accuracy: 0.9255\n",
      "Epoch 20/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.4998 - accuracy: 0.9255\n",
      "Epoch 21/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.4836 - accuracy: 0.9286\n",
      "Epoch 22/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.4686 - accuracy: 0.9286\n",
      "Epoch 23/100\n",
      "322/322 [==============================] - 0s 71us/step - loss: 0.4548 - accuracy: 0.9348\n",
      "Epoch 24/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.4424 - accuracy: 0.9255\n",
      "Epoch 25/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.4315 - accuracy: 0.9317\n",
      "Epoch 26/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.4191 - accuracy: 0.9348\n",
      "Epoch 27/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.4119 - accuracy: 0.9348\n",
      "Epoch 28/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.4002 - accuracy: 0.9348\n",
      "Epoch 29/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.3886 - accuracy: 0.9441\n",
      "Epoch 30/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.3806 - accuracy: 0.9441\n",
      "Epoch 31/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.3721 - accuracy: 0.9410\n",
      "Epoch 32/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.3639 - accuracy: 0.9472\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 75us/step - loss: 0.3555 - accuracy: 0.9503\n",
      "Epoch 34/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.3469 - accuracy: 0.9565\n",
      "Epoch 35/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.3394 - accuracy: 0.9565\n",
      "Epoch 36/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.3335 - accuracy: 0.9503\n",
      "Epoch 37/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.3259 - accuracy: 0.9627\n",
      "Epoch 38/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.3178 - accuracy: 0.9658\n",
      "Epoch 39/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.3134 - accuracy: 0.9565\n",
      "Epoch 40/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.3048 - accuracy: 0.9596\n",
      "Epoch 41/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.2991 - accuracy: 0.9596\n",
      "Epoch 42/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.2938 - accuracy: 0.9752\n",
      "Epoch 43/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.2889 - accuracy: 0.9627\n",
      "Epoch 44/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.2825 - accuracy: 0.9627\n",
      "Epoch 45/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.2771 - accuracy: 0.9627\n",
      "Epoch 46/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.2706 - accuracy: 0.9658\n",
      "Epoch 47/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.2651 - accuracy: 0.9689\n",
      "Epoch 48/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.2599 - accuracy: 0.9720\n",
      "Epoch 49/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.2549 - accuracy: 0.9720\n",
      "Epoch 50/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.2494 - accuracy: 0.9720\n",
      "Epoch 51/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.2442 - accuracy: 0.9720\n",
      "Epoch 52/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.2404 - accuracy: 0.9689\n",
      "Epoch 53/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.2357 - accuracy: 0.9845\n",
      "Epoch 54/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.2305 - accuracy: 0.9876\n",
      "Epoch 55/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.2270 - accuracy: 0.9689\n",
      "Epoch 56/100\n",
      "322/322 [==============================] - 0s 71us/step - loss: 0.2214 - accuracy: 0.9783\n",
      "Epoch 57/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.2165 - accuracy: 0.9876\n",
      "Epoch 58/100\n",
      "322/322 [==============================] - 0s 78us/step - loss: 0.2122 - accuracy: 0.9876\n",
      "Epoch 59/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.2078 - accuracy: 0.9845\n",
      "Epoch 60/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.2041 - accuracy: 0.9845\n",
      "Epoch 61/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.2006 - accuracy: 0.9845\n",
      "Epoch 62/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1957 - accuracy: 0.9907\n",
      "Epoch 63/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1929 - accuracy: 0.9814\n",
      "Epoch 64/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.1896 - accuracy: 0.9876\n",
      "Epoch 65/100\n",
      "322/322 [==============================] - 0s 75us/step - loss: 0.1848 - accuracy: 0.9907\n",
      "Epoch 66/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1819 - accuracy: 0.9876\n",
      "Epoch 67/100\n",
      "322/322 [==============================] - 0s 81us/step - loss: 0.1782 - accuracy: 0.9907\n",
      "Epoch 68/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1752 - accuracy: 0.9938\n",
      "Epoch 69/100\n",
      "322/322 [==============================] - 0s 71us/step - loss: 0.1718 - accuracy: 0.9938\n",
      "Epoch 70/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1705 - accuracy: 0.9907\n",
      "Epoch 71/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1775 - accuracy: 0.9814\n",
      "Epoch 72/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1701 - accuracy: 0.9814\n",
      "Epoch 73/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1638 - accuracy: 0.9876\n",
      "Epoch 74/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1571 - accuracy: 0.9969\n",
      "Epoch 75/100\n",
      "322/322 [==============================] - 0s 112us/step - loss: 0.1582 - accuracy: 0.9907\n",
      "Epoch 76/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.1532 - accuracy: 0.9969\n",
      "Epoch 77/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1510 - accuracy: 0.9907\n",
      "Epoch 78/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.1481 - accuracy: 0.9938\n",
      "Epoch 79/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1458 - accuracy: 0.9969\n",
      "Epoch 80/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.1567 - accuracy: 0.9845\n",
      "Epoch 81/100\n",
      "322/322 [==============================] - 0s 112us/step - loss: 0.1455 - accuracy: 0.9876\n",
      "Epoch 82/100\n",
      "322/322 [==============================] - 0s 118us/step - loss: 0.1424 - accuracy: 0.9907\n",
      "Epoch 83/100\n",
      "322/322 [==============================] - 0s 112us/step - loss: 0.1395 - accuracy: 0.9938\n",
      "Epoch 84/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.1361 - accuracy: 0.9938\n",
      "Epoch 85/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.1345 - accuracy: 0.9969\n",
      "Epoch 86/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.1320 - accuracy: 0.9969\n",
      "Epoch 87/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.1304 - accuracy: 0.9969\n",
      "Epoch 88/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1285 - accuracy: 0.9969\n",
      "Epoch 89/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.1269 - accuracy: 0.9969\n",
      "Epoch 90/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1251 - accuracy: 0.9969\n",
      "Epoch 91/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.1234 - accuracy: 0.9969\n",
      "Epoch 92/100\n",
      "322/322 [==============================] - 0s 96us/step - loss: 0.1218 - accuracy: 0.9969\n",
      "Epoch 93/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1202 - accuracy: 0.9969\n",
      "Epoch 94/100\n",
      "322/322 [==============================] - 0s 84us/step - loss: 0.1194 - accuracy: 0.9969\n",
      "Epoch 95/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1175 - accuracy: 0.9969\n",
      "Epoch 96/100\n",
      "322/322 [==============================] - 0s 87us/step - loss: 0.1161 - accuracy: 0.9938\n",
      "Epoch 97/100\n",
      "322/322 [==============================] - 0s 99us/step - loss: 0.1146 - accuracy: 0.9969\n",
      "Epoch 98/100\n",
      "322/322 [==============================] - 0s 90us/step - loss: 0.1129 - accuracy: 0.9938\n",
      "Epoch 99/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1117 - accuracy: 0.9938\n",
      "Epoch 100/100\n",
      "322/322 [==============================] - 0s 93us/step - loss: 0.1102 - accuracy: 0.9969\n",
      "161/161 [==============================] - 0s 833us/step\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.T\n",
    "y_train = y_train.T\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100) # epoch -> Number of Iteration\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3) # Cross validation score\n",
    "mean = accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98757762 0.97515529 0.93788821]\n",
      "Accuracy mean : 0.9668737053871155\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)\n",
    "print(\"Accuracy mean :\",mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
