{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mochammad Rafii Nanda Wicaksana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09011281823053"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial Neural Network\n",
    "Pada Assassinations Dataset\n",
    "\n",
    "Sumber : https://www.kaggle.com/tmtdmr/ann-on-assassinations-dataset\n",
    "\n",
    "Di kernel ini akan membandingkan algoritma Keras Classifier untuk berbagai nilai \"Numbers of ANN\", \"CV\" dan \"epochs\" dan menebak \"jenis kelamin\" orang yang meninggal karena pembunuhan.\n",
    "\n",
    "CONTENT\n",
    "\n",
    "1. Data Cleaning\n",
    "2. Normalization\n",
    "3. Train Test Split\n",
    "4. Build to 2 Layer Neural Network\n",
    "5. Build ANN from Keras for different hyperparameters\n",
    "6. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/LENOVO/Documents/JUPYTER KECERDASAN BUATAN/Assassinations Dataset/master.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menurunkan kolom nul dan non numerik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.drop([\"age\",\"country\",\"country-year\",\"generation\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengubah pria dan wanita menjadi 1 dan 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sex = [1 if each == \"male\" else 0 for each in data.sex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menghapus jarak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus jarak\n",
    "data.rename(columns={' gdp_for_year ($) ':'gdp_year'}, inplace=True)\n",
    "data.rename(columns={'HDI for year':'HDI_year'}, inplace=True)\n",
    "data.rename(columns={'suicides/100k pop':'suicides/100k_pop'}, inplace=True)\n",
    "data.rename(columns={'gdp_per_capita ($)':'gdp_per_capita_dollar'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menghapus koma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gdp_year = data.gdp_year.str.replace(',','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengidentifikasikan x dan y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.sex\n",
    "x_data = data.drop([\"sex\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konversi jenis kolom keenam dari string ke float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.gdp_year = data.gdp_year.apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proses normalisasi untuk memodifikasi nilai dalam varabel sehingga dapat mengukurnya dalam skala umum. Beberapa bentuk normalisasi yang paling umum bertujuan untuk mengubah nilai-nilai sehingga jumlahnya menjadi 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x_data - np.min(x_data)) / (np.max(x_data) - np.min(x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya yaitu membagi data set menjadi data train dan data test\n",
    "\n",
    "Training set adalah bagian dataset yang kita latih untuk membuat prediksi atau menjalankan fungsi dari sebuah algoritma ML. Kita memberikan petunjuk melalui algoritma agar mesin yang kita latih bisa mencari korelasinya sendiri atau belajar pola dari data yang diberikan.\n",
    "\n",
    "Test set adalah bagian dataset yang kita tes untuk melihat keakuratannya, atau dengan kata lain melihat performanya.\n",
    "\n",
    "Biasanya sebagai rule of thumb (aturan umum) proporsi test set sebesar 20% dan train set 80%. Namun ada juga yang menentukan 25:75, terserah yang mana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membagi data train dan test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.15, random_state = 42)\n",
    "\n",
    "x_train = x_train.values.T\n",
    "x_test = x_test.values.T\n",
    "y_test = y_test.values.reshape(1,y_test.shape[0])\n",
    "y_train = y_train.values.reshape(1,y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z))\n",
    "    return y_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menginisialisasi parameter dan ukuran lapisan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_and_layer_sizes_NN(x_train, y_train):\n",
    "    parameters = {\"weight1\": np.random.randn(3,x_train.shape[0]) * 0.1,\n",
    "                  \"bias1\": np.zeros((3,1)),\n",
    "                  \"weight2\": np.random.randn(y_train.shape[0],3) * 0.1,\n",
    "                  \"bias2\": np.zeros((y_train.shape[0],1))}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward propagation adalah proses dimana kita membawa data pada input melewati tiap neuron pada hidden layer sampai kepada output layer yang nanti akan dihitung errornya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_NN(x_train, parameters):\n",
    "\n",
    "    Z1 = np.dot(parameters[\"weight1\"],x_train) +parameters[\"bias1\"]\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(parameters[\"weight2\"],A1) + parameters[\"bias2\"]\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_NN(A2, Y, parameters):\n",
    "    logprobs = np.multiply(np.log(A2),Y)\n",
    "    cost = -np.sum(logprobs)/Y.shape[1]\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation adalah algoritma pembelajaran untuk memperkecil tingkat error dengan cara menyesuaikan bobotnya berdasarkan perbedaan output dan target yang diinginkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation_NN(parameters, cache, X, Y):\n",
    "\n",
    "    dZ2 = cache[\"A2\"]-Y\n",
    "    dW2 = np.dot(dZ2,cache[\"A1\"].T)/X.shape[1]\n",
    "    db2 = np.sum(dZ2,axis =1,keepdims=True)/X.shape[1]\n",
    "    dZ1 = np.dot(parameters[\"weight2\"].T,dZ2)*(1 - np.power(cache[\"A1\"], 2))\n",
    "    dW1 = np.dot(dZ1,X.T)/X.shape[1]\n",
    "    db1 = np.sum(dZ1,axis =1,keepdims=True)/X.shape[1]\n",
    "    grads = {\"dweight1\": dW1,\n",
    "             \"dbias1\": db1,\n",
    "             \"dweight2\": dW2,\n",
    "             \"dbias2\": db2}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_NN(parameters, grads, learning_rate = 0.01):\n",
    "    parameters = {\"weight1\": parameters[\"weight1\"]-learning_rate*grads[\"dweight1\"],\n",
    "                  \"bias1\": parameters[\"bias1\"]-learning_rate*grads[\"dbias1\"],\n",
    "                  \"weight2\": parameters[\"weight2\"]-learning_rate*grads[\"dweight2\"],\n",
    "                  \"bias2\": parameters[\"bias2\"]-learning_rate*grads[\"dbias2\"]}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_NN(parameters,x_test):\n",
    "    # x_test is a input for forward propagation\n",
    "    A2, cache = forward_propagation_NN(x_test,parameters)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n",
    "    for i in range(A2.shape[1]):\n",
    "        if A2[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build to 2 Layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.349240\n",
      "Cost after iteration 100: 0.348384\n",
      "Cost after iteration 200: 0.347729\n",
      "Cost after iteration 300: 0.347226\n",
      "Cost after iteration 400: 0.346840\n",
      "Cost after iteration 500: 0.346543\n",
      "Cost after iteration 600: 0.346314\n",
      "Cost after iteration 700: 0.346136\n",
      "Cost after iteration 800: 0.345997\n",
      "Cost after iteration 900: 0.345888\n",
      "Cost after iteration 1000: 0.345801\n",
      "Cost after iteration 1100: 0.345732\n",
      "Cost after iteration 1200: 0.345675\n",
      "Cost after iteration 1300: 0.345628\n",
      "Cost after iteration 1400: 0.345588\n",
      "Cost after iteration 1500: 0.345553\n",
      "Cost after iteration 1600: 0.345522\n",
      "Cost after iteration 1700: 0.345493\n",
      "Cost after iteration 1800: 0.345467\n",
      "Cost after iteration 1900: 0.345441\n",
      "Cost after iteration 2000: 0.345417\n",
      "Cost after iteration 2100: 0.345392\n",
      "Cost after iteration 2200: 0.345368\n",
      "Cost after iteration 2300: 0.345344\n",
      "Cost after iteration 2400: 0.345318\n",
      "Cost after iteration 2500: 0.345293\n",
      "Cost after iteration 2600: 0.345267\n",
      "Cost after iteration 2700: 0.345239\n",
      "Cost after iteration 2800: 0.345211\n",
      "Cost after iteration 2900: 0.345182\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f1b155588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 59.136306090870725 %\n",
      "test accuracy: 55.93625498007968 %\n"
     ]
    }
   ],
   "source": [
    "def two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations):\n",
    "    cost_list = []\n",
    "    index_list = []\n",
    "    #initialize parameters and layer sizes\n",
    "    parameters = initialize_parameters_and_layer_sizes_NN(x_train, y_train)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "         # forward propagation\n",
    "        A2, cache = forward_propagation_NN(x_train,parameters)\n",
    "        # compute cost\n",
    "        cost = compute_cost_NN(A2, y_train, parameters)\n",
    "         # backward propagation\n",
    "        grads = backward_propagation_NN(parameters, cache, x_train, y_train)\n",
    "         # update parameters\n",
    "        parameters = update_parameters_NN(parameters, grads)\n",
    "      \n",
    "        if i % 100 == 0:\n",
    "            cost_list.append(cost)\n",
    "            index_list.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))    \n",
    "    plt.plot(index_list,cost_list)\n",
    "    plt.xticks(index_list,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # predict\n",
    "    y_prediction_test = predict_NN(parameters,x_test)\n",
    "    y_prediction_train = predict_NN(parameters,x_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    return parameters\n",
    "\n",
    "parameters = two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah menggunakan 2 Layer Neural Network didapat hasil data train memiliki akurasi sebesar 59% dan data tes memiliki akurasi sebesar 55%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membentuk kembali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ubah kembali data yang sudah di proses menjadi semula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = x_train.T, x_test.T, y_train.T, y_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Build ANN From Keras for Different Hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengevaluasi ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menggunakan ANN untuk menentukan besar akurasi data train dan test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4739/4739 [==============================] - 0s 57us/step - loss: 0.6931 - accuracy: 0.5039\n",
      "Epoch 2/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.6870 - accuracy: 0.6202\n",
      "Epoch 3/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.6570 - accuracy: 0.7031\n",
      "Epoch 4/100\n",
      "4739/4739 [==============================] - 0s 42us/step - loss: 0.6126 - accuracy: 0.7253\n",
      "Epoch 5/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5813 - accuracy: 0.7253\n",
      "Epoch 6/100\n",
      "4739/4739 [==============================] - 0s 40us/step - loss: 0.5636 - accuracy: 0.7324\n",
      "Epoch 7/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5552 - accuracy: 0.7318\n",
      "Epoch 8/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5509 - accuracy: 0.7329\n",
      "Epoch 9/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5501 - accuracy: 0.7337\n",
      "Epoch 10/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5479 - accuracy: 0.7303\n",
      "Epoch 11/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5485 - accuracy: 0.7343\n",
      "Epoch 12/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5472 - accuracy: 0.7331\n",
      "Epoch 13/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5476 - accuracy: 0.7333\n",
      "Epoch 14/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5471 - accuracy: 0.7354\n",
      "Epoch 15/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5469 - accuracy: 0.7318\n",
      "Epoch 16/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5471 - accuracy: 0.7324\n",
      "Epoch 17/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5467 - accuracy: 0.7350\n",
      "Epoch 18/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5468 - accuracy: 0.7333\n",
      "Epoch 19/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5465 - accuracy: 0.7348\n",
      "Epoch 20/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5467 - accuracy: 0.7356\n",
      "Epoch 21/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5464 - accuracy: 0.7329\n",
      "Epoch 22/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5459 - accuracy: 0.7348\n",
      "Epoch 23/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5464 - accuracy: 0.7339\n",
      "Epoch 24/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5465 - accuracy: 0.7348\n",
      "Epoch 25/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5458 - accuracy: 0.7354\n",
      "Epoch 26/100\n",
      "4739/4739 [==============================] - 0s 29us/step - loss: 0.5456 - accuracy: 0.7348\n",
      "Epoch 27/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5460 - accuracy: 0.7356\n",
      "Epoch 28/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5456 - accuracy: 0.7362\n",
      "Epoch 29/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5459 - accuracy: 0.7329\n",
      "Epoch 30/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5455 - accuracy: 0.7341\n",
      "Epoch 31/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5454 - accuracy: 0.7335\n",
      "Epoch 32/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5457 - accuracy: 0.7343\n",
      "Epoch 33/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5457 - accuracy: 0.7367\n",
      "Epoch 34/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5451 - accuracy: 0.7348\n",
      "Epoch 35/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5457 - accuracy: 0.7339\n",
      "Epoch 36/100\n",
      "4739/4739 [==============================] - 0s 29us/step - loss: 0.5456 - accuracy: 0.7339\n",
      "Epoch 37/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5457 - accuracy: 0.7352\n",
      "Epoch 38/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5458 - accuracy: 0.7354\n",
      "Epoch 39/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5463 - accuracy: 0.7339\n",
      "Epoch 40/100\n",
      "4739/4739 [==============================] - 0s 29us/step - loss: 0.5455 - accuracy: 0.7348\n",
      "Epoch 41/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5451 - accuracy: 0.7364\n",
      "Epoch 42/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5449 - accuracy: 0.7362\n",
      "Epoch 43/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5452 - accuracy: 0.7356\n",
      "Epoch 44/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5455 - accuracy: 0.7367\n",
      "Epoch 45/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5450 - accuracy: 0.7343\n",
      "Epoch 46/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5456 - accuracy: 0.7322\n",
      "Epoch 47/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5452 - accuracy: 0.7352\n",
      "Epoch 48/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5453 - accuracy: 0.7341\n",
      "Epoch 49/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5451 - accuracy: 0.7373\n",
      "Epoch 50/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5450 - accuracy: 0.7362\n",
      "Epoch 51/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5454 - accuracy: 0.7375\n",
      "Epoch 52/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5453 - accuracy: 0.7375\n",
      "Epoch 53/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5452 - accuracy: 0.7337\n",
      "Epoch 54/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5453 - accuracy: 0.7375\n",
      "Epoch 55/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5449 - accuracy: 0.7341\n",
      "Epoch 56/100\n",
      "4739/4739 [==============================] - 0s 41us/step - loss: 0.5449 - accuracy: 0.7360\n",
      "Epoch 57/100\n",
      "4739/4739 [==============================] - 0s 44us/step - loss: 0.5450 - accuracy: 0.7350\n",
      "Epoch 58/100\n",
      "4739/4739 [==============================] - 0s 40us/step - loss: 0.5450 - accuracy: 0.7367\n",
      "Epoch 59/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5448 - accuracy: 0.7356\n",
      "Epoch 60/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5449 - accuracy: 0.7356\n",
      "Epoch 61/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5450 - accuracy: 0.7364\n",
      "Epoch 62/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5446 - accuracy: 0.7369\n",
      "Epoch 63/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5447 - accuracy: 0.7356\n",
      "Epoch 64/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5454 - accuracy: 0.7348\n",
      "Epoch 65/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5447 - accuracy: 0.7375\n",
      "Epoch 66/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5444 - accuracy: 0.7381\n",
      "Epoch 67/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5448 - accuracy: 0.7371\n",
      "Epoch 68/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5446 - accuracy: 0.7371\n",
      "Epoch 69/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5441 - accuracy: 0.7350\n",
      "Epoch 70/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5445 - accuracy: 0.7358\n",
      "Epoch 71/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5443 - accuracy: 0.7362\n",
      "Epoch 72/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5443 - accuracy: 0.7360\n",
      "Epoch 73/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5442 - accuracy: 0.7369\n",
      "Epoch 74/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5442 - accuracy: 0.7348\n",
      "Epoch 75/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5438 - accuracy: 0.7362\n",
      "Epoch 76/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5439 - accuracy: 0.7367\n",
      "Epoch 77/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5444 - accuracy: 0.7379\n",
      "Epoch 78/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5440 - accuracy: 0.7373\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5434 - accuracy: 0.7381\n",
      "Epoch 80/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5439 - accuracy: 0.7371\n",
      "Epoch 81/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5437 - accuracy: 0.7362\n",
      "Epoch 82/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5435 - accuracy: 0.7400\n",
      "Epoch 83/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5442 - accuracy: 0.7352\n",
      "Epoch 84/100\n",
      "4739/4739 [==============================] - 0s 40us/step - loss: 0.5442 - accuracy: 0.7348\n",
      "Epoch 85/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5436 - accuracy: 0.7360\n",
      "Epoch 86/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5435 - accuracy: 0.7371\n",
      "Epoch 87/100\n",
      "4739/4739 [==============================] - 0s 39us/step - loss: 0.5435 - accuracy: 0.7373\n",
      "Epoch 88/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5425 - accuracy: 0.7348\n",
      "Epoch 89/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5436 - accuracy: 0.7383\n",
      "Epoch 90/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5430 - accuracy: 0.7394\n",
      "Epoch 91/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5433 - accuracy: 0.7360\n",
      "Epoch 92/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5432 - accuracy: 0.7375\n",
      "Epoch 93/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5434 - accuracy: 0.7367\n",
      "Epoch 94/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5429 - accuracy: 0.7375\n",
      "Epoch 95/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5431 - accuracy: 0.7381\n",
      "Epoch 96/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5432 - accuracy: 0.7360\n",
      "Epoch 97/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5429 - accuracy: 0.7373\n",
      "Epoch 98/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5429 - accuracy: 0.7369\n",
      "Epoch 99/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5431 - accuracy: 0.7375\n",
      "Epoch 100/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5431 - accuracy: 0.7381\n",
      "2370/2370 [==============================] - 0s 24us/step\n",
      "Epoch 1/100\n",
      "4739/4739 [==============================] - 0s 48us/step - loss: 0.6932 - accuracy: 0.5016\n",
      "Epoch 2/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.6916 - accuracy: 0.5539\n",
      "Epoch 3/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.6838 - accuracy: 0.5938\n",
      "Epoch 4/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.6710 - accuracy: 0.6375\n",
      "Epoch 5/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.6509 - accuracy: 0.6879\n",
      "Epoch 6/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.6162 - accuracy: 0.7126\n",
      "Epoch 7/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5874 - accuracy: 0.7236\n",
      "Epoch 8/100\n",
      "4739/4739 [==============================] - 0s 39us/step - loss: 0.5710 - accuracy: 0.7261\n",
      "Epoch 9/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5624 - accuracy: 0.7282\n",
      "Epoch 10/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5592 - accuracy: 0.7307\n",
      "Epoch 11/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5565 - accuracy: 0.7280\n",
      "Epoch 12/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5528 - accuracy: 0.7343\n",
      "Epoch 13/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5516 - accuracy: 0.7329\n",
      "Epoch 14/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5509 - accuracy: 0.7350\n",
      "Epoch 15/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5501 - accuracy: 0.7360\n",
      "Epoch 16/100\n",
      "4739/4739 [==============================] - 0s 41us/step - loss: 0.5496 - accuracy: 0.7345\n",
      "Epoch 17/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5491 - accuracy: 0.7358\n",
      "Epoch 18/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5489 - accuracy: 0.7348\n",
      "Epoch 19/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5487 - accuracy: 0.7354\n",
      "Epoch 20/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5478 - accuracy: 0.7352\n",
      "Epoch 21/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5479 - accuracy: 0.7369\n",
      "Epoch 22/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5477 - accuracy: 0.7371\n",
      "Epoch 23/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5476 - accuracy: 0.7350\n",
      "Epoch 24/100\n",
      "4739/4739 [==============================] - 0s 41us/step - loss: 0.5466 - accuracy: 0.7343\n",
      "Epoch 25/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5460 - accuracy: 0.7373\n",
      "Epoch 26/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5459 - accuracy: 0.7356\n",
      "Epoch 27/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5451 - accuracy: 0.7364\n",
      "Epoch 28/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5451 - accuracy: 0.7383\n",
      "Epoch 29/100\n",
      "4739/4739 [==============================] - 0s 42us/step - loss: 0.5450 - accuracy: 0.7362\n",
      "Epoch 30/100\n",
      "4739/4739 [==============================] - 0s 40us/step - loss: 0.5444 - accuracy: 0.7360\n",
      "Epoch 31/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5450 - accuracy: 0.7369\n",
      "Epoch 32/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5448 - accuracy: 0.7373\n",
      "Epoch 33/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5443 - accuracy: 0.7358\n",
      "Epoch 34/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5442 - accuracy: 0.7343\n",
      "Epoch 35/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5440 - accuracy: 0.7367\n",
      "Epoch 36/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5440 - accuracy: 0.7402\n",
      "Epoch 37/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5437 - accuracy: 0.7345\n",
      "Epoch 38/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5438 - accuracy: 0.7362\n",
      "Epoch 39/100\n",
      "4739/4739 [==============================] - 0s 40us/step - loss: 0.5436 - accuracy: 0.7369\n",
      "Epoch 40/100\n",
      "4739/4739 [==============================] - 0s 42us/step - loss: 0.5436 - accuracy: 0.7364\n",
      "Epoch 41/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5432 - accuracy: 0.7350\n",
      "Epoch 42/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5433 - accuracy: 0.7371\n",
      "Epoch 43/100\n",
      "4739/4739 [==============================] - 0s 39us/step - loss: 0.5427 - accuracy: 0.7371\n",
      "Epoch 44/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5431 - accuracy: 0.7356\n",
      "Epoch 45/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5427 - accuracy: 0.7369\n",
      "Epoch 46/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5430 - accuracy: 0.7383\n",
      "Epoch 47/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5429 - accuracy: 0.7392\n",
      "Epoch 48/100\n",
      "4739/4739 [==============================] - 0s 40us/step - loss: 0.5431 - accuracy: 0.7367\n",
      "Epoch 49/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5426 - accuracy: 0.7373\n",
      "Epoch 50/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5434 - accuracy: 0.7362\n",
      "Epoch 51/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5434 - accuracy: 0.7379\n",
      "Epoch 52/100\n",
      "4739/4739 [==============================] - 0s 29us/step - loss: 0.5430 - accuracy: 0.7381\n",
      "Epoch 53/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5427 - accuracy: 0.7392\n",
      "Epoch 54/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5429 - accuracy: 0.7360\n",
      "Epoch 55/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5429 - accuracy: 0.7362\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5427 - accuracy: 0.7369\n",
      "Epoch 57/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5420 - accuracy: 0.7375\n",
      "Epoch 58/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5435 - accuracy: 0.7369\n",
      "Epoch 59/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5421 - accuracy: 0.7362\n",
      "Epoch 60/100\n",
      "4739/4739 [==============================] - 0s 31us/step - loss: 0.5425 - accuracy: 0.7352\n",
      "Epoch 61/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5421 - accuracy: 0.7364\n",
      "Epoch 62/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5422 - accuracy: 0.7373\n",
      "Epoch 63/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5427 - accuracy: 0.7354\n",
      "Epoch 64/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5421 - accuracy: 0.7360\n",
      "Epoch 65/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5412 - accuracy: 0.7348\n",
      "Epoch 66/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5434 - accuracy: 0.7333\n",
      "Epoch 67/100\n",
      "4739/4739 [==============================] - 0s 34us/step - loss: 0.5422 - accuracy: 0.7373\n",
      "Epoch 68/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5424 - accuracy: 0.7369\n",
      "Epoch 69/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5416 - accuracy: 0.7383\n",
      "Epoch 70/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5423 - accuracy: 0.7360\n",
      "Epoch 71/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5415 - accuracy: 0.7356\n",
      "Epoch 72/100\n",
      "4739/4739 [==============================] - 0s 43us/step - loss: 0.5416 - accuracy: 0.7386\n",
      "Epoch 73/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5413 - accuracy: 0.7364\n",
      "Epoch 74/100\n",
      "4739/4739 [==============================] - 0s 40us/step - loss: 0.5414 - accuracy: 0.7392\n",
      "Epoch 75/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5408 - accuracy: 0.7364\n",
      "Epoch 76/100\n",
      "4739/4739 [==============================] - 0s 39us/step - loss: 0.5413 - accuracy: 0.7339\n",
      "Epoch 77/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5415 - accuracy: 0.7358\n",
      "Epoch 78/100\n",
      "4739/4739 [==============================] - 0s 42us/step - loss: 0.5417 - accuracy: 0.7371\n",
      "Epoch 79/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5413 - accuracy: 0.7367\n",
      "Epoch 80/100\n",
      "4739/4739 [==============================] - 0s 43us/step - loss: 0.5410 - accuracy: 0.7377\n",
      "Epoch 81/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5420 - accuracy: 0.7356\n",
      "Epoch 82/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5412 - accuracy: 0.7369\n",
      "Epoch 83/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5407 - accuracy: 0.7369\n",
      "Epoch 84/100\n",
      "4739/4739 [==============================] - 0s 30us/step - loss: 0.5417 - accuracy: 0.7354\n",
      "Epoch 85/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5405 - accuracy: 0.7377\n",
      "Epoch 86/100\n",
      "4739/4739 [==============================] - 0s 39us/step - loss: 0.5407 - accuracy: 0.7373\n",
      "Epoch 87/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5403 - accuracy: 0.7379\n",
      "Epoch 88/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5407 - accuracy: 0.7367\n",
      "Epoch 89/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5404 - accuracy: 0.7379\n",
      "Epoch 90/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5404 - accuracy: 0.7375\n",
      "Epoch 91/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5408 - accuracy: 0.7383\n",
      "Epoch 92/100\n",
      "4739/4739 [==============================] - 0s 40us/step - loss: 0.5408 - accuracy: 0.7371\n",
      "Epoch 93/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5404 - accuracy: 0.7375\n",
      "Epoch 94/100\n",
      "4739/4739 [==============================] - 0s 36us/step - loss: 0.5402 - accuracy: 0.7360\n",
      "Epoch 95/100\n",
      "4739/4739 [==============================] - 0s 38us/step - loss: 0.5401 - accuracy: 0.7375\n",
      "Epoch 96/100\n",
      "4739/4739 [==============================] - 0s 35us/step - loss: 0.5402 - accuracy: 0.7381\n",
      "Epoch 97/100\n",
      "4739/4739 [==============================] - 0s 42us/step - loss: 0.5402 - accuracy: 0.7371\n",
      "Epoch 98/100\n",
      "4739/4739 [==============================] - 0s 33us/step - loss: 0.5400 - accuracy: 0.7371\n",
      "Epoch 99/100\n",
      "4739/4739 [==============================] - 0s 32us/step - loss: 0.5402 - accuracy: 0.7388\n",
      "Epoch 100/100\n",
      "4739/4739 [==============================] - 0s 37us/step - loss: 0.5399 - accuracy: 0.7367\n",
      "2370/2370 [==============================] - 0s 25us/step\n",
      "Epoch 1/100\n",
      "4740/4740 [==============================] - 0s 52us/step - loss: 0.6932 - accuracy: 0.4863\n",
      "Epoch 2/100\n",
      "4740/4740 [==============================] - 0s 33us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 3/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 4/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 5/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 6/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 7/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 8/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 9/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6930 - accuracy: 0.5078\n",
      "Epoch 10/100\n",
      "4740/4740 [==============================] - 0s 33us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 11/100\n",
      "4740/4740 [==============================] - 0s 38us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 12/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 13/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 14/100\n",
      "4740/4740 [==============================] - 0s 37us/step - loss: 0.6930 - accuracy: 0.5078\n",
      "Epoch 15/100\n",
      "4740/4740 [==============================] - 0s 36us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 16/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 17/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 18/100\n",
      "4740/4740 [==============================] - 0s 30us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 19/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 20/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 21/100\n",
      "4740/4740 [==============================] - 0s 29us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 22/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 23/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 24/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 25/100\n",
      "4740/4740 [==============================] - 0s 33us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 26/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 27/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 28/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 29/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 30/100\n",
      "4740/4740 [==============================] - 0s 38us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 31/100\n",
      "4740/4740 [==============================] - 0s 37us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 32/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 34/100\n",
      "4740/4740 [==============================] - 0s 33us/step - loss: 0.6930 - accuracy: 0.5078\n",
      "Epoch 35/100\n",
      "4740/4740 [==============================] - 0s 37us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 36/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 37/100\n",
      "4740/4740 [==============================] - 0s 33us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 38/100\n",
      "4740/4740 [==============================] - 0s 41us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 39/100\n",
      "4740/4740 [==============================] - 0s 39us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 40/100\n",
      "4740/4740 [==============================] - 0s 36us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 41/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 42/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 43/100\n",
      "4740/4740 [==============================] - 0s 38us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 44/100\n",
      "4740/4740 [==============================] - 0s 37us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 45/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 46/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 47/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 48/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 49/100\n",
      "4740/4740 [==============================] - 0s 38us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 50/100\n",
      "4740/4740 [==============================] - 0s 39us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 51/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 52/100\n",
      "4740/4740 [==============================] - 0s 33us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 53/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 54/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 55/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 56/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 57/100\n",
      "4740/4740 [==============================] - 0s 30us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 58/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 59/100\n",
      "4740/4740 [==============================] - 0s 33us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 60/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 61/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 62/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 63/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 64/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 65/100\n",
      "4740/4740 [==============================] - 0s 30us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 66/100\n",
      "4740/4740 [==============================] - 0s 28us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 67/100\n",
      "4740/4740 [==============================] - 0s 37us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 68/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 69/100\n",
      "4740/4740 [==============================] - 0s 36us/step - loss: 0.6930 - accuracy: 0.5078\n",
      "Epoch 70/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 71/100\n",
      "4740/4740 [==============================] - 0s 36us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 72/100\n",
      "4740/4740 [==============================] - 0s 33us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 73/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6930 - accuracy: 0.5078\n",
      "Epoch 74/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 75/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 76/100\n",
      "4740/4740 [==============================] - 0s 28us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 77/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 78/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 79/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 80/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 81/100\n",
      "4740/4740 [==============================] - 0s 37us/step - loss: 0.6930 - accuracy: 0.5078\n",
      "Epoch 82/100\n",
      "4740/4740 [==============================] - 0s 37us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 83/100\n",
      "4740/4740 [==============================] - 0s 36us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 84/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 85/100\n",
      "4740/4740 [==============================] - 0s 38us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 86/100\n",
      "4740/4740 [==============================] - 0s 34us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 87/100\n",
      "4740/4740 [==============================] - 0s 30us/step - loss: 0.6930 - accuracy: 0.5078\n",
      "Epoch 88/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 89/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 90/100\n",
      "4740/4740 [==============================] - 0s 33us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 91/100\n",
      "4740/4740 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 92/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 93/100\n",
      "4740/4740 [==============================] - 0s 29us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 94/100\n",
      "4740/4740 [==============================] - 0s 30us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 95/100\n",
      "4740/4740 [==============================] - 0s 33us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 96/100\n",
      "4740/4740 [==============================] - 0s 31us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 97/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 98/100\n",
      "4740/4740 [==============================] - 0s 30us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 99/100\n",
      "4740/4740 [==============================] - 0s 32us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "Epoch 100/100\n",
      "4740/4740 [==============================] - 0s 30us/step - loss: 0.6931 - accuracy: 0.5078\n",
      "2369/2369 [==============================] - 0s 28us/step\n",
      "Accuracy mean: 0.6488734384377798\n",
      "Accuracy variance: 0.11229222642818\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library \n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1])) # we use dimension of x_train as input\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu')) # we use 4 nodes in first layer\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')) # if we use sigmoid function it means we add output layer\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) # we will use accuracy as metrics\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100) # epochs means that is number of iteration \n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_values = {'ANN_Num': [], 'CV': [],'epochs': [] , 'accuracy': [] }\n",
    "data_temproray = pd.DataFrame.from_dict(dict_of_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temproray.ANN_Num = [2]\n",
    "data_temproray.CV = [3]\n",
    "data_temproray.epochs = [100]\n",
    "data_temproray.accuracy = [0.6558003964712986]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANN_Num</th>\n",
       "      <th>CV</th>\n",
       "      <th>epochs</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANN_Num  CV  epochs  accuracy\n",
       "0        2   3     100    0.6558"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temproray.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5331/5331 [==============================] - 0s 46us/step - loss: 0.6930 - accuracy: 0.5059\n",
      "Epoch 2/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.6852 - accuracy: 0.6211\n",
      "Epoch 3/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.6475 - accuracy: 0.6907\n",
      "Epoch 4/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5988 - accuracy: 0.7201\n",
      "Epoch 5/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5706 - accuracy: 0.7239\n",
      "Epoch 6/150\n",
      "5331/5331 [==============================] - 0s 29us/step - loss: 0.5589 - accuracy: 0.7301\n",
      "Epoch 7/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5553 - accuracy: 0.7306\n",
      "Epoch 8/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5527 - accuracy: 0.7299\n",
      "Epoch 9/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5516 - accuracy: 0.7329\n",
      "Epoch 10/150\n",
      "5331/5331 [==============================] - 0s 35us/step - loss: 0.5510 - accuracy: 0.7319\n",
      "Epoch 11/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5510 - accuracy: 0.7329\n",
      "Epoch 12/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5502 - accuracy: 0.7308\n",
      "Epoch 13/150\n",
      "5331/5331 [==============================] - 0s 29us/step - loss: 0.5502 - accuracy: 0.7308\n",
      "Epoch 14/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5500 - accuracy: 0.7291\n",
      "Epoch 15/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5493 - accuracy: 0.7289\n",
      "Epoch 16/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5490 - accuracy: 0.7310\n",
      "Epoch 17/150\n",
      "5331/5331 [==============================] - 0s 35us/step - loss: 0.5493 - accuracy: 0.7297\n",
      "Epoch 18/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5496 - accuracy: 0.7304\n",
      "Epoch 19/150\n",
      "5331/5331 [==============================] - 0s 37us/step - loss: 0.5487 - accuracy: 0.7318\n",
      "Epoch 20/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5491 - accuracy: 0.7321\n",
      "Epoch 21/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5487 - accuracy: 0.7308\n",
      "Epoch 22/150\n",
      "5331/5331 [==============================] - 0s 37us/step - loss: 0.5489 - accuracy: 0.7304\n",
      "Epoch 23/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5480 - accuracy: 0.7306\n",
      "Epoch 24/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5483 - accuracy: 0.7319\n",
      "Epoch 25/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5474 - accuracy: 0.7314\n",
      "Epoch 26/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5487 - accuracy: 0.7303\n",
      "Epoch 27/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5483 - accuracy: 0.7331\n",
      "Epoch 28/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5477 - accuracy: 0.7338\n",
      "Epoch 29/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5479 - accuracy: 0.7331\n",
      "Epoch 30/150\n",
      "5331/5331 [==============================] - 0s 38us/step - loss: 0.5480 - accuracy: 0.7321\n",
      "Epoch 31/150\n",
      "5331/5331 [==============================] - 0s 39us/step - loss: 0.5482 - accuracy: 0.7314\n",
      "Epoch 32/150\n",
      "5331/5331 [==============================] - 0s 35us/step - loss: 0.5478 - accuracy: 0.7329\n",
      "Epoch 33/150\n",
      "5331/5331 [==============================] - 0s 37us/step - loss: 0.5477 - accuracy: 0.7308\n",
      "Epoch 34/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5478 - accuracy: 0.7316\n",
      "Epoch 35/150\n",
      "5331/5331 [==============================] - 0s 38us/step - loss: 0.5477 - accuracy: 0.7310\n",
      "Epoch 36/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5476 - accuracy: 0.7325\n",
      "Epoch 37/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5474 - accuracy: 0.7325\n",
      "Epoch 38/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5475 - accuracy: 0.7336\n",
      "Epoch 39/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5468 - accuracy: 0.7340\n",
      "Epoch 40/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5470 - accuracy: 0.7318\n",
      "Epoch 41/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5469 - accuracy: 0.7325\n",
      "Epoch 42/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5465 - accuracy: 0.7308\n",
      "Epoch 43/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5465 - accuracy: 0.7331\n",
      "Epoch 44/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5470 - accuracy: 0.7334\n",
      "Epoch 45/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5463 - accuracy: 0.7323\n",
      "Epoch 46/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5467 - accuracy: 0.7316\n",
      "Epoch 47/150\n",
      "5331/5331 [==============================] - 0s 37us/step - loss: 0.5466 - accuracy: 0.7321\n",
      "Epoch 48/150\n",
      "5331/5331 [==============================] - 0s 29us/step - loss: 0.5462 - accuracy: 0.7327\n",
      "Epoch 49/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5460 - accuracy: 0.7331\n",
      "Epoch 50/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5459 - accuracy: 0.7331\n",
      "Epoch 51/150\n",
      "5331/5331 [==============================] - 0s 35us/step - loss: 0.5457 - accuracy: 0.7333\n",
      "Epoch 52/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5460 - accuracy: 0.7346\n",
      "Epoch 53/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5458 - accuracy: 0.7333\n",
      "Epoch 54/150\n",
      "5331/5331 [==============================] - 0s 35us/step - loss: 0.5458 - accuracy: 0.7323\n",
      "Epoch 55/150\n",
      "5331/5331 [==============================] - 0s 37us/step - loss: 0.5459 - accuracy: 0.7355\n",
      "Epoch 56/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5457 - accuracy: 0.7342\n",
      "Epoch 57/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5456 - accuracy: 0.7340\n",
      "Epoch 58/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5457 - accuracy: 0.7310\n",
      "Epoch 59/150\n",
      "5331/5331 [==============================] - 0s 38us/step - loss: 0.5453 - accuracy: 0.7338\n",
      "Epoch 60/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5444 - accuracy: 0.7344\n",
      "Epoch 61/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5446 - accuracy: 0.7340\n",
      "Epoch 62/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5448 - accuracy: 0.7316\n",
      "Epoch 63/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5447 - accuracy: 0.7331\n",
      "Epoch 64/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5452 - accuracy: 0.7342\n",
      "Epoch 65/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5447 - accuracy: 0.7342\n",
      "Epoch 66/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5452 - accuracy: 0.7310\n",
      "Epoch 67/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5445 - accuracy: 0.7334\n",
      "Epoch 68/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5443 - accuracy: 0.7329\n",
      "Epoch 69/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5443 - accuracy: 0.7329\n",
      "Epoch 70/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5443 - accuracy: 0.7333\n",
      "Epoch 71/150\n",
      "5331/5331 [==============================] - 0s 35us/step - loss: 0.5442 - accuracy: 0.7357\n",
      "Epoch 72/150\n",
      "5331/5331 [==============================] - 0s 29us/step - loss: 0.5452 - accuracy: 0.7314\n",
      "Epoch 73/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5440 - accuracy: 0.7323\n",
      "Epoch 74/150\n",
      "5331/5331 [==============================] - 0s 35us/step - loss: 0.5439 - accuracy: 0.7325\n",
      "Epoch 75/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5439 - accuracy: 0.7329\n",
      "Epoch 76/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5440 - accuracy: 0.7359\n",
      "Epoch 77/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5441 - accuracy: 0.7336\n",
      "Epoch 78/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5447 - accuracy: 0.7319\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5438 - accuracy: 0.7316\n",
      "Epoch 80/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5438 - accuracy: 0.7314\n",
      "Epoch 81/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5434 - accuracy: 0.7316\n",
      "Epoch 82/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5436 - accuracy: 0.7334\n",
      "Epoch 83/150\n",
      "5331/5331 [==============================] - 0s 35us/step - loss: 0.5435 - accuracy: 0.7340\n",
      "Epoch 84/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5431 - accuracy: 0.7351\n",
      "Epoch 85/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5429 - accuracy: 0.7338\n",
      "Epoch 86/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5428 - accuracy: 0.7353\n",
      "Epoch 87/150\n",
      "5331/5331 [==============================] - 0s 35us/step - loss: 0.5431 - accuracy: 0.7333\n",
      "Epoch 88/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5430 - accuracy: 0.7318\n",
      "Epoch 89/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5428 - accuracy: 0.7338\n",
      "Epoch 90/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5429 - accuracy: 0.7325\n",
      "Epoch 91/150\n",
      "5331/5331 [==============================] - 0s 29us/step - loss: 0.5425 - accuracy: 0.7364\n",
      "Epoch 92/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5426 - accuracy: 0.7346\n",
      "Epoch 93/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5424 - accuracy: 0.7340\n",
      "Epoch 94/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5423 - accuracy: 0.7349\n",
      "Epoch 95/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5420 - accuracy: 0.7346\n",
      "Epoch 96/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5422 - accuracy: 0.7325\n",
      "Epoch 97/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5423 - accuracy: 0.7318\n",
      "Epoch 98/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5428 - accuracy: 0.7344\n",
      "Epoch 99/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5420 - accuracy: 0.7331\n",
      "Epoch 100/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5419 - accuracy: 0.7333\n",
      "Epoch 101/150\n",
      "5331/5331 [==============================] - 0s 35us/step - loss: 0.5417 - accuracy: 0.7346\n",
      "Epoch 102/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5417 - accuracy: 0.7334\n",
      "Epoch 103/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5419 - accuracy: 0.7329\n",
      "Epoch 104/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5415 - accuracy: 0.7342\n",
      "Epoch 105/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5411 - accuracy: 0.7321\n",
      "Epoch 106/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5416 - accuracy: 0.7338\n",
      "Epoch 107/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5415 - accuracy: 0.7323\n",
      "Epoch 108/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5411 - accuracy: 0.7336\n",
      "Epoch 109/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5412 - accuracy: 0.7323\n",
      "Epoch 110/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5409 - accuracy: 0.7318\n",
      "Epoch 111/150\n",
      "5331/5331 [==============================] - 0s 28us/step - loss: 0.5405 - accuracy: 0.7318\n",
      "Epoch 112/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5410 - accuracy: 0.7342\n",
      "Epoch 113/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5410 - accuracy: 0.7319\n",
      "Epoch 114/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5411 - accuracy: 0.7329\n",
      "Epoch 115/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5415 - accuracy: 0.7331\n",
      "Epoch 116/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5403 - accuracy: 0.7316\n",
      "Epoch 117/150\n",
      "5331/5331 [==============================] - 0s 39us/step - loss: 0.5403 - accuracy: 0.7340\n",
      "Epoch 118/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5409 - accuracy: 0.7357\n",
      "Epoch 119/150\n",
      "5331/5331 [==============================] - 0s 29us/step - loss: 0.5403 - accuracy: 0.7303\n",
      "Epoch 120/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5406 - accuracy: 0.7323\n",
      "Epoch 121/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5400 - accuracy: 0.7321\n",
      "Epoch 122/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5399 - accuracy: 0.7336\n",
      "Epoch 123/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5400 - accuracy: 0.7336\n",
      "Epoch 124/150\n",
      "5331/5331 [==============================] - 0s 27us/step - loss: 0.5400 - accuracy: 0.7319\n",
      "Epoch 125/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5397 - accuracy: 0.7340\n",
      "Epoch 126/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5396 - accuracy: 0.7349\n",
      "Epoch 127/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5406 - accuracy: 0.7318\n",
      "Epoch 128/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5398 - accuracy: 0.7340\n",
      "Epoch 129/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5400 - accuracy: 0.7304\n",
      "Epoch 130/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5390 - accuracy: 0.7346\n",
      "Epoch 131/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5395 - accuracy: 0.7327\n",
      "Epoch 132/150\n",
      "5331/5331 [==============================] - 0s 35us/step - loss: 0.5391 - accuracy: 0.7331\n",
      "Epoch 133/150\n",
      "5331/5331 [==============================] - 0s 30us/step - loss: 0.5390 - accuracy: 0.7329\n",
      "Epoch 134/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5387 - accuracy: 0.7319\n",
      "Epoch 135/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5386 - accuracy: 0.7321\n",
      "Epoch 136/150\n",
      "5331/5331 [==============================] - 0s 32us/step - loss: 0.5396 - accuracy: 0.7306\n",
      "Epoch 137/150\n",
      "5331/5331 [==============================] - 0s 29us/step - loss: 0.5390 - accuracy: 0.7349\n",
      "Epoch 138/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5389 - accuracy: 0.7346\n",
      "Epoch 139/150\n",
      "5331/5331 [==============================] - 0s 28us/step - loss: 0.5388 - accuracy: 0.7346\n",
      "Epoch 140/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5383 - accuracy: 0.7334\n",
      "Epoch 141/150\n",
      "5331/5331 [==============================] - 0s 28us/step - loss: 0.5389 - accuracy: 0.7312\n",
      "Epoch 142/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5388 - accuracy: 0.7325\n",
      "Epoch 143/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5384 - accuracy: 0.7331\n",
      "Epoch 144/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5387 - accuracy: 0.7334\n",
      "Epoch 145/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5382 - accuracy: 0.7334\n",
      "Epoch 146/150\n",
      "5331/5331 [==============================] - 0s 36us/step - loss: 0.5380 - accuracy: 0.7338\n",
      "Epoch 147/150\n",
      "5331/5331 [==============================] - 0s 33us/step - loss: 0.5381 - accuracy: 0.7331\n",
      "Epoch 148/150\n",
      "5331/5331 [==============================] - 0s 31us/step - loss: 0.5381 - accuracy: 0.7308\n",
      "Epoch 149/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5382 - accuracy: 0.7325\n",
      "Epoch 150/150\n",
      "5331/5331 [==============================] - 0s 34us/step - loss: 0.5384 - accuracy: 0.7344\n",
      "1778/1778 [==============================] - 0s 30us/step\n",
      "Epoch 1/150\n",
      "5332/5332 [==============================] - 0s 47us/step - loss: 0.6931 - accuracy: 0.5079\n",
      "Epoch 2/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.6889 - accuracy: 0.5489\n",
      "Epoch 3/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6752 - accuracy: 0.6071\n",
      "Epoch 4/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6582 - accuracy: 0.6613\n",
      "Epoch 5/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6424 - accuracy: 0.6862\n",
      "Epoch 6/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.6288 - accuracy: 0.7086\n",
      "Epoch 7/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6168 - accuracy: 0.7191\n",
      "Epoch 8/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6069 - accuracy: 0.7243\n",
      "Epoch 9/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5993 - accuracy: 0.7284\n",
      "Epoch 10/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5920 - accuracy: 0.7356\n",
      "Epoch 11/150\n",
      "5332/5332 [==============================] - 0s 39us/step - loss: 0.5858 - accuracy: 0.7356\n",
      "Epoch 12/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5814 - accuracy: 0.7341\n",
      "Epoch 13/150\n",
      "5332/5332 [==============================] - 0s 42us/step - loss: 0.5772 - accuracy: 0.7346\n",
      "Epoch 14/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5744 - accuracy: 0.7344\n",
      "Epoch 15/150\n",
      "5332/5332 [==============================] - 0s 45us/step - loss: 0.5711 - accuracy: 0.7342\n",
      "Epoch 16/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5693 - accuracy: 0.7350\n",
      "Epoch 17/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5663 - accuracy: 0.7359\n",
      "Epoch 18/150\n",
      "5332/5332 [==============================] - 0s 41us/step - loss: 0.5649 - accuracy: 0.7357\n",
      "Epoch 19/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5625 - accuracy: 0.7342\n",
      "Epoch 20/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5621 - accuracy: 0.7376\n",
      "Epoch 21/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.5609 - accuracy: 0.7365\n",
      "Epoch 22/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5590 - accuracy: 0.7324\n",
      "Epoch 23/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5582 - accuracy: 0.7372\n",
      "Epoch 24/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5579 - accuracy: 0.7376\n",
      "Epoch 25/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5570 - accuracy: 0.7348\n",
      "Epoch 26/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5553 - accuracy: 0.7372\n",
      "Epoch 27/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.5551 - accuracy: 0.7372\n",
      "Epoch 28/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5550 - accuracy: 0.7372\n",
      "Epoch 29/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5537 - accuracy: 0.7369\n",
      "Epoch 30/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5540 - accuracy: 0.7365\n",
      "Epoch 31/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.5528 - accuracy: 0.7372\n",
      "Epoch 32/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5523 - accuracy: 0.7337\n",
      "Epoch 33/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5521 - accuracy: 0.7363\n",
      "Epoch 34/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5517 - accuracy: 0.7372\n",
      "Epoch 35/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5514 - accuracy: 0.7346\n",
      "Epoch 36/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5511 - accuracy: 0.7372\n",
      "Epoch 37/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.5510 - accuracy: 0.7356\n",
      "Epoch 38/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5504 - accuracy: 0.7350\n",
      "Epoch 39/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5502 - accuracy: 0.7352\n",
      "Epoch 40/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5508 - accuracy: 0.7357\n",
      "Epoch 41/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5499 - accuracy: 0.7350\n",
      "Epoch 42/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5496 - accuracy: 0.7365\n",
      "Epoch 43/150\n",
      "5332/5332 [==============================] - 0s 39us/step - loss: 0.5489 - accuracy: 0.7337\n",
      "Epoch 44/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5491 - accuracy: 0.7389\n",
      "Epoch 45/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5492 - accuracy: 0.7357\n",
      "Epoch 46/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5485 - accuracy: 0.7361\n",
      "Epoch 47/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5483 - accuracy: 0.7350\n",
      "Epoch 48/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5484 - accuracy: 0.7378\n",
      "Epoch 49/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5480 - accuracy: 0.7367\n",
      "Epoch 50/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5481 - accuracy: 0.7378\n",
      "Epoch 51/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5479 - accuracy: 0.7374\n",
      "Epoch 52/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5479 - accuracy: 0.7342\n",
      "Epoch 53/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5475 - accuracy: 0.7367\n",
      "Epoch 54/150\n",
      "5332/5332 [==============================] - 0s 39us/step - loss: 0.5483 - accuracy: 0.7359\n",
      "Epoch 55/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5473 - accuracy: 0.7382\n",
      "Epoch 56/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5474 - accuracy: 0.7367\n",
      "Epoch 57/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5471 - accuracy: 0.7380\n",
      "Epoch 58/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.5469 - accuracy: 0.7372\n",
      "Epoch 59/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5473 - accuracy: 0.7356\n",
      "Epoch 60/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5470 - accuracy: 0.7363\n",
      "Epoch 61/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5471 - accuracy: 0.7346\n",
      "Epoch 62/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5476 - accuracy: 0.7369\n",
      "Epoch 63/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5464 - accuracy: 0.7380\n",
      "Epoch 64/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5466 - accuracy: 0.7365\n",
      "Epoch 65/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5465 - accuracy: 0.7344\n",
      "Epoch 66/150\n",
      "5332/5332 [==============================] - 0s 39us/step - loss: 0.5461 - accuracy: 0.7372\n",
      "Epoch 67/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5462 - accuracy: 0.7369\n",
      "Epoch 68/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5462 - accuracy: 0.7374\n",
      "Epoch 69/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5454 - accuracy: 0.7367\n",
      "Epoch 70/150\n",
      "5332/5332 [==============================] - 0s 39us/step - loss: 0.5457 - accuracy: 0.7356\n",
      "Epoch 71/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5461 - accuracy: 0.7365\n",
      "Epoch 72/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5454 - accuracy: 0.7363\n",
      "Epoch 73/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5452 - accuracy: 0.7352\n",
      "Epoch 74/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5456 - accuracy: 0.7384\n",
      "Epoch 75/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5456 - accuracy: 0.7335\n",
      "Epoch 76/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5447 - accuracy: 0.7372\n",
      "Epoch 77/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5449 - accuracy: 0.7363\n",
      "Epoch 78/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5448 - accuracy: 0.7380\n",
      "Epoch 79/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5440 - accuracy: 0.7376\n",
      "Epoch 80/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5444 - accuracy: 0.7335\n",
      "Epoch 81/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5437 - accuracy: 0.7361\n",
      "Epoch 82/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5440 - accuracy: 0.7371\n",
      "Epoch 83/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5436 - accuracy: 0.7367\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5436 - accuracy: 0.7365\n",
      "Epoch 85/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5436 - accuracy: 0.7369\n",
      "Epoch 86/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5435 - accuracy: 0.7352\n",
      "Epoch 87/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5435 - accuracy: 0.7374\n",
      "Epoch 88/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5433 - accuracy: 0.7376\n",
      "Epoch 89/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5426 - accuracy: 0.7376\n",
      "Epoch 90/150\n",
      "5332/5332 [==============================] - 0s 41us/step - loss: 0.5431 - accuracy: 0.7365\n",
      "Epoch 91/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5428 - accuracy: 0.7341\n",
      "Epoch 92/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5426 - accuracy: 0.7380\n",
      "Epoch 93/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5427 - accuracy: 0.7341\n",
      "Epoch 94/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5432 - accuracy: 0.7387\n",
      "Epoch 95/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5427 - accuracy: 0.7333\n",
      "Epoch 96/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5422 - accuracy: 0.7382\n",
      "Epoch 97/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5422 - accuracy: 0.7376\n",
      "Epoch 98/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5424 - accuracy: 0.7374\n",
      "Epoch 99/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5421 - accuracy: 0.7371\n",
      "Epoch 100/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5419 - accuracy: 0.7352\n",
      "Epoch 101/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5424 - accuracy: 0.7371\n",
      "Epoch 102/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5429 - accuracy: 0.7342\n",
      "Epoch 103/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5423 - accuracy: 0.7389\n",
      "Epoch 104/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.5417 - accuracy: 0.7365\n",
      "Epoch 105/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5414 - accuracy: 0.7374\n",
      "Epoch 106/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5418 - accuracy: 0.7365\n",
      "Epoch 107/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5417 - accuracy: 0.7365\n",
      "Epoch 108/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5418 - accuracy: 0.7352\n",
      "Epoch 109/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5413 - accuracy: 0.7382\n",
      "Epoch 110/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5410 - accuracy: 0.7384\n",
      "Epoch 111/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5418 - accuracy: 0.7363\n",
      "Epoch 112/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5408 - accuracy: 0.7372\n",
      "Epoch 113/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5414 - accuracy: 0.7372\n",
      "Epoch 114/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5410 - accuracy: 0.7380\n",
      "Epoch 115/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5408 - accuracy: 0.7386\n",
      "Epoch 116/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5407 - accuracy: 0.7386\n",
      "Epoch 117/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5411 - accuracy: 0.7367\n",
      "Epoch 118/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5402 - accuracy: 0.7387\n",
      "Epoch 119/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5401 - accuracy: 0.7376\n",
      "Epoch 120/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5413 - accuracy: 0.7367\n",
      "Epoch 121/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5414 - accuracy: 0.7350\n",
      "Epoch 122/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5405 - accuracy: 0.7378\n",
      "Epoch 123/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5402 - accuracy: 0.7363\n",
      "Epoch 124/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5403 - accuracy: 0.7369\n",
      "Epoch 125/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5406 - accuracy: 0.7365\n",
      "Epoch 126/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5399 - accuracy: 0.7384\n",
      "Epoch 127/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5402 - accuracy: 0.7367\n",
      "Epoch 128/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5406 - accuracy: 0.7348\n",
      "Epoch 129/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5400 - accuracy: 0.7386\n",
      "Epoch 130/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5402 - accuracy: 0.7342\n",
      "Epoch 131/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5404 - accuracy: 0.7372\n",
      "Epoch 132/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5394 - accuracy: 0.7389\n",
      "Epoch 133/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5396 - accuracy: 0.7365\n",
      "Epoch 134/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5396 - accuracy: 0.7378\n",
      "Epoch 135/150\n",
      "5332/5332 [==============================] - 0s 28us/step - loss: 0.5400 - accuracy: 0.7387\n",
      "Epoch 136/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5393 - accuracy: 0.7378\n",
      "Epoch 137/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5396 - accuracy: 0.7386\n",
      "Epoch 138/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5393 - accuracy: 0.7367\n",
      "Epoch 139/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5398 - accuracy: 0.7356\n",
      "Epoch 140/150\n",
      "5332/5332 [==============================] - 0s 28us/step - loss: 0.5394 - accuracy: 0.7371\n",
      "Epoch 141/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5393 - accuracy: 0.7378\n",
      "Epoch 142/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5390 - accuracy: 0.7367\n",
      "Epoch 143/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5393 - accuracy: 0.7380\n",
      "Epoch 144/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5393 - accuracy: 0.7374\n",
      "Epoch 145/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5399 - accuracy: 0.7363\n",
      "Epoch 146/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5390 - accuracy: 0.7376\n",
      "Epoch 147/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.5388 - accuracy: 0.7391\n",
      "Epoch 148/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5386 - accuracy: 0.7363\n",
      "Epoch 149/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5394 - accuracy: 0.7380\n",
      "Epoch 150/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5387 - accuracy: 0.7384\n",
      "1777/1777 [==============================] - 0s 18us/step\n",
      "Epoch 1/150\n",
      "5332/5332 [==============================] - 0s 64us/step - loss: 0.6932 - accuracy: 0.4910\n",
      "Epoch 2/150\n",
      "5332/5332 [==============================] - 0s 42us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 3/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 4/150\n",
      "5332/5332 [==============================] - 0s 41us/step - loss: 0.6932 - accuracy: 0.4979\n",
      "Epoch 5/150\n",
      "5332/5332 [==============================] - 0s 43us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 6/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.6932 - accuracy: 0.4949\n",
      "Epoch 7/150\n",
      "5332/5332 [==============================] - 0s 26us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 8/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 9/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 10/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 11/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.6932 - accuracy: 0.4934\n",
      "Epoch 12/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 13/150\n",
      "5332/5332 [==============================] - 0s 28us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 14/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 15/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 16/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 17/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 18/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 19/150\n",
      "5332/5332 [==============================] - 0s 28us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 20/150\n",
      "5332/5332 [==============================] - 0s 28us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 21/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 22/150\n",
      "5332/5332 [==============================] - 0s 26us/step - loss: 0.6932 - accuracy: 0.4979\n",
      "Epoch 23/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 24/150\n",
      "5332/5332 [==============================] - 0s 24us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 25/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 26/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 27/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 28/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 29/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 30/150\n",
      "5332/5332 [==============================] - 0s 42us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 31/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 32/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 33/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 34/150\n",
      "5332/5332 [==============================] - 0s 39us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 35/150\n",
      "5332/5332 [==============================] - 0s 42us/step - loss: 0.6932 - accuracy: 0.4949\n",
      "Epoch 36/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 37/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 38/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 39/150\n",
      "5332/5332 [==============================] - 0s 27us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 40/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 41/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 42/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.4961\n",
      "Epoch 43/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 44/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 45/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 46/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 47/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.4987\n",
      "Epoch 48/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 49/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 50/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6932 - accuracy: 0.4938\n",
      "Epoch 51/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 52/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 53/150\n",
      "5332/5332 [==============================] - 0s 27us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 54/150\n",
      "5332/5332 [==============================] - 0s 26us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 55/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 56/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 57/150\n",
      "5332/5332 [==============================] - 0s 27us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 58/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 59/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.4964\n",
      "Epoch 60/150\n",
      "5332/5332 [==============================] - 0s 27us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 61/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.6932 - accuracy: 0.4957\n",
      "Epoch 62/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 63/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 64/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 65/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 66/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 67/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 68/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 69/150\n",
      "5332/5332 [==============================] - 0s 27us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 70/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 71/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 72/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 73/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 74/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.6932 - accuracy: 0.4957\n",
      "Epoch 75/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 76/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.6932 - accuracy: 0.4972\n",
      "Epoch 77/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 78/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 79/150\n",
      "5332/5332 [==============================] - 0s 28us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 80/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 81/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 82/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 83/150\n",
      "5332/5332 [==============================] - 0s 26us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 84/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 85/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 86/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 87/150\n",
      "5332/5332 [==============================] - 0s 41us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 88/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 90/150\n",
      "5332/5332 [==============================] - 0s 28us/step - loss: 0.6932 - accuracy: 0.4916\n",
      "Epoch 91/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 92/150\n",
      "5332/5332 [==============================] - 0s 27us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 93/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.4961\n",
      "Epoch 94/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 95/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 96/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 97/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 98/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 99/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.4968\n",
      "Epoch 100/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 101/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 102/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 103/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 104/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.6932 - accuracy: 0.4968\n",
      "Epoch 105/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 106/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 107/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 108/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.4957\n",
      "Epoch 109/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 110/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 111/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.6932 - accuracy: 0.4991\n",
      "Epoch 112/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.4972\n",
      "Epoch 113/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 114/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 115/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 116/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 117/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 118/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 119/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 120/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 121/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 122/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 123/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 124/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 125/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 126/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.4934\n",
      "Epoch 127/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 128/150\n",
      "5332/5332 [==============================] - 0s 26us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 129/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 130/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 131/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 132/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 133/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 134/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 135/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 136/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 137/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 138/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 139/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 140/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 141/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 142/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 143/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 144/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 145/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 146/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.4942\n",
      "Epoch 147/150\n",
      "5332/5332 [==============================] - 0s 27us/step - loss: 0.6931 - accuracy: 0.5024\n",
      "Epoch 148/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 149/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "Epoch 150/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.6932 - accuracy: 0.5024\n",
      "1777/1777 [==============================] - 0s 30us/step\n",
      "Epoch 1/150\n",
      "5332/5332 [==============================] - 0s 43us/step - loss: 0.6931 - accuracy: 0.5045\n",
      "Epoch 2/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.6916 - accuracy: 0.5739\n",
      "Epoch 3/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.6849 - accuracy: 0.6095\n",
      "Epoch 4/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.6736 - accuracy: 0.6423\n",
      "Epoch 5/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.6601 - accuracy: 0.6579\n",
      "Epoch 6/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.6470 - accuracy: 0.6860\n",
      "Epoch 7/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.6352 - accuracy: 0.7001\n",
      "Epoch 8/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.6199 - accuracy: 0.7127\n",
      "Epoch 9/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5863 - accuracy: 0.7200\n",
      "Epoch 10/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5676 - accuracy: 0.7239\n",
      "Epoch 11/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5603 - accuracy: 0.7236\n",
      "Epoch 12/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5564 - accuracy: 0.7221\n",
      "Epoch 13/150\n",
      "5332/5332 [==============================] - 0s 28us/step - loss: 0.5541 - accuracy: 0.7245\n",
      "Epoch 14/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5523 - accuracy: 0.7245\n",
      "Epoch 15/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5519 - accuracy: 0.7243\n",
      "Epoch 16/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5510 - accuracy: 0.7260\n",
      "Epoch 17/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5511 - accuracy: 0.7284\n",
      "Epoch 18/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5506 - accuracy: 0.7260\n",
      "Epoch 19/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5504 - accuracy: 0.7269\n",
      "Epoch 20/150\n",
      "5332/5332 [==============================] - 0s 39us/step - loss: 0.5502 - accuracy: 0.7245\n",
      "Epoch 21/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5499 - accuracy: 0.7267\n",
      "Epoch 22/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5497 - accuracy: 0.7264\n",
      "Epoch 23/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5495 - accuracy: 0.7269\n",
      "Epoch 24/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5493 - accuracy: 0.7262\n",
      "Epoch 25/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5493 - accuracy: 0.7249\n",
      "Epoch 26/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5498 - accuracy: 0.7249\n",
      "Epoch 27/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5494 - accuracy: 0.7277\n",
      "Epoch 28/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5489 - accuracy: 0.7264\n",
      "Epoch 29/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5492 - accuracy: 0.7264\n",
      "Epoch 30/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5493 - accuracy: 0.7247\n",
      "Epoch 31/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5491 - accuracy: 0.7241\n",
      "Epoch 32/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5493 - accuracy: 0.7266\n",
      "Epoch 33/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.5488 - accuracy: 0.7251\n",
      "Epoch 34/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5484 - accuracy: 0.7271\n",
      "Epoch 35/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5486 - accuracy: 0.7239\n",
      "Epoch 36/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5491 - accuracy: 0.7236\n",
      "Epoch 37/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5484 - accuracy: 0.7260\n",
      "Epoch 38/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5488 - accuracy: 0.7254\n",
      "Epoch 39/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5485 - accuracy: 0.7241\n",
      "Epoch 40/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5486 - accuracy: 0.7245\n",
      "Epoch 41/150\n",
      "5332/5332 [==============================] - 0s 27us/step - loss: 0.5482 - accuracy: 0.7260\n",
      "Epoch 42/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5483 - accuracy: 0.7275\n",
      "Epoch 43/150\n",
      "5332/5332 [==============================] - 0s 27us/step - loss: 0.5484 - accuracy: 0.7241\n",
      "Epoch 44/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5484 - accuracy: 0.7266\n",
      "Epoch 45/150\n",
      "5332/5332 [==============================] - 0s 44us/step - loss: 0.5484 - accuracy: 0.7245\n",
      "Epoch 46/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5477 - accuracy: 0.7247\n",
      "Epoch 47/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5479 - accuracy: 0.7251\n",
      "Epoch 48/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5481 - accuracy: 0.7245\n",
      "Epoch 49/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5478 - accuracy: 0.7264\n",
      "Epoch 50/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5481 - accuracy: 0.7290\n",
      "Epoch 51/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5480 - accuracy: 0.7251\n",
      "Epoch 52/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5478 - accuracy: 0.7247\n",
      "Epoch 53/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5474 - accuracy: 0.7273\n",
      "Epoch 54/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5477 - accuracy: 0.7247\n",
      "Epoch 55/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5477 - accuracy: 0.7254\n",
      "Epoch 56/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5476 - accuracy: 0.7273\n",
      "Epoch 57/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5473 - accuracy: 0.7251\n",
      "Epoch 58/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5479 - accuracy: 0.7245\n",
      "Epoch 59/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5471 - accuracy: 0.7262\n",
      "Epoch 60/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5472 - accuracy: 0.7267\n",
      "Epoch 61/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5472 - accuracy: 0.7258\n",
      "Epoch 62/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5474 - accuracy: 0.7243\n",
      "Epoch 63/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5471 - accuracy: 0.7267\n",
      "Epoch 64/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5472 - accuracy: 0.7241\n",
      "Epoch 65/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5470 - accuracy: 0.7256\n",
      "Epoch 66/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.5474 - accuracy: 0.7266\n",
      "Epoch 67/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5470 - accuracy: 0.7247\n",
      "Epoch 68/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5471 - accuracy: 0.7254\n",
      "Epoch 69/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5472 - accuracy: 0.7262\n",
      "Epoch 70/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5467 - accuracy: 0.7267\n",
      "Epoch 71/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5469 - accuracy: 0.7254\n",
      "Epoch 72/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5472 - accuracy: 0.7262\n",
      "Epoch 73/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5470 - accuracy: 0.7264\n",
      "Epoch 74/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5470 - accuracy: 0.7275\n",
      "Epoch 75/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5469 - accuracy: 0.7267\n",
      "Epoch 76/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5468 - accuracy: 0.7260\n",
      "Epoch 77/150\n",
      "5332/5332 [==============================] - 0s 39us/step - loss: 0.5469 - accuracy: 0.7260\n",
      "Epoch 78/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5473 - accuracy: 0.7249\n",
      "Epoch 79/150\n",
      "5332/5332 [==============================] - 0s 41us/step - loss: 0.5462 - accuracy: 0.7267\n",
      "Epoch 80/150\n",
      "5332/5332 [==============================] - 0s 41us/step - loss: 0.5463 - accuracy: 0.7275\n",
      "Epoch 81/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5465 - accuracy: 0.7251\n",
      "Epoch 82/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5466 - accuracy: 0.7267\n",
      "Epoch 83/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5464 - accuracy: 0.7271\n",
      "Epoch 84/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5464 - accuracy: 0.7269\n",
      "Epoch 85/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5465 - accuracy: 0.7273\n",
      "Epoch 86/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5465 - accuracy: 0.7254\n",
      "Epoch 87/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5461 - accuracy: 0.7296\n",
      "Epoch 88/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.5462 - accuracy: 0.7271\n",
      "Epoch 89/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5459 - accuracy: 0.7288\n",
      "Epoch 90/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5461 - accuracy: 0.7266\n",
      "Epoch 91/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5458 - accuracy: 0.7264\n",
      "Epoch 92/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5461 - accuracy: 0.7271\n",
      "Epoch 93/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5462 - accuracy: 0.7271\n",
      "Epoch 94/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5459 - accuracy: 0.7267\n",
      "Epoch 95/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5461 - accuracy: 0.7256\n",
      "Epoch 96/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5457 - accuracy: 0.7260\n",
      "Epoch 97/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5456 - accuracy: 0.7228\n",
      "Epoch 98/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5461 - accuracy: 0.7249\n",
      "Epoch 99/150\n",
      "5332/5332 [==============================] - 0s 28us/step - loss: 0.5466 - accuracy: 0.7286\n",
      "Epoch 100/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5464 - accuracy: 0.7254\n",
      "Epoch 101/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5453 - accuracy: 0.7271\n",
      "Epoch 102/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5457 - accuracy: 0.7264\n",
      "Epoch 103/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5458 - accuracy: 0.7249\n",
      "Epoch 104/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5458 - accuracy: 0.7264\n",
      "Epoch 105/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5454 - accuracy: 0.7264\n",
      "Epoch 106/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5457 - accuracy: 0.7271\n",
      "Epoch 107/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5451 - accuracy: 0.7254\n",
      "Epoch 108/150\n",
      "5332/5332 [==============================] - 0s 40us/step - loss: 0.5451 - accuracy: 0.7267\n",
      "Epoch 109/150\n",
      "5332/5332 [==============================] - 0s 37us/step - loss: 0.5455 - accuracy: 0.7260\n",
      "Epoch 110/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5450 - accuracy: 0.7288\n",
      "Epoch 111/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5453 - accuracy: 0.7267\n",
      "Epoch 112/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5449 - accuracy: 0.7275\n",
      "Epoch 113/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5450 - accuracy: 0.7269\n",
      "Epoch 114/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5451 - accuracy: 0.7269\n",
      "Epoch 115/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5451 - accuracy: 0.7264\n",
      "Epoch 116/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5449 - accuracy: 0.7277\n",
      "Epoch 117/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5450 - accuracy: 0.7251\n",
      "Epoch 118/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5448 - accuracy: 0.7275\n",
      "Epoch 119/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5451 - accuracy: 0.7222\n",
      "Epoch 120/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5451 - accuracy: 0.7258\n",
      "Epoch 121/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5446 - accuracy: 0.7275\n",
      "Epoch 122/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5452 - accuracy: 0.7277\n",
      "Epoch 123/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5446 - accuracy: 0.7275\n",
      "Epoch 124/150\n",
      "5332/5332 [==============================] - 0s 41us/step - loss: 0.5450 - accuracy: 0.7252\n",
      "Epoch 125/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5451 - accuracy: 0.7260\n",
      "Epoch 126/150\n",
      "5332/5332 [==============================] - 0s 36us/step - loss: 0.5448 - accuracy: 0.7256\n",
      "Epoch 127/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5448 - accuracy: 0.7260\n",
      "Epoch 128/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5446 - accuracy: 0.7254\n",
      "Epoch 129/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5447 - accuracy: 0.7228\n",
      "Epoch 130/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5444 - accuracy: 0.7258\n",
      "Epoch 131/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5447 - accuracy: 0.7260\n",
      "Epoch 132/150\n",
      "5332/5332 [==============================] - 0s 33us/step - loss: 0.5446 - accuracy: 0.7266\n",
      "Epoch 133/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5442 - accuracy: 0.7267\n",
      "Epoch 134/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5448 - accuracy: 0.7254\n",
      "Epoch 135/150\n",
      "5332/5332 [==============================] - 0s 28us/step - loss: 0.5445 - accuracy: 0.7264\n",
      "Epoch 136/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5443 - accuracy: 0.7258\n",
      "Epoch 137/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5444 - accuracy: 0.7237\n",
      "Epoch 138/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5439 - accuracy: 0.7264\n",
      "Epoch 139/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5438 - accuracy: 0.7269\n",
      "Epoch 140/150\n",
      "5332/5332 [==============================] - 0s 32us/step - loss: 0.5444 - accuracy: 0.7236\n",
      "Epoch 141/150\n",
      "5332/5332 [==============================] - 0s 38us/step - loss: 0.5448 - accuracy: 0.7264\n",
      "Epoch 142/150\n",
      "5332/5332 [==============================] - 0s 34us/step - loss: 0.5442 - accuracy: 0.7264\n",
      "Epoch 143/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5437 - accuracy: 0.7245\n",
      "Epoch 144/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5440 - accuracy: 0.7269\n",
      "Epoch 145/150\n",
      "5332/5332 [==============================] - 0s 31us/step - loss: 0.5437 - accuracy: 0.7245\n",
      "Epoch 146/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5435 - accuracy: 0.7277\n",
      "Epoch 147/150\n",
      "5332/5332 [==============================] - 0s 35us/step - loss: 0.5439 - accuracy: 0.7258\n",
      "Epoch 148/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5442 - accuracy: 0.7243\n",
      "Epoch 149/150\n",
      "5332/5332 [==============================] - 0s 29us/step - loss: 0.5440 - accuracy: 0.7252\n",
      "Epoch 150/150\n",
      "5332/5332 [==============================] - 0s 30us/step - loss: 0.5433 - accuracy: 0.7256\n",
      "1777/1777 [==============================] - 0s 31us/step\n",
      "Accuracy mean: 0.67758409678936\n",
      "Accuracy variance: 0.10277476331724532\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library \n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier2():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1])) # we use dimension of x_train as input\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu')) # we use 4 nodes in second layer\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')) # if we use sigmoid function it means we add output layer\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) # we will use accuracy as metrics\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier2, epochs = 150) # epochs means that is number of iteration \n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 4)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temproray.loc[-1] = [2, 4, 150,  0.6640782611279521]  # adding a row\n",
    "data_temproray.index = data_temproray.index + 1  # shifting index\n",
    "data_temproray = data_temproray.sort_index()  # sorting by index\n",
    "\n",
    "data_temproray.loc[-1] = [3, 3, 100, 0.492614638565769]  # adding a row\n",
    "data_temproray.index = data_temproray.index + 1  # shifting index\n",
    "data_temproray = data_temproray.sort_index()  # sorting by index\n",
    "\n",
    "data_temproray.loc[-1] = [3, 4, 150, 0.49022363005586056]  # adding a row\n",
    "data_temproray.index = data_temproray.index + 1  # shifting index\n",
    "data_temproray = data_temproray.sort_index()  # sorting by index\n",
    "\n",
    "data_temproray.loc[-1] = [2, 4, 150, 0.7318890200427076]  # adding a row\n",
    "data_temproray.index = data_temproray.index + 1  # shifting index\n",
    "data_temproray = data_temproray.sort_index()  # sorting by index\n",
    "\n",
    "data_temproray.loc[-1] = [2, 5, 150, 0.7341438597594337]  # adding a row\n",
    "data_temproray.index = data_temproray.index + 1  # shifting index\n",
    "data_temproray = data_temproray.sort_index()  # sorting by index\n",
    "\n",
    "data_temproray.loc[-1] = [2, 4, 200, 0.7310445842269522]  # adding a row\n",
    "data_temproray.index = data_temproray.index + 1  # shifting index\n",
    "data_temproray = data_temproray.sort_index()  # sorting by index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANN_Num</th>\n",
       "      <th>CV</th>\n",
       "      <th>epochs</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.731045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.734144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.731889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.490224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.492615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.664078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.655800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANN_Num   CV  epochs  accuracy\n",
       "0      2.0  4.0   200.0  0.731045\n",
       "1      2.0  5.0   150.0  0.734144\n",
       "2      2.0  4.0   150.0  0.731889\n",
       "3      3.0  4.0   150.0  0.490224\n",
       "4      3.0  3.0   100.0  0.492615\n",
       "5      2.0  4.0   150.0  0.664078\n",
       "6      2.0  3.0   100.0  0.655800"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temproray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temproray.accuracy = data_temproray.accuracy.apply(lambda x: x*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANN_Num</th>\n",
       "      <th>CV</th>\n",
       "      <th>epochs</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>73.104458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>73.414386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>73.188902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>49.022363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.261464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>66.407826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>65.580040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANN_Num   CV  epochs   accuracy\n",
       "0      2.0  4.0   200.0  73.104458\n",
       "1      2.0  5.0   150.0  73.414386\n",
       "2      2.0  4.0   150.0  73.188902\n",
       "3      3.0  4.0   150.0  49.022363\n",
       "4      3.0  3.0   100.0  49.261464\n",
       "5      2.0  4.0   150.0  66.407826\n",
       "6      2.0  3.0   100.0  65.580040"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temproray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import plotly.plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": [
           200,
           150,
           150,
           150,
           100,
           150,
           100
          ],
          "showscale": true,
          "size": [
           73.10445842269522,
           73.41438597594338,
           73.18890200427076,
           49.02236300558606,
           49.261463856576896,
           66.4078261127952,
           65.58003964712987
          ]
         },
         "mode": "markers",
         "text": [
          73.10445842269522,
          73.41438597594338,
          73.18890200427076,
          49.02236300558606,
          49.261463856576896,
          66.4078261127952,
          65.58003964712987
         ],
         "type": "scatter",
         "x": [
          2,
          2,
          2,
          3,
          3,
          2,
          2
         ],
         "y": [
          4,
          5,
          4,
          4,
          3,
          4,
          3
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"d3e5f3dd-65a5-41a8-82ec-4835a9b29506\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d3e5f3dd-65a5-41a8-82ec-4835a9b29506\")) {                    Plotly.newPlot(                        \"d3e5f3dd-65a5-41a8-82ec-4835a9b29506\",                        [{\"marker\": {\"color\": [200.0, 150.0, 150.0, 150.0, 100.0, 150.0, 100.0], \"showscale\": true, \"size\": [73.10445842269522, 73.41438597594338, 73.18890200427076, 49.02236300558606, 49.261463856576896, 66.4078261127952, 65.58003964712987]}, \"mode\": \"markers\", \"text\": [73.10445842269522, 73.41438597594338, 73.18890200427076, 49.02236300558606, 49.261463856576896, 66.4078261127952, 65.58003964712987], \"type\": \"scatter\", \"x\": [2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0], \"y\": [4.0, 5.0, 4.0, 4.0, 3.0, 4.0, 3.0]}],                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d3e5f3dd-65a5-41a8-82ec-4835a9b29506');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "international_color = [float(each) for each in data_temproray.epochs]\n",
    "data2 = [\n",
    "    {\n",
    "        'y':data_temproray.CV,\n",
    "        'x': data_temproray.ANN_Num,\n",
    "        'mode': 'markers',\n",
    "        'marker': {\n",
    "            'color': international_color,\n",
    "            'size': data_temproray.accuracy,\n",
    "            'showscale': True\n",
    "        },\n",
    "        \"text\" :  data_temproray.accuracy    \n",
    "    }\n",
    "]\n",
    "iplot(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kesimpulan\n",
    "\n",
    "Hasil terbaik dari model ini adalah 73,41% berkat \"Layer of Network\" yang dikenal sebagai ANN_num = 2, CV = 5, epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
