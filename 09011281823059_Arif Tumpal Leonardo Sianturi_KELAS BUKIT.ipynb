{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Testing dan Training dari Artificial Neural Network dengan Perhitungan Back-Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pertama, kita import modul yang dibutuhkan dan me-load dataset yang digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database raw shape (86,7130)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "db = np.loadtxt(\"duke-breast-cancer.txt\")\n",
    "print(\"Database raw shape (%s,%s)\" % np.shape(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.      , -0.362772, -0.314085, ...,  0.343084, -1.24348 ,\n",
       "         1.80402 ],\n",
       "       [ 1.      , -0.45958 , -0.719855, ..., -0.729734, -0.639368,\n",
       "         0.344724],\n",
       "       [ 1.      ,  0.103909, -0.296076, ...,  0.1812  , -0.626812,\n",
       "         0.237308],\n",
       "       ...,\n",
       "       [ 0.      , -0.512385, -0.326583, ...,  0.180162,  0.701266,\n",
       "        -0.3054  ],\n",
       "       [ 0.      , -0.213418,  0.415821, ...,  1.0016  , -0.390027,\n",
       "        -0.62477 ],\n",
       "       [ 0.      , -0.72451 , -0.359479, ...,  0.222557, -0.733495,\n",
       "        -0.821411]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 7129) (9, 7129)\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(db)\n",
    "y = db[:, 0]\n",
    "x = np.delete(db, [0], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "print(np.shape(x_train),np.shape(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu kemudian kita membuat vector hidden-layer,  weight's matrix, output layer vector dan hidden weight's matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = np.zeros(72)\n",
    "weights = np.random.random((len(x[0]), 72))\n",
    "output_layer = np.zeros(2)\n",
    "hidden_weights = np.random.random((72, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kemudian kita perlu mengimplementasikan fungsi sum, fungsi aktifasi, fungsi softmax, fungsi recalculate-weight dan terakhir fungsi back-propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Fungsi Sumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_function(weights, index_locked_col, x):\n",
    "    result = 0\n",
    "    for i in range(0, len(x)):\n",
    "        result += x[i] * weights[i][index_locked_col]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Fungsi Aktifasinya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_layer(layer, weights, x):\n",
    "    for i in range(0, len(layer)):\n",
    "        layer[i] = 1.7159 * np.tanh(2.0 * sum_function(weights, i, x) / 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Fungsi Softmaxnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(layer):\n",
    "    soft_max_output_layer = np.zeros(len(layer))\n",
    "    for i in range(0, len(layer)):\n",
    "        denominator = 0\n",
    "        for j in range(0, len(layer)):\n",
    "            denominator += np.exp(layer[j] - np.max(layer))\n",
    "        soft_max_output_layer[i] = np.exp(layer[i] - np.max(layer)) / denominator\n",
    "    return soft_max_output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Fungsi Recalculate-Weight-nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_weights(learning_rate, weights, gradient, activation):\n",
    "    for i in range(0, len(weights)):\n",
    "        for j in range(0, len(weights[i])):\n",
    "            weights[i][j] = (learning_rate * gradient[j] * activation[i]) + weights[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dan terakhir, fungsi Back-Propagationnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(hidden_layer, output_layer, one_hot_encoding, learning_rate, x):\n",
    "    output_derivative = np.zeros(2)\n",
    "    output_gradient = np.zeros(2)\n",
    "    for i in range(0, len(output_layer)):\n",
    "        output_derivative[i] = (1.0 - output_layer[i]) * output_layer[i]\n",
    "    for i in range(0, len(output_layer)):\n",
    "        output_gradient[i] = output_derivative[i] * (one_hot_encoding[i] - output_layer[i])\n",
    "    hidden_derivative = np.zeros(72)\n",
    "    hidden_gradient = np.zeros(72)\n",
    "    for i in range(0, len(hidden_layer)):\n",
    "        hidden_derivative[i] = (1.0 - hidden_layer[i]) * (1.0 + hidden_layer[i])\n",
    "    for i in range(0, len(hidden_layer)):\n",
    "        sum_ = 0\n",
    "        for j in range(0, len(output_gradient)):\n",
    "            sum_ += output_gradient[j] * hidden_weights[i][j]\n",
    "        hidden_gradient[i] = sum_ * hidden_derivative[i]\n",
    "    recalculate_weights(learning_rate, hidden_weights, output_gradient, hidden_layer)\n",
    "    recalculate_weights(learning_rate, weights, hidden_gradient, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kemudian kita masuk ke dalam training, dan terakhir adalah testing,\n",
    "Dimana dibawah ini adalah code untuk testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Correct answers while learning: 52 / 77 (Accuracy = 0.6753246753246753) on Duke breast cancer database.\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoding = np.zeros((2,2))\n",
    "for i in range(0, len(one_hot_encoding)):\n",
    "    one_hot_encoding[i][i] = 1\n",
    "training_correct_answers = 0\n",
    "for i in range(0, len(x_train)):\n",
    "    activate_layer(hidden_layer, weights, x_train[i])\n",
    "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
    "    output_layer = soft_max(output_layer)\n",
    "    training_correct_answers += 1 if y_train[i] == np.argmax(output_layer) else 0\n",
    "    back_propagation(hidden_layer, output_layer, one_hot_encoding[int(y_train[i])], -1, x_train[i])\n",
    "print(\"MLP Correct answers while learning: %s / %s (Accuracy = %s) on %s database.\" % (training_correct_answers, len(x_train), \n",
    "                                                                                       training_correct_answers/len(x_train),\"Duke breast cancer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah selesai proses training, dengan hasil 0.0.6753246753246753,\n",
    "Kita melakukan proses testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Correct answers while testing: 8 / 9 (Accuracy = 0.8888888888888888) on Duke breast cancer database\n"
     ]
    }
   ],
   "source": [
    "testing_correct_answers = 0\n",
    "for i in range(0, len(x_test)):\n",
    "    activate_layer(hidden_layer, weights, x_test[i])\n",
    "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
    "    output_layer = soft_max(output_layer)\n",
    "    testing_correct_answers += 1 if y_test[i] == np.argmax(output_layer) else 0\n",
    "print(\"MLP Correct answers while testing: %s / %s (Accuracy = %s) on %s database\" % (testing_correct_answers, len(x_test),\n",
    "                                                                                     testing_correct_answers/len(x_test), \"Duke breast cancer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proses testing slesai dengan hasil akurasi 0.7777777777777778, dimana dari hasil ini dapat kita simpulkan bahwa, jumlah error yang didapatkan masih dalam angka yang besar\n",
    "Karena hasilnya masih jauh dari hasil sempurna, 1,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumber : https://www.kaggle.com/andreicosma/back-propagation-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
