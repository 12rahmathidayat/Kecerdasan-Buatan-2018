{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TEXT PROCESSING***\n",
    "\n",
    "Text Processing merupakan bagian dari Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ajie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ajie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ajie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library yang digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = pd.read_csv('labeled_data.csv', index_col=0)\n",
    "labeled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24783 entries, 0 to 25296\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   count               24783 non-null  int64 \n",
      " 1   hate_speech         24783 non-null  int64 \n",
      " 2   offensive_language  24783 non-null  int64 \n",
      " 3   neither             24783 non-null  int64 \n",
      " 4   class               24783 non-null  int64 \n",
      " 5   tweet               24783 non-null  object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "labeled_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Melakukan Teks Pre-Processing***\n",
    "\n",
    "Text Preprocessing adalah salah satu bagian dari Natural Language Processing (NLP) dan merupakan tahapan paling awal sebelum masuk ke dalam proses inti pengolahan data. Text Preprocessing berfungsi dalam mempersiapkan data yang digunakan agar lebih terstruktur dan efektif. NLP merupakan teknologi Artificial Intelligence (AI) yang digunakan untuk mengubah data inti dari suatu dokumen berbentuk teks (text form) menjadi suatu data kuantitatif berbentuk angka (numerical form) secara cepat. Sehingga, data dapat diproses lebih lanjut seperti, dilakukan klasifikasi,clustering, dan sebagainya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        !!! RT @mayasolovely: As a woman you shouldn't...\n",
      "1        !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
      "2        !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
      "3        !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
      "4        !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
      "                               ...                        \n",
      "25291    you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
      "25292    you've gone and broke the wrong heart baby, an...\n",
      "25294    young buck wanna eat!!.. dat nigguh like I ain...\n",
      "25295                youu got wild bitches tellin you lies\n",
      "25296    ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...\n",
      "Name: tweet, Length: 24783, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tweet = labeled_data['tweet']\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Teks Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.lower()  # Lowercase text\n",
    "    text = re.sub(r'\\d+', '', text.lower())  # Clear Number\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Clear  !@#$##&$*(%)\n",
    "    text = text.strip()  # Bersihkan whitespaces (karakter karakter yang aneh/tak terlihat)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penerapan/Apply Fungsi pada salah satu feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        rt mayasolovely as a woman you shouldnt compla...\n",
       "1        rt mleew boy dats coldtyga dwn bad for cuffin ...\n",
       "2        rt urkindofbrand dawg rt sbabylife you ever fu...\n",
       "3           rt cganderson vivabased she look like a tranny\n",
       "4        rt shenikaroberts the shit you hear about me m...\n",
       "                               ...                        \n",
       "25291    yous a muthafin lie lifeasking pearls coreyema...\n",
       "25292    youve gone and broke the wrong heart baby and ...\n",
       "25294    young buck wanna eat dat nigguh like i aint fu...\n",
       "25295                youu got wild bitches tellin you lies\n",
       "25296    ruffled  ntac eileen dahlia  beautiful color c...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = tweet.apply(clean)\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\ajie\\anaconda3\\lib\\site-packages (3.5)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: regex in c:\\users\\ajie\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\ajie\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\ajie\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ajie\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perbedaan antara stemmer dan Lemmatizer adalah, Lemmatizer mempertimbangkan konteks dan mengubah kata menjadi bentuk dasarnya yang berarti, sedangkan stemmer hanya menghilangkan beberapa karakter terakhir, seringkali menyebabkan kesalahan arti dan ejaan.\n",
    "\n",
    "‘Caring’ -> lemmatizer -> ‘Care’\n",
    "‘Caring’ -> stemmer -> ‘Car’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenstem(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered = []\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            w = lemmatizer.lemmatize(w)\n",
    "            w = stemmer.stem(w)\n",
    "            filtered.append(w)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [rt, mayasolov, woman, shouldnt, complain, cle...\n",
       "1        [rt, mleew, boy, dat, coldtyga, dwn, bad, cuff...\n",
       "2        [rt, urkindofbrand, dawg, rt, sbabylif, ever, ...\n",
       "3            [rt, cganderson, vivabas, look, like, tranni]\n",
       "4        [rt, shenikarobert, shit, hear, might, true, m...\n",
       "                               ...                        \n",
       "25291    [you, muthafin, lie, lifeask, pearl, coreyeman...\n",
       "25292    [youv, gone, broke, wrong, heart, babi, drove,...\n",
       "25294    [young, buck, wan, na, eat, dat, nigguh, like,...\n",
       "25295                [youu, got, wild, bitch, tellin, lie]\n",
       "25296    [ruffl, ntac, eileen, dahlia, beauti, color, c...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = tweet.apply(tokenstem)\n",
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan**\n",
    "\n",
    "Lowercase = Fungsi yang mengubah huruf kapital menjadi huruf kecil.\n",
    "\n",
    "Regular Expression = Fungsi yang digunakan untuk menghapus angka.\n",
    "\n",
    "Punctuation = Fungsi yang digunakan untuk menghapus tanda baca.\n",
    "\n",
    "Fungsi strip, digunakan untuk menghapus white space yaitu spasi di awal ataupun di akhir kalimat.\n",
    "\n",
    "Tokenize = Proses pemisahan menjadi potongan kata.\n",
    "\n",
    "Lemmatizer = Menghilangkan akhiran infleksi dari suatu kata dan mengembalikan kata tersebut menjadi kata dasarnya, sebagai contohnya kata runs, running, dan ran akan diubah menjadi kata dasarnya yaitu run.\n",
    "\n",
    "Stemming = Tahapan pencarian dan pengubahan kata dasar dari tiap kata hasil Filtering.\n",
    "\n",
    "Stop Words = Kata umum yang biasanya muncul dalam jumlah besar dan dianggap tidak memiliki makna. Seperti, 'the'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah dilakukannya text pre processing, maka selanjutnya data bisa mulai diproses dengan mengubahnya terlebih dahulu ke dalam bentuk angka. Setelah diubah, maka data akan mulai diproses menggunakan Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
