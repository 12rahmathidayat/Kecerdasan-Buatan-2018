{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nama : Dimas Aditya Kristianto\n",
    "# NIM    : 09011281823132\n",
    "# Kelas : SK5B Indralaya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data dan library\n",
    "Pada cell berikut adalah library yang akan dipakai untuk memuat data. Program ini sudah dicoba dan dapat berjalan pada :\n",
    "* Python = 3.7\n",
    "* numpy  = 1.16.5\n",
    "* pandas = 0.25.1\n",
    "* matplotlib = 3.1.1\n",
    "* seaborn = 0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:39.113765Z",
     "iopub.status.busy": "2020-10-01T18:04:39.112717Z",
     "iopub.status.idle": "2020-10-01T18:04:40.220956Z",
     "shell.execute_reply": "2020-10-01T18:04:40.220195Z"
    },
    "papermill": {
     "duration": 1.150504,
     "end_time": "2020-10-01T18:04:40.221083",
     "exception": false,
     "start_time": "2020-10-01T18:04:39.070579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://storage.googleapis.com/kagglesdsdata/datasets/727551/1263738/heart_failure_clinical_records_dataset.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20201026%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20201026T151256Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=3c8da3a2e4edfe5e043e98059b8d762cc42362cf3cc4e73bd52f1b98e02a13273d1247dac41942adf2dbdc500b0fd63720e11007384499dd358720e887d0f5d8e227a871ef0f26ec9e09d9867eac37816119ac1a1450a3aa8380b829bf90bbe31d7570aa6fce9fbcb99099da10a4c4c22e60d8a55f396e8dbc03e5f9928d2518df6cce45e5e57fc45eeac0e05b309c20add6bcc55d53be5ee665699b26d3979e44a6ee91ad2612f98b0fd5399c4d3c424037feb6745d01b7785f6d2051071e849dddae27450eb6142a5313f931b220c7dc4ffd1dc7b72328434b0ed8a29421ba7724445aa3f5d8939baffb98b4269e4de12b011cbf5fdceabccefa8d4c943593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:40.368883Z",
     "iopub.status.busy": "2020-10-01T18:04:40.368030Z",
     "iopub.status.idle": "2020-10-01T18:04:40.382958Z",
     "shell.execute_reply": "2020-10-01T18:04:40.382058Z"
    },
    "papermill": {
     "duration": 0.05707,
     "end_time": "2020-10-01T18:04:40.383101",
     "exception": false,
     "start_time": "2020-10-01T18:04:40.326031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034807,
     "end_time": "2020-10-01T18:04:40.454420",
     "exception": false,
     "start_time": "2020-10-01T18:04:40.419613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Overview\n",
    "\n",
    "Pada sesi ini, dataset akan ditunjukkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:40.542106Z",
     "iopub.status.busy": "2020-10-01T18:04:40.539320Z",
     "iopub.status.idle": "2020-10-01T18:04:40.558077Z",
     "shell.execute_reply": "2020-10-01T18:04:40.557256Z"
    },
    "papermill": {
     "duration": 0.068747,
     "end_time": "2020-10-01T18:04:40.558208",
     "exception": false,
     "start_time": "2020-10-01T18:04:40.489461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:40.649760Z",
     "iopub.status.busy": "2020-10-01T18:04:40.648762Z",
     "iopub.status.idle": "2020-10-01T18:04:40.653345Z",
     "shell.execute_reply": "2020-10-01T18:04:40.652588Z"
    },
    "papermill": {
     "duration": 0.059608,
     "end_time": "2020-10-01T18:04:40.653475",
     "exception": false,
     "start_time": "2020-10-01T18:04:40.593867",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      "age                         299 non-null float64\n",
      "anaemia                     299 non-null int64\n",
      "creatinine_phosphokinase    299 non-null int64\n",
      "diabetes                    299 non-null int64\n",
      "ejection_fraction           299 non-null int64\n",
      "high_blood_pressure         299 non-null int64\n",
      "platelets                   299 non-null float64\n",
      "serum_creatinine            299 non-null float64\n",
      "serum_sodium                299 non-null int64\n",
      "sex                         299 non-null int64\n",
      "smoking                     299 non-null int64\n",
      "time                        299 non-null int64\n",
      "DEATH_EVENT                 299 non-null int64\n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035759,
     "end_time": "2020-10-01T18:04:40.725709",
     "exception": false,
     "start_time": "2020-10-01T18:04:40.689950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Ada 13 kolom di dalam dataset\n",
    "* Semua kolom berupa bilangan\n",
    "* Kolom DEATH_EVENT akan digunakan sebagai label pada sumbu y\n",
    "* Terdapat 299 baris pada dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03824,
     "end_time": "2020-10-01T18:04:40.800099",
     "exception": false,
     "start_time": "2020-10-01T18:04:40.761859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing\n",
    "Pada sesi ini, dataset akan dipersiapkan sebelum deep learning. Hal yang akan dilakukan dalam persiapannya adalah :\n",
    "\n",
    "* Dataset Normalizing\n",
    "* Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036859,
     "end_time": "2020-10-01T18:04:40.873092",
     "exception": false,
     "start_time": "2020-10-01T18:04:40.836233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Normalizing\n",
    "\n",
    "Pada sub-sesi ini, data akan di-normalisasi. Formula berikut akan digunakan untuk menormalisasikan data:\n",
    "\n",
    "**normalized_data = (data - min(data) / (max(data) - min(data))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:40.955048Z",
     "iopub.status.busy": "2020-10-01T18:04:40.954244Z",
     "iopub.status.idle": "2020-10-01T18:04:40.990715Z",
     "shell.execute_reply": "2020-10-01T18:04:40.989890Z"
    },
    "papermill": {
     "duration": 0.079997,
     "end_time": "2020-10-01T18:04:40.990849",
     "exception": false,
     "start_time": "2020-10-01T18:04:40.910852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = (data-np.min(data)) /(np.max(data)-np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:41.087963Z",
     "iopub.status.busy": "2020-10-01T18:04:41.072816Z",
     "iopub.status.idle": "2020-10-01T18:04:41.093752Z",
     "shell.execute_reply": "2020-10-01T18:04:41.093105Z"
    },
    "papermill": {
     "duration": 0.064324,
     "end_time": "2020-10-01T18:04:41.093902",
     "exception": false,
     "start_time": "2020-10-01T18:04:41.029578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.290823</td>\n",
       "      <td>0.157303</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288833</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165960</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010676</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224148</td>\n",
       "      <td>0.157303</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010676</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365984</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  0.636364      0.0                  0.071319       0.0           0.090909   \n",
       "1  0.272727      0.0                  1.000000       0.0           0.363636   \n",
       "2  0.454545      0.0                  0.015693       0.0           0.090909   \n",
       "3  0.181818      1.0                  0.011227       0.0           0.090909   \n",
       "4  0.454545      1.0                  0.017479       1.0           0.090909   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                  1.0   0.290823          0.157303      0.485714  1.0   \n",
       "1                  0.0   0.288833          0.067416      0.657143  1.0   \n",
       "2                  0.0   0.165960          0.089888      0.457143  1.0   \n",
       "3                  0.0   0.224148          0.157303      0.685714  1.0   \n",
       "4                  0.0   0.365984          0.247191      0.085714  0.0   \n",
       "\n",
       "   smoking      time  DEATH_EVENT  \n",
       "0      0.0  0.000000          1.0  \n",
       "1      0.0  0.007117          1.0  \n",
       "2      1.0  0.010676          1.0  \n",
       "3      0.0  0.010676          1.0  \n",
       "4      0.0  0.014235          1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038008,
     "end_time": "2020-10-01T18:04:41.170801",
     "exception": false,
     "start_time": "2020-10-01T18:04:41.132793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Test Split\n",
    "\n",
    "Pada sesi ini, dataset akan di-split(pisah) menjadi train(latih) dan test(uji coba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:41.256169Z",
     "iopub.status.busy": "2020-10-01T18:04:41.255335Z",
     "iopub.status.idle": "2020-10-01T18:04:41.396120Z",
     "shell.execute_reply": "2020-10-01T18:04:41.395490Z"
    },
    "papermill": {
     "duration": 0.186519,
     "end_time": "2020-10-01T18:04:41.396255",
     "exception": false,
     "start_time": "2020-10-01T18:04:41.209736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data.drop(\"DEATH_EVENT\",axis=1)\n",
    "y = data[\"DEATH_EVENT\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.15,random_state=42)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:41.558903Z",
     "iopub.status.busy": "2020-10-01T18:04:41.557831Z",
     "iopub.status.idle": "2020-10-01T18:04:41.562535Z",
     "shell.execute_reply": "2020-10-01T18:04:41.561866Z"
    },
    "papermill": {
     "duration": 0.052167,
     "end_time": "2020-10-01T18:04:41.562675",
     "exception": false,
     "start_time": "2020-10-01T18:04:41.510508",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 254)\n",
      "(12, 45)\n",
      "(254, 1)\n",
      "(45, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038282,
     "end_time": "2020-10-01T18:04:41.638923",
     "exception": false,
     "start_time": "2020-10-01T18:04:41.600641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating ANN Model\n",
    "\n",
    "Pada sesi ini, akan dibuat model ANN dengan 2 Layer\n",
    "\n",
    "Untuk membuat model ANN, akan diikuti langkah berikut:\n",
    "* Initializing Parameters\n",
    "* Forward Propagation\n",
    "* Loss and Cost Functions\n",
    "* Backward Propagation\n",
    "* Update Parameters\n",
    "* Prediction\n",
    "* Combining All Functions Into A Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037808,
     "end_time": "2020-10-01T18:04:41.715277",
     "exception": false,
     "start_time": "2020-10-01T18:04:41.677469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initializing Parameters\n",
    "\n",
    "Pada sesi ini, akan ditulis fungsi yang akan membantu dalam meng-inisialisasi parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:41.801704Z",
     "iopub.status.busy": "2020-10-01T18:04:41.800853Z",
     "iopub.status.idle": "2020-10-01T18:04:41.804761Z",
     "shell.execute_reply": "2020-10-01T18:04:41.803995Z"
    },
    "papermill": {
     "duration": 0.051057,
     "end_time": "2020-10-01T18:04:41.804895",
     "exception": false,
     "start_time": "2020-10-01T18:04:41.753838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_parameters_and_layer_sizes_NN(x_train, y_train):\n",
    "    parameters = {\"weight1\": np.random.randn(3,x_train.shape[0]) * 0.1,\n",
    "                  \"bias1\": np.zeros((3,1)),\n",
    "                  \"weight2\": np.random.randn(y_train.shape[0],3) * 0.1,\n",
    "                  \"bias2\": np.zeros((y_train.shape[0],1))}\n",
    "    return parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037846,
     "end_time": "2020-10-01T18:04:41.959362",
     "exception": false,
     "start_time": "2020-10-01T18:04:41.921516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Forward Propagation\n",
    "\n",
    "Pada fungsi forward propagation, program ini akan menggunakan formula:\n",
    "Z = W*a + B \n",
    "A = tanh(Z)\n",
    "\n",
    "Rumus untuk tanh:\n",
    "![ann-heart-failure](ann-heart-failure.png \"ann-heart-failure\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:42.044554Z",
     "iopub.status.busy": "2020-10-01T18:04:42.043378Z",
     "iopub.status.idle": "2020-10-01T18:04:42.047103Z",
     "shell.execute_reply": "2020-10-01T18:04:42.046349Z"
    },
    "papermill": {
     "duration": 0.048645,
     "end_time": "2020-10-01T18:04:42.047232",
     "exception": false,
     "start_time": "2020-10-01T18:04:41.998587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z))\n",
    "    return y_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:42.213108Z",
     "iopub.status.busy": "2020-10-01T18:04:42.212331Z",
     "iopub.status.idle": "2020-10-01T18:04:42.216513Z",
     "shell.execute_reply": "2020-10-01T18:04:42.215644Z"
    },
    "papermill": {
     "duration": 0.052261,
     "end_time": "2020-10-01T18:04:42.216647",
     "exception": false,
     "start_time": "2020-10-01T18:04:42.164386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward_propagation(x_train,parameters):\n",
    "    \n",
    "    Z1 = np.dot(parameters[\"weight1\"],x_train) + parameters[\"bias1\"]\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(parameters[\"weight2\"],A1) + parameters[\"bias2\"]\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    \n",
    "    cache = {\"Z1\":Z1,\n",
    "            \"A1\":A1,\n",
    "            \"Z2\":Z2,\n",
    "            \"A2\":A2 }\n",
    "    \n",
    "    return A2,cache\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04075,
     "end_time": "2020-10-01T18:04:42.295893",
     "exception": false,
     "start_time": "2020-10-01T18:04:42.255143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cost Function\n",
    "Pada sesi ini, akan dibuat fungsi cost. Pada deep learning diperlukan cost, model akan meningkat sedangkan cost akan berkurang.\n",
    "\n",
    "Rumus untuk fungsi cost:\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:42.387241Z",
     "iopub.status.busy": "2020-10-01T18:04:42.385929Z",
     "iopub.status.idle": "2020-10-01T18:04:42.391488Z",
     "shell.execute_reply": "2020-10-01T18:04:42.390558Z"
    },
    "papermill": {
     "duration": 0.054976,
     "end_time": "2020-10-01T18:04:42.391687",
     "exception": false,
     "start_time": "2020-10-01T18:04:42.336711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cost_func(A2,Y,parameters):\n",
    "    logprobs = np.multiply(np.log(A2),Y)\n",
    "    cost = -np.sum(logprobs)/Y.shape[1]\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051309,
     "end_time": "2020-10-01T18:04:42.493542",
     "exception": false,
     "start_time": "2020-10-01T18:04:42.442233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Backward Propagation\n",
    "\n",
    "Pada sesi ini akan dibuat fungsi dari back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:42.591745Z",
     "iopub.status.busy": "2020-10-01T18:04:42.590727Z",
     "iopub.status.idle": "2020-10-01T18:04:42.594121Z",
     "shell.execute_reply": "2020-10-01T18:04:42.593431Z"
    },
    "papermill": {
     "duration": 0.057335,
     "end_time": "2020-10-01T18:04:42.594267",
     "exception": false,
     "start_time": "2020-10-01T18:04:42.536932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "\n",
    "    dZ2 = cache[\"A2\"]-Y\n",
    "    dW2 = np.dot(dZ2,cache[\"A1\"].T)/X.shape[1]\n",
    "    db2 = np.sum(dZ2,axis =1,keepdims=True)/X.shape[1]\n",
    "    dZ1 = np.dot(parameters[\"weight2\"].T,dZ2)*(1 - np.power(cache[\"A1\"], 2))\n",
    "    dW1 = np.dot(dZ1,X.T)/X.shape[1]\n",
    "    db1 = np.sum(dZ1,axis =1,keepdims=True)/X.shape[1]\n",
    "    grads = {\"dweight1\": dW1,\n",
    "             \"dbias1\": db1,\n",
    "             \"dweight2\": dW2,\n",
    "             \"dbias2\": db2}\n",
    "    return grads"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03867,
     "end_time": "2020-10-01T18:04:42.751241",
     "exception": false,
     "start_time": "2020-10-01T18:04:42.712571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Updating Function\n",
    "\n",
    "Pada sesi ini akan dibuat fungsi updating. Program akan meng-update bobot dan bias.\n",
    "\n",
    "Ada rumus untuk meng-update:\n",
    "![image2](image2.png \"ann-heart-failure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:42.837785Z",
     "iopub.status.busy": "2020-10-01T18:04:42.836930Z",
     "iopub.status.idle": "2020-10-01T18:04:42.840372Z",
     "shell.execute_reply": "2020-10-01T18:04:42.839683Z"
    },
    "papermill": {
     "duration": 0.050306,
     "end_time": "2020-10-01T18:04:42.840501",
     "exception": false,
     "start_time": "2020-10-01T18:04:42.790195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def updating(parameters, grads, learning_rate = 0.01):\n",
    "    parameters = {\"weight1\": parameters[\"weight1\"]-learning_rate*grads[\"dweight1\"],\n",
    "                  \"bias1\": parameters[\"bias1\"]-learning_rate*grads[\"dbias1\"],\n",
    "                  \"weight2\": parameters[\"weight2\"]-learning_rate*grads[\"dweight2\"],\n",
    "                  \"bias2\": parameters[\"bias2\"]-learning_rate*grads[\"dbias2\"]}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04009,
     "end_time": "2020-10-01T18:04:42.921513",
     "exception": false,
     "start_time": "2020-10-01T18:04:42.881423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction Function\n",
    "\n",
    "Fungsi utama sudah siap, tetapi masih diperlukan fungsi prediksi untuk menggunakan model yang sudah dilatih."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:43.008810Z",
     "iopub.status.busy": "2020-10-01T18:04:43.007952Z",
     "iopub.status.idle": "2020-10-01T18:04:43.011786Z",
     "shell.execute_reply": "2020-10-01T18:04:43.011013Z"
    },
    "papermill": {
     "duration": 0.051328,
     "end_time": "2020-10-01T18:04:43.011917",
     "exception": false,
     "start_time": "2020-10-01T18:04:42.960589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction(parameters,x_test):\n",
    "    A2, cache = forward_propagation(x_test,parameters)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "\n",
    "    for i in range(A2.shape[1]):\n",
    "        if A2[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038946,
     "end_time": "2020-10-01T18:04:43.090425",
     "exception": false,
     "start_time": "2020-10-01T18:04:43.051479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Combining All Functions Into A Function\n",
    "\n",
    "Semua fungsi sudah siap dan sekarang semua fungsi akan digabungkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:43.187616Z",
     "iopub.status.busy": "2020-10-01T18:04:43.186471Z",
     "iopub.status.idle": "2020-10-01T18:04:43.190553Z",
     "shell.execute_reply": "2020-10-01T18:04:43.189778Z"
    },
    "papermill": {
     "duration": 0.060351,
     "end_time": "2020-10-01T18:04:43.190689",
     "exception": false,
     "start_time": "2020-10-01T18:04:43.130338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ann_2layer(x_train,y_train,x_test,y_test,num_of_iter=2500):\n",
    "    cost_list = []\n",
    "    iter_list = []\n",
    " \n",
    "    parameters = initialize_parameters_and_layer_sizes_NN(x_train,y_train)\n",
    "    \n",
    "    for i in range(0,num_of_iter):\n",
    "        \n",
    "        A2,cache = forward_propagation(x_train,parameters) # Forward Propagation\n",
    "        \n",
    "        cost = cost_func(A2,y_train,parameters) # Cost Function\n",
    "        \n",
    "        grads = backward_propagation(parameters,cache,x_train,y_train) # Backward Propagation\n",
    "        \n",
    "        parameters = updating(parameters,grads) # Updating Parameters\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            cost_list.append(cost)\n",
    "            iter_list.append(i)\n",
    "            print(\"Cost after iteration {} : {}\".format(i,cost))\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    Cost Value Visualization\n",
    "    \"\"\"\n",
    "    fig,ax = plt.subplots(figsize=(8,6))\n",
    "    plt.plot(iter_list,cost_list)\n",
    "    plt.xticks(iter_list,rotation=90)\n",
    "    plt.xlabel(\"Number Of Iteration\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    y_prediction_test = prediction(parameters,x_test)\n",
    "    y_prediction_train = prediction(parameters,x_train)\n",
    "\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n",
    "    \n",
    "    return parameters\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:43.355308Z",
     "iopub.status.busy": "2020-10-01T18:04:43.354452Z",
     "iopub.status.idle": "2020-10-01T18:04:54.497075Z",
     "shell.execute_reply": "2020-10-01T18:04:54.496354Z"
    },
    "papermill": {
     "duration": 11.188339,
     "end_time": "2020-10-01T18:04:54.497238",
     "exception": false,
     "start_time": "2020-10-01T18:04:43.308899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0 : 13401.093255220923\n",
      "Cost after iteration 100 : 5657.690427296116\n",
      "Cost after iteration 200 : 2883.2232782397773\n",
      "Cost after iteration 300 : 1881.6192290498334\n",
      "Cost after iteration 400 : 1383.8317311078347\n",
      "Cost after iteration 500 : 1089.955372130146\n",
      "Cost after iteration 600 : 897.1583308968037\n",
      "Cost after iteration 700 : 761.3871570300249\n",
      "Cost after iteration 800 : 660.7985757283328\n",
      "Cost after iteration 900 : 583.3844726972532\n",
      "Cost after iteration 1000 : 522.016902835014\n",
      "Cost after iteration 1100 : 472.2061624588917\n",
      "Cost after iteration 1200 : 430.9875358702999\n",
      "Cost after iteration 1300 : 396.3264811819154\n",
      "Cost after iteration 1400 : 366.7814205039624\n",
      "Cost after iteration 1500 : 341.30298139891727\n",
      "Cost after iteration 1600 : 319.10945684367306\n",
      "Cost after iteration 1700 : 299.60679070503727\n",
      "Cost after iteration 1800 : 282.335591413628\n",
      "Cost after iteration 1900 : 266.9351065754461\n",
      "Cost after iteration 2000 : 253.11815471503542\n",
      "Cost after iteration 2100 : 240.65331925929846\n",
      "Cost after iteration 2200 : 229.35206669695506\n",
      "Cost after iteration 2300 : 219.0592723063621\n",
      "Cost after iteration 2400 : 209.64614758809628\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 70.07874015748031 %\n",
      "test accuracy: 55.55555555555556 %\n"
     ]
    }
   ],
   "source": [
    "parameters = ann_2layer(x_train,y_train,x_test,y_test,2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052686,
     "end_time": "2020-10-01T18:04:54.610182",
     "exception": false,
     "start_time": "2020-10-01T18:04:54.557496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hasil skor train: %70\n",
    "\n",
    "Hasil skor tes: %55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050718,
     "end_time": "2020-10-01T18:04:54.712426",
     "exception": false,
     "start_time": "2020-10-01T18:04:54.661708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating ANN Model Using Keras Library\n",
    "\n",
    "Pada sesi ini akan dibuat model ANN menggunakan library Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:54.823004Z",
     "iopub.status.busy": "2020-10-01T18:04:54.822009Z",
     "iopub.status.idle": "2020-10-01T18:04:54.825801Z",
     "shell.execute_reply": "2020-10-01T18:04:54.825030Z"
    },
    "papermill": {
     "duration": 0.062705,
     "end_time": "2020-10-01T18:04:54.825937",
     "exception": false,
     "start_time": "2020-10-01T18:04:54.763232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train,x_test = x_train.T,x_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:54.936676Z",
     "iopub.status.busy": "2020-10-01T18:04:54.935571Z",
     "iopub.status.idle": "2020-10-01T18:04:54.940208Z",
     "shell.execute_reply": "2020-10-01T18:04:54.939495Z"
    },
    "papermill": {
     "duration": 0.062619,
     "end_time": "2020-10-01T18:04:54.940355",
     "exception": false,
     "start_time": "2020-10-01T18:04:54.877736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254, 12)\n",
      "(45, 12)\n",
      "(254, 1)\n",
      "(45, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library untuk membuat model ANN menggunakan keras\n",
    "Program ini telah dicoba dijalankan menggunakan:\n",
    "* scikit-learn = 0.21.3\n",
    "* keras = 2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:04:55.109089Z",
     "iopub.status.busy": "2020-10-01T18:04:55.108005Z",
     "iopub.status.idle": "2020-10-01T18:05:08.137331Z",
     "shell.execute_reply": "2020-10-01T18:05:08.136491Z"
    },
    "papermill": {
     "duration": 13.114255,
     "end_time": "2020-10-01T18:05:08.137475",
     "exception": false,
     "start_time": "2020-10-01T18:04:55.023220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dimas\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "169/169 [==============================] - 2s 11ms/step - loss: 0.6927 - acc: 0.6213\n",
      "Epoch 2/100\n",
      "169/169 [==============================] - 0s 414us/step - loss: 0.6907 - acc: 0.7396\n",
      "Epoch 3/100\n",
      "169/169 [==============================] - 0s 207us/step - loss: 0.6884 - acc: 0.7396\n",
      "Epoch 4/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.6855 - acc: 0.7396\n",
      "Epoch 5/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.6815 - acc: 0.7396\n",
      "Epoch 6/100\n",
      "169/169 [==============================] - 0s 195us/step - loss: 0.6767 - acc: 0.7396\n",
      "Epoch 7/100\n",
      "169/169 [==============================] - 0s 136us/step - loss: 0.6686 - acc: 0.7396\n",
      "Epoch 8/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.6590 - acc: 0.7396\n",
      "Epoch 9/100\n",
      "169/169 [==============================] - 0s 284us/step - loss: 0.6477 - acc: 0.7396\n",
      "Epoch 10/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.6344 - acc: 0.7396\n",
      "Epoch 11/100\n",
      "169/169 [==============================] - 0s 112us/step - loss: 0.6211 - acc: 0.7396\n",
      "Epoch 12/100\n",
      "169/169 [==============================] - 0s 118us/step - loss: 0.6075 - acc: 0.7396\n",
      "Epoch 13/100\n",
      "169/169 [==============================] - 0s 166us/step - loss: 0.5970 - acc: 0.7396\n",
      "Epoch 14/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.5882 - acc: 0.7396\n",
      "Epoch 15/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.5813 - acc: 0.7396\n",
      "Epoch 16/100\n",
      "169/169 [==============================] - 0s 177us/step - loss: 0.5754 - acc: 0.7396\n",
      "Epoch 17/100\n",
      "169/169 [==============================] - 0s 142us/step - loss: 0.5714 - acc: 0.7396\n",
      "Epoch 18/100\n",
      "169/169 [==============================] - 0s 101us/step - loss: 0.5691 - acc: 0.7396\n",
      "Epoch 19/100\n",
      "169/169 [==============================] - 0s 284us/step - loss: 0.5675 - acc: 0.7396\n",
      "Epoch 20/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.5669 - acc: 0.7396\n",
      "Epoch 21/100\n",
      "169/169 [==============================] - 0s 118us/step - loss: 0.5653 - acc: 0.7396\n",
      "Epoch 22/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.5646 - acc: 0.7396\n",
      "Epoch 23/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.5635 - acc: 0.7396\n",
      "Epoch 24/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.5625 - acc: 0.7396\n",
      "Epoch 25/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.5616 - acc: 0.7396\n",
      "Epoch 26/100\n",
      "169/169 [==============================] - 0s 166us/step - loss: 0.5609 - acc: 0.7396\n",
      "Epoch 27/100\n",
      "169/169 [==============================] - 0s 337us/step - loss: 0.5594 - acc: 0.7396\n",
      "Epoch 28/100\n",
      "169/169 [==============================] - 0s 118us/step - loss: 0.5580 - acc: 0.7396\n",
      "Epoch 29/100\n",
      "169/169 [==============================] - 0s 118us/step - loss: 0.5566 - acc: 0.7396\n",
      "Epoch 30/100\n",
      "169/169 [==============================] - 0s 272us/step - loss: 0.5557 - acc: 0.7396\n",
      "Epoch 31/100\n",
      "169/169 [==============================] - 0s 177us/step - loss: 0.5536 - acc: 0.7396\n",
      "Epoch 32/100\n",
      "169/169 [==============================] - 0s 112us/step - loss: 0.5515 - acc: 0.7396\n",
      "Epoch 33/100\n",
      "169/169 [==============================] - 0s 207us/step - loss: 0.5492 - acc: 0.7396\n",
      "Epoch 34/100\n",
      "169/169 [==============================] - 0s 166us/step - loss: 0.5467 - acc: 0.7396\n",
      "Epoch 35/100\n",
      "169/169 [==============================] - 0s 136us/step - loss: 0.5437 - acc: 0.7396\n",
      "Epoch 36/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.5403 - acc: 0.7396\n",
      "Epoch 37/100\n",
      "169/169 [==============================] - 0s 183us/step - loss: 0.5367 - acc: 0.7396\n",
      "Epoch 38/100\n",
      "169/169 [==============================] - 0s 118us/step - loss: 0.5327 - acc: 0.7396\n",
      "Epoch 39/100\n",
      "169/169 [==============================] - 0s 195us/step - loss: 0.5279 - acc: 0.7396\n",
      "Epoch 40/100\n",
      "169/169 [==============================] - 0s 171us/step - loss: 0.5236 - acc: 0.7396\n",
      "Epoch 41/100\n",
      "169/169 [==============================] - 0s 166us/step - loss: 0.5179 - acc: 0.7396\n",
      "Epoch 42/100\n",
      "169/169 [==============================] - 0s 142us/step - loss: 0.5114 - acc: 0.7396\n",
      "Epoch 43/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.5049 - acc: 0.7396\n",
      "Epoch 44/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.4980 - acc: 0.7456\n",
      "Epoch 45/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.4904 - acc: 0.7456\n",
      "Epoch 46/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.4822 - acc: 0.7456\n",
      "Epoch 47/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.4737 - acc: 0.7515\n",
      "Epoch 48/100\n",
      "169/169 [==============================] - 0s 189us/step - loss: 0.4641 - acc: 0.7811\n",
      "Epoch 49/100\n",
      "169/169 [==============================] - 0s 118us/step - loss: 0.4562 - acc: 0.7870\n",
      "Epoch 50/100\n",
      "169/169 [==============================] - 0s 112us/step - loss: 0.4460 - acc: 0.8047\n",
      "Epoch 51/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.4363 - acc: 0.8166\n",
      "Epoch 52/100\n",
      "169/169 [==============================] - 0s 136us/step - loss: 0.4270 - acc: 0.8225\n",
      "Epoch 53/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.4187 - acc: 0.8284\n",
      "Epoch 54/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.4094 - acc: 0.8580\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 0s 248us/step - loss: 0.4021 - acc: 0.8639\n",
      "Epoch 56/100\n",
      "169/169 [==============================] - 0s 112us/step - loss: 0.3949 - acc: 0.8639\n",
      "Epoch 57/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3858 - acc: 0.843 - 0s 118us/step - loss: 0.3883 - acc: 0.8698\n",
      "Epoch 58/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.3813 - acc: 0.8698\n",
      "Epoch 59/100\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3501 - acc: 0.906 - 0s 721us/step - loss: 0.3753 - acc: 0.8757\n",
      "Epoch 60/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.3692 - acc: 0.8817\n",
      "Epoch 61/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.3640 - acc: 0.8817\n",
      "Epoch 62/100\n",
      "169/169 [==============================] - 0s 296us/step - loss: 0.3585 - acc: 0.8935\n",
      "Epoch 63/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.3540 - acc: 0.8817\n",
      "Epoch 64/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.3491 - acc: 0.8817\n",
      "Epoch 65/100\n",
      "169/169 [==============================] - 0s 367us/step - loss: 0.3457 - acc: 0.8876\n",
      "Epoch 66/100\n",
      "169/169 [==============================] - 0s 118us/step - loss: 0.3419 - acc: 0.8876\n",
      "Epoch 67/100\n",
      "169/169 [==============================] - 0s 166us/step - loss: 0.3387 - acc: 0.8876\n",
      "Epoch 68/100\n",
      "169/169 [==============================] - 0s 231us/step - loss: 0.3353 - acc: 0.8876\n",
      "Epoch 69/100\n",
      "169/169 [==============================] - 0s 136us/step - loss: 0.3314 - acc: 0.8876\n",
      "Epoch 70/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.3292 - acc: 0.8876\n",
      "Epoch 71/100\n",
      "169/169 [==============================] - 0s 166us/step - loss: 0.3261 - acc: 0.8876\n",
      "Epoch 72/100\n",
      "169/169 [==============================] - 0s 189us/step - loss: 0.3244 - acc: 0.8876\n",
      "Epoch 73/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.3217 - acc: 0.8876\n",
      "Epoch 74/100\n",
      "169/169 [==============================] - 0s 171us/step - loss: 0.3192 - acc: 0.8935\n",
      "Epoch 75/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.3174 - acc: 0.8935\n",
      "Epoch 76/100\n",
      "169/169 [==============================] - 0s 142us/step - loss: 0.3157 - acc: 0.8935\n",
      "Epoch 77/100\n",
      "169/169 [==============================] - 0s 160us/step - loss: 0.3160 - acc: 0.8876\n",
      "Epoch 78/100\n",
      "169/169 [==============================] - 0s 266us/step - loss: 0.3131 - acc: 0.8817\n",
      "Epoch 79/100\n",
      "169/169 [==============================] - 0s 160us/step - loss: 0.3127 - acc: 0.8994\n",
      "Epoch 80/100\n",
      "169/169 [==============================] - 0s 313us/step - loss: 0.3095 - acc: 0.8994\n",
      "Epoch 81/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.3092 - acc: 0.8876\n",
      "Epoch 82/100\n",
      "169/169 [==============================] - 0s 207us/step - loss: 0.3088 - acc: 0.8935\n",
      "Epoch 83/100\n",
      "169/169 [==============================] - 0s 450us/step - loss: 0.3074 - acc: 0.8994\n",
      "Epoch 84/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.3075 - acc: 0.9053\n",
      "Epoch 85/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.3054 - acc: 0.8994\n",
      "Epoch 86/100\n",
      "169/169 [==============================] - 0s 207us/step - loss: 0.3047 - acc: 0.8935\n",
      "Epoch 87/100\n",
      "169/169 [==============================] - 0s 172us/step - loss: 0.3038 - acc: 0.8876\n",
      "Epoch 88/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.3032 - acc: 0.8935\n",
      "Epoch 89/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.3023 - acc: 0.8935\n",
      "Epoch 90/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.3018 - acc: 0.8935\n",
      "Epoch 91/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.3038 - acc: 0.8935\n",
      "Epoch 92/100\n",
      "169/169 [==============================] - 0s 136us/step - loss: 0.3022 - acc: 0.8817\n",
      "Epoch 93/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.3005 - acc: 0.8994\n",
      "Epoch 94/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.3030 - acc: 0.8994\n",
      "Epoch 95/100\n",
      "169/169 [==============================] - 0s 284us/step - loss: 0.3006 - acc: 0.9053\n",
      "Epoch 96/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.2987 - acc: 0.8994\n",
      "Epoch 97/100\n",
      "169/169 [==============================] - 0s 189us/step - loss: 0.2985 - acc: 0.8935\n",
      "Epoch 98/100\n",
      "169/169 [==============================] - 0s 118us/step - loss: 0.2982 - acc: 0.8935\n",
      "Epoch 99/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.2990 - acc: 0.8935\n",
      "Epoch 100/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.2991 - acc: 0.8935\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "169/169 [==============================] - 2s 13ms/step - loss: 0.6926 - acc: 0.6036\n",
      "Epoch 2/100\n",
      "169/169 [==============================] - 0s 166us/step - loss: 0.6911 - acc: 0.6805\n",
      "Epoch 3/100\n",
      "169/169 [==============================] - 0s 136us/step - loss: 0.6894 - acc: 0.6805\n",
      "Epoch 4/100\n",
      "169/169 [==============================] - 0s 189us/step - loss: 0.6870 - acc: 0.6805\n",
      "Epoch 5/100\n",
      "169/169 [==============================] - 0s 242us/step - loss: 0.6838 - acc: 0.6805\n",
      "Epoch 6/100\n",
      "169/169 [==============================] - 0s 248us/step - loss: 0.6798 - acc: 0.6805\n",
      "Epoch 7/100\n",
      "169/169 [==============================] - 0s 237us/step - loss: 0.6745 - acc: 0.6805\n",
      "Epoch 8/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.6672 - acc: 0.6805\n",
      "Epoch 9/100\n",
      "169/169 [==============================] - 0s 142us/step - loss: 0.6590 - acc: 0.6805\n",
      "Epoch 10/100\n",
      "169/169 [==============================] - 0s 242us/step - loss: 0.6502 - acc: 0.6805\n",
      "Epoch 11/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.6416 - acc: 0.6805\n",
      "Epoch 12/100\n",
      "169/169 [==============================] - 0s 142us/step - loss: 0.6347 - acc: 0.6805\n",
      "Epoch 13/100\n",
      "169/169 [==============================] - 0s 260us/step - loss: 0.6285 - acc: 0.6805\n",
      "Epoch 14/100\n",
      "169/169 [==============================] - 0s 319us/step - loss: 0.6247 - acc: 0.6805\n",
      "Epoch 15/100\n",
      "169/169 [==============================] - 0s 142us/step - loss: 0.6223 - acc: 0.6805\n",
      "Epoch 16/100\n",
      "169/169 [==============================] - 0s 183us/step - loss: 0.6201 - acc: 0.6805\n",
      "Epoch 17/100\n",
      "169/169 [==============================] - 0s 142us/step - loss: 0.6193 - acc: 0.6805\n",
      "Epoch 18/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.6180 - acc: 0.6805\n",
      "Epoch 19/100\n",
      "169/169 [==============================] - 0s 201us/step - loss: 0.6170 - acc: 0.6805\n",
      "Epoch 20/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.6162 - acc: 0.6805\n",
      "Epoch 21/100\n",
      "169/169 [==============================] - 0s 254us/step - loss: 0.6152 - acc: 0.6805\n",
      "Epoch 22/100\n",
      "169/169 [==============================] - 0s 118us/step - loss: 0.6140 - acc: 0.6805\n",
      "Epoch 23/100\n",
      "169/169 [==============================] - 0s 160us/step - loss: 0.6127 - acc: 0.6805\n",
      "Epoch 24/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.6110 - acc: 0.6805\n",
      "Epoch 25/100\n",
      "169/169 [==============================] - 0s 171us/step - loss: 0.6096 - acc: 0.6805\n",
      "Epoch 26/100\n",
      "169/169 [==============================] - 0s 207us/step - loss: 0.6081 - acc: 0.6805\n",
      "Epoch 27/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.6063 - acc: 0.6805\n",
      "Epoch 28/100\n",
      "169/169 [==============================] - 0s 136us/step - loss: 0.6044 - acc: 0.6805\n",
      "Epoch 29/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.6024 - acc: 0.6805\n",
      "Epoch 30/100\n",
      "169/169 [==============================] - 0s 201us/step - loss: 0.6003 - acc: 0.6805\n",
      "Epoch 31/100\n",
      "169/169 [==============================] - 0s 166us/step - loss: 0.5977 - acc: 0.6805\n",
      "Epoch 32/100\n",
      "169/169 [==============================] - 0s 177us/step - loss: 0.5946 - acc: 0.6805\n",
      "Epoch 33/100\n",
      "169/169 [==============================] - 0s 207us/step - loss: 0.5915 - acc: 0.6805\n",
      "Epoch 34/100\n",
      "169/169 [==============================] - 0s 254us/step - loss: 0.5879 - acc: 0.6805\n",
      "Epoch 35/100\n",
      "169/169 [==============================] - 0s 207us/step - loss: 0.5840 - acc: 0.6805\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 0s 160us/step - loss: 0.5789 - acc: 0.6805\n",
      "Epoch 37/100\n",
      "169/169 [==============================] - 0s 201us/step - loss: 0.5750 - acc: 0.6805\n",
      "Epoch 38/100\n",
      "169/169 [==============================] - 0s 127us/step - loss: 0.5688 - acc: 0.6805\n",
      "Epoch 39/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.5631 - acc: 0.6864\n",
      "Epoch 40/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.5566 - acc: 0.6864\n",
      "Epoch 41/100\n",
      "169/169 [==============================] - 0s 142us/step - loss: 0.5499 - acc: 0.7041\n",
      "Epoch 42/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.5426 - acc: 0.7219\n",
      "Epoch 43/100\n",
      "169/169 [==============================] - 0s 177us/step - loss: 0.5350 - acc: 0.7396\n",
      "Epoch 44/100\n",
      "169/169 [==============================] - 0s 136us/step - loss: 0.5289 - acc: 0.7692\n",
      "Epoch 45/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.5213 - acc: 0.7692\n",
      "Epoch 46/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.5131 - acc: 0.7692\n",
      "Epoch 47/100\n",
      "169/169 [==============================] - 0s 136us/step - loss: 0.5064 - acc: 0.7751\n",
      "Epoch 48/100\n",
      "169/169 [==============================] - 0s 198us/step - loss: 0.4983 - acc: 0.7870\n",
      "Epoch 49/100\n",
      "169/169 [==============================] - 0s 308us/step - loss: 0.4909 - acc: 0.7870\n",
      "Epoch 50/100\n",
      "169/169 [==============================] - 0s 183us/step - loss: 0.4828 - acc: 0.7811\n",
      "Epoch 51/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.4760 - acc: 0.7751\n",
      "Epoch 52/100\n",
      "169/169 [==============================] - 0s 325us/step - loss: 0.4688 - acc: 0.7870\n",
      "Epoch 53/100\n",
      "169/169 [==============================] - 0s 177us/step - loss: 0.4632 - acc: 0.7929\n",
      "Epoch 54/100\n",
      "169/169 [==============================] - 0s 160us/step - loss: 0.4560 - acc: 0.8107\n",
      "Epoch 55/100\n",
      "169/169 [==============================] - 0s 166us/step - loss: 0.4502 - acc: 0.8166\n",
      "Epoch 56/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.4467 - acc: 0.8284\n",
      "Epoch 57/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.4420 - acc: 0.8166\n",
      "Epoch 58/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.4360 - acc: 0.8284\n",
      "Epoch 59/100\n",
      "169/169 [==============================] - 0s 160us/step - loss: 0.4319 - acc: 0.8343\n",
      "Epoch 60/100\n",
      "169/169 [==============================] - 0s 142us/step - loss: 0.4277 - acc: 0.8284\n",
      "Epoch 61/100\n",
      "169/169 [==============================] - 0s 189us/step - loss: 0.4240 - acc: 0.8284\n",
      "Epoch 62/100\n",
      "169/169 [==============================] - 0s 142us/step - loss: 0.4210 - acc: 0.8225\n",
      "Epoch 63/100\n",
      "169/169 [==============================] - 0s 189us/step - loss: 0.4175 - acc: 0.8225\n",
      "Epoch 64/100\n",
      "169/169 [==============================] - 0s 281us/step - loss: 0.4140 - acc: 0.8284\n",
      "Epoch 65/100\n",
      "169/169 [==============================] - 0s 213us/step - loss: 0.4114 - acc: 0.8225\n",
      "Epoch 66/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.4129 - acc: 0.8166\n",
      "Epoch 67/100\n",
      "169/169 [==============================] - 0s 195us/step - loss: 0.4083 - acc: 0.8107\n",
      "Epoch 68/100\n",
      "169/169 [==============================] - 0s 112us/step - loss: 0.4047 - acc: 0.8166\n",
      "Epoch 69/100\n",
      "169/169 [==============================] - 0s 308us/step - loss: 0.4024 - acc: 0.8166\n",
      "Epoch 70/100\n",
      "169/169 [==============================] - 0s 213us/step - loss: 0.4003 - acc: 0.8107\n",
      "Epoch 71/100\n",
      "169/169 [==============================] - 0s 177us/step - loss: 0.3985 - acc: 0.8166\n",
      "Epoch 72/100\n",
      "169/169 [==============================] - 0s 189us/step - loss: 0.3968 - acc: 0.8166\n",
      "Epoch 73/100\n",
      "169/169 [==============================] - 0s 231us/step - loss: 0.3953 - acc: 0.8107\n",
      "Epoch 74/100\n",
      "169/169 [==============================] - 0s 160us/step - loss: 0.3940 - acc: 0.8225\n",
      "Epoch 75/100\n",
      "169/169 [==============================] - 0s 177us/step - loss: 0.3928 - acc: 0.8225\n",
      "Epoch 76/100\n",
      "169/169 [==============================] - 0s 183us/step - loss: 0.3919 - acc: 0.8166\n",
      "Epoch 77/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.3916 - acc: 0.8107\n",
      "Epoch 78/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.3896 - acc: 0.8107\n",
      "Epoch 79/100\n",
      "169/169 [==============================] - 0s 183us/step - loss: 0.3900 - acc: 0.8225\n",
      "Epoch 80/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.3885 - acc: 0.8166\n",
      "Epoch 81/100\n",
      "169/169 [==============================] - 0s 195us/step - loss: 0.3873 - acc: 0.8107\n",
      "Epoch 82/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.3869 - acc: 0.8107\n",
      "Epoch 83/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.3851 - acc: 0.8166\n",
      "Epoch 84/100\n",
      "169/169 [==============================] - 0s 154us/step - loss: 0.3897 - acc: 0.8166\n",
      "Epoch 85/100\n",
      "169/169 [==============================] - 0s 157us/step - loss: 0.3868 - acc: 0.8107\n",
      "Epoch 86/100\n",
      "169/169 [==============================] - 0s 260us/step - loss: 0.3860 - acc: 0.8166\n",
      "Epoch 87/100\n",
      "169/169 [==============================] - 0s 148us/step - loss: 0.3843 - acc: 0.8166\n",
      "Epoch 88/100\n",
      "169/169 [==============================] - 0s 172us/step - loss: 0.3828 - acc: 0.8166\n",
      "Epoch 89/100\n",
      "169/169 [==============================] - 0s 201us/step - loss: 0.3862 - acc: 0.8284\n",
      "Epoch 90/100\n",
      "169/169 [==============================] - 0s 136us/step - loss: 0.3839 - acc: 0.8402\n",
      "Epoch 91/100\n",
      "169/169 [==============================] - 0s 225us/step - loss: 0.3823 - acc: 0.8284\n",
      "Epoch 92/100\n",
      "169/169 [==============================] - 0s 166us/step - loss: 0.3827 - acc: 0.8225\n",
      "Epoch 93/100\n",
      "169/169 [==============================] - 0s 183us/step - loss: 0.3803 - acc: 0.8284\n",
      "Epoch 94/100\n",
      "169/169 [==============================] - 0s 124us/step - loss: 0.3824 - acc: 0.8284\n",
      "Epoch 95/100\n",
      "169/169 [==============================] - 0s 136us/step - loss: 0.3808 - acc: 0.8343\n",
      "Epoch 96/100\n",
      "169/169 [==============================] - 0s 112us/step - loss: 0.3799 - acc: 0.8284\n",
      "Epoch 97/100\n",
      "169/169 [==============================] - 0s 183us/step - loss: 0.3797 - acc: 0.8284\n",
      "Epoch 98/100\n",
      "169/169 [==============================] - 0s 189us/step - loss: 0.3804 - acc: 0.8284\n",
      "Epoch 99/100\n",
      "169/169 [==============================] - 0s 112us/step - loss: 0.3788 - acc: 0.8284\n",
      "Epoch 100/100\n",
      "169/169 [==============================] - 0s 130us/step - loss: 0.3810 - acc: 0.8284\n",
      "85/85 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "170/170 [==============================] - 2s 11ms/step - loss: 0.6926 - acc: 0.6000\n",
      "Epoch 2/100\n",
      "170/170 [==============================] - 0s 165us/step - loss: 0.6910 - acc: 0.6824\n",
      "Epoch 3/100\n",
      "170/170 [==============================] - 0s 112us/step - loss: 0.6891 - acc: 0.6824\n",
      "Epoch 4/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.6862 - acc: 0.6824\n",
      "Epoch 5/100\n",
      "170/170 [==============================] - 0s 106us/step - loss: 0.6828 - acc: 0.6824\n",
      "Epoch 6/100\n",
      "170/170 [==============================] - 0s 118us/step - loss: 0.6786 - acc: 0.6824\n",
      "Epoch 7/100\n",
      "170/170 [==============================] - 0s 106us/step - loss: 0.6731 - acc: 0.6824\n",
      "Epoch 8/100\n",
      "170/170 [==============================] - 0s 153us/step - loss: 0.6657 - acc: 0.6824\n",
      "Epoch 9/100\n",
      "170/170 [==============================] - 0s 118us/step - loss: 0.6581 - acc: 0.6824\n",
      "Epoch 10/100\n",
      "170/170 [==============================] - 0s 129us/step - loss: 0.6485 - acc: 0.6824\n",
      "Epoch 11/100\n",
      "170/170 [==============================] - 0s 129us/step - loss: 0.6403 - acc: 0.6824\n",
      "Epoch 12/100\n",
      "170/170 [==============================] - 0s 212us/step - loss: 0.6321 - acc: 0.6824\n",
      "Epoch 13/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.6267 - acc: 0.6824\n",
      "Epoch 14/100\n",
      "170/170 [==============================] - 0s 129us/step - loss: 0.6223 - acc: 0.6824\n",
      "Epoch 15/100\n",
      "170/170 [==============================] - 0s 159us/step - loss: 0.6185 - acc: 0.6824\n",
      "Epoch 16/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.6162 - acc: 0.6824\n",
      "Epoch 17/100\n",
      "170/170 [==============================] - 0s 153us/step - loss: 0.6151 - acc: 0.6824\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 129us/step - loss: 0.6138 - acc: 0.6824\n",
      "Epoch 19/100\n",
      "170/170 [==============================] - 0s 112us/step - loss: 0.6125 - acc: 0.6824\n",
      "Epoch 20/100\n",
      "170/170 [==============================] - 0s 153us/step - loss: 0.6118 - acc: 0.6824\n",
      "Epoch 21/100\n",
      "170/170 [==============================] - 0s 165us/step - loss: 0.6101 - acc: 0.6824\n",
      "Epoch 22/100\n",
      "170/170 [==============================] - 0s 259us/step - loss: 0.6085 - acc: 0.6824\n",
      "Epoch 23/100\n",
      "170/170 [==============================] - 0s 159us/step - loss: 0.6069 - acc: 0.6824\n",
      "Epoch 24/100\n",
      "170/170 [==============================] - 0s 194us/step - loss: 0.6051 - acc: 0.6824\n",
      "Epoch 25/100\n",
      "170/170 [==============================] - 0s 188us/step - loss: 0.6028 - acc: 0.6824\n",
      "Epoch 26/100\n",
      "170/170 [==============================] - 0s 294us/step - loss: 0.6009 - acc: 0.6824\n",
      "Epoch 27/100\n",
      "170/170 [==============================] - 0s 262us/step - loss: 0.5987 - acc: 0.6824\n",
      "Epoch 28/100\n",
      "170/170 [==============================] - 0s 141us/step - loss: 0.5957 - acc: 0.6824\n",
      "Epoch 29/100\n",
      "170/170 [==============================] - 0s 171us/step - loss: 0.5925 - acc: 0.6824\n",
      "Epoch 30/100\n",
      "170/170 [==============================] - 0s 229us/step - loss: 0.5898 - acc: 0.6824\n",
      "Epoch 31/100\n",
      "170/170 [==============================] - 0s 141us/step - loss: 0.5858 - acc: 0.6824\n",
      "Epoch 32/100\n",
      "170/170 [==============================] - 0s 141us/step - loss: 0.5816 - acc: 0.6824\n",
      "Epoch 33/100\n",
      "170/170 [==============================] - 0s 171us/step - loss: 0.5771 - acc: 0.6824\n",
      "Epoch 34/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.5720 - acc: 0.6824\n",
      "Epoch 35/100\n",
      "170/170 [==============================] - 0s 182us/step - loss: 0.5664 - acc: 0.6824\n",
      "Epoch 36/100\n",
      "170/170 [==============================] - 0s 147us/step - loss: 0.5598 - acc: 0.6824\n",
      "Epoch 37/100\n",
      "170/170 [==============================] - 0s 129us/step - loss: 0.5526 - acc: 0.6882\n",
      "Epoch 38/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.5453 - acc: 0.7000\n",
      "Epoch 39/100\n",
      "170/170 [==============================] - 0s 118us/step - loss: 0.5356 - acc: 0.7118\n",
      "Epoch 40/100\n",
      "170/170 [==============================] - 0s 306us/step - loss: 0.5264 - acc: 0.7176\n",
      "Epoch 41/100\n",
      "170/170 [==============================] - 0s 165us/step - loss: 0.5170 - acc: 0.7353\n",
      "Epoch 42/100\n",
      "170/170 [==============================] - 0s 170us/step - loss: 0.5068 - acc: 0.7529\n",
      "Epoch 43/100\n",
      "170/170 [==============================] - 0s 129us/step - loss: 0.4968 - acc: 0.7647\n",
      "Epoch 44/100\n",
      "170/170 [==============================] - 0s 123us/step - loss: 0.4868 - acc: 0.7824\n",
      "Epoch 45/100\n",
      "170/170 [==============================] - 0s 147us/step - loss: 0.4771 - acc: 0.8059\n",
      "Epoch 46/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.4668 - acc: 0.8059\n",
      "Epoch 47/100\n",
      "170/170 [==============================] - 0s 153us/step - loss: 0.4581 - acc: 0.8118\n",
      "Epoch 48/100\n",
      "170/170 [==============================] - 0s 194us/step - loss: 0.4488 - acc: 0.8118\n",
      "Epoch 49/100\n",
      "170/170 [==============================] - 0s 118us/step - loss: 0.4384 - acc: 0.8118\n",
      "Epoch 50/100\n",
      "170/170 [==============================] - 0s 259us/step - loss: 0.4300 - acc: 0.8118\n",
      "Epoch 51/100\n",
      "170/170 [==============================] - 0s 141us/step - loss: 0.4218 - acc: 0.8235\n",
      "Epoch 52/100\n",
      "170/170 [==============================] - 0s 148us/step - loss: 0.4139 - acc: 0.8471\n",
      "Epoch 53/100\n",
      "170/170 [==============================] - 0s 194us/step - loss: 0.4072 - acc: 0.8529\n",
      "Epoch 54/100\n",
      "170/170 [==============================] - 0s 253us/step - loss: 0.3998 - acc: 0.8529\n",
      "Epoch 55/100\n",
      "170/170 [==============================] - 0s 130us/step - loss: 0.3940 - acc: 0.8529\n",
      "Epoch 56/100\n",
      "170/170 [==============================] - 0s 171us/step - loss: 0.3883 - acc: 0.8588\n",
      "Epoch 57/100\n",
      "170/170 [==============================] - 0s 118us/step - loss: 0.3836 - acc: 0.8588\n",
      "Epoch 58/100\n",
      "170/170 [==============================] - 0s 153us/step - loss: 0.3780 - acc: 0.8529\n",
      "Epoch 59/100\n",
      "170/170 [==============================] - 0s 165us/step - loss: 0.3732 - acc: 0.8588\n",
      "Epoch 60/100\n",
      "170/170 [==============================] - 0s 153us/step - loss: 0.3686 - acc: 0.8588\n",
      "Epoch 61/100\n",
      "170/170 [==============================] - 0s 123us/step - loss: 0.3648 - acc: 0.8588\n",
      "Epoch 62/100\n",
      "170/170 [==============================] - 0s 283us/step - loss: 0.3615 - acc: 0.8588\n",
      "Epoch 63/100\n",
      "170/170 [==============================] - 0s 194us/step - loss: 0.3597 - acc: 0.8588\n",
      "Epoch 64/100\n",
      "170/170 [==============================] - 0s 153us/step - loss: 0.3549 - acc: 0.8588\n",
      "Epoch 65/100\n",
      "170/170 [==============================] - 0s 170us/step - loss: 0.3521 - acc: 0.8647\n",
      "Epoch 66/100\n",
      "170/170 [==============================] - 0s 194us/step - loss: 0.3494 - acc: 0.8647\n",
      "Epoch 67/100\n",
      "170/170 [==============================] - 0s 194us/step - loss: 0.3474 - acc: 0.8588\n",
      "Epoch 68/100\n",
      "170/170 [==============================] - 0s 165us/step - loss: 0.3448 - acc: 0.8706\n",
      "Epoch 69/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.3435 - acc: 0.8765\n",
      "Epoch 70/100\n",
      "170/170 [==============================] - 0s 129us/step - loss: 0.3412 - acc: 0.8765\n",
      "Epoch 71/100\n",
      "170/170 [==============================] - 0s 159us/step - loss: 0.3393 - acc: 0.8706\n",
      "Epoch 72/100\n",
      "170/170 [==============================] - 0s 129us/step - loss: 0.3378 - acc: 0.8765\n",
      "Epoch 73/100\n",
      "170/170 [==============================] - 0s 147us/step - loss: 0.3363 - acc: 0.8824\n",
      "Epoch 74/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.3346 - acc: 0.8824\n",
      "Epoch 75/100\n",
      "170/170 [==============================] - 0s 171us/step - loss: 0.3336 - acc: 0.8824\n",
      "Epoch 76/100\n",
      "170/170 [==============================] - 0s 166us/step - loss: 0.3324 - acc: 0.8765\n",
      "Epoch 77/100\n",
      "170/170 [==============================] - 0s 262us/step - loss: 0.3310 - acc: 0.8824\n",
      "Epoch 78/100\n",
      "170/170 [==============================] - 0s 170us/step - loss: 0.3300 - acc: 0.8765\n",
      "Epoch 79/100\n",
      "170/170 [==============================] - 0s 206us/step - loss: 0.3286 - acc: 0.8824\n",
      "Epoch 80/100\n",
      "170/170 [==============================] - 0s 129us/step - loss: 0.3275 - acc: 0.8824\n",
      "Epoch 81/100\n",
      "170/170 [==============================] - 0s 200us/step - loss: 0.3285 - acc: 0.8765\n",
      "Epoch 82/100\n",
      "170/170 [==============================] - 0s 400us/step - loss: 0.3268 - acc: 0.8765\n",
      "Epoch 83/100\n",
      "170/170 [==============================] - 0s 123us/step - loss: 0.3282 - acc: 0.8765\n",
      "Epoch 84/100\n",
      "170/170 [==============================] - 0s 123us/step - loss: 0.3241 - acc: 0.8824\n",
      "Epoch 85/100\n",
      "170/170 [==============================] - 0s 312us/step - loss: 0.3250 - acc: 0.8824\n",
      "Epoch 86/100\n",
      "170/170 [==============================] - 0s 112us/step - loss: 0.3248 - acc: 0.8824\n",
      "Epoch 87/100\n",
      "170/170 [==============================] - 0s 170us/step - loss: 0.3234 - acc: 0.8765\n",
      "Epoch 88/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.3217 - acc: 0.8882\n",
      "Epoch 89/100\n",
      "170/170 [==============================] - 0s 159us/step - loss: 0.3222 - acc: 0.8882\n",
      "Epoch 90/100\n",
      "170/170 [==============================] - 0s 182us/step - loss: 0.3221 - acc: 0.8882\n",
      "Epoch 91/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.3203 - acc: 0.8882\n",
      "Epoch 92/100\n",
      "170/170 [==============================] - 0s 170us/step - loss: 0.3199 - acc: 0.8765\n",
      "Epoch 93/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.3197 - acc: 0.8824\n",
      "Epoch 94/100\n",
      "170/170 [==============================] - 0s 147us/step - loss: 0.3196 - acc: 0.8765\n",
      "Epoch 95/100\n",
      "170/170 [==============================] - 0s 165us/step - loss: 0.3192 - acc: 0.8824\n",
      "Epoch 96/100\n",
      "170/170 [==============================] - 0s 135us/step - loss: 0.3186 - acc: 0.8765\n",
      "Epoch 97/100\n",
      "170/170 [==============================] - 0s 153us/step - loss: 0.3181 - acc: 0.8824\n",
      "Epoch 98/100\n",
      "170/170 [==============================] - 0s 112us/step - loss: 0.3186 - acc: 0.8882\n",
      "Epoch 99/100\n",
      "170/170 [==============================] - 0s 159us/step - loss: 0.3170 - acc: 0.8882\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 159us/step - loss: 0.3171 - acc: 0.8882\n",
      "84/84 [==============================] - 1s 7ms/step\n",
      "Mean of CV Scores is  0.8463118582880464\n",
      "Std of CV Scores is 0.03540313124945446\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=16,kernel_initializer=\"uniform\",activation=\"tanh\",input_dim=x_train.shape[1]))\n",
    "    classifier.add(Dense(units=8,kernel_initializer=\"uniform\",activation=\"tanh\"))\n",
    "    classifier.add(Dense(units=1,kernel_initializer=\"uniform\",activation=\"sigmoid\"))\n",
    "    classifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier,epochs=100)\n",
    "accuracies = cross_val_score(estimator=classifier,X = x_train , y = y_train , cv=3)\n",
    "\n",
    "print(\"Mean of CV Scores is \",accuracies.mean())\n",
    "print(\"Std of CV Scores is\",accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.35603,
     "end_time": "2020-10-01T18:05:08.846661",
     "exception": false,
     "start_time": "2020-10-01T18:05:08.490631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Hasil skor rata-rata CV: %84\n",
    "* Hasil skor Std CV: 0.035\n",
    "\n",
    "Dan sekarang akan dikomputasi skor akurasi nya. Untuk melakukannya, akan dimasukkan data pada model\n",
    "And now I am going to compute accuracy score. In order to do this I am going to start with fit my data to my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:05:09.577520Z",
     "iopub.status.busy": "2020-10-01T18:05:09.576680Z",
     "iopub.status.idle": "2020-10-01T18:05:11.884229Z",
     "shell.execute_reply": "2020-10-01T18:05:11.883543Z"
    },
    "papermill": {
     "duration": 2.672909,
     "end_time": "2020-10-01T18:05:11.884414",
     "exception": false,
     "start_time": "2020-10-01T18:05:09.211505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.6923 - acc: 0.6575\n",
      "Epoch 2/100\n",
      "254/254 [==============================] - 0s 106us/step - loss: 0.6898 - acc: 0.7008\n",
      "Epoch 3/100\n",
      "254/254 [==============================] - 0s 114us/step - loss: 0.6856 - acc: 0.7008\n",
      "Epoch 4/100\n",
      "254/254 [==============================] - 0s 122us/step - loss: 0.6800 - acc: 0.7008\n",
      "Epoch 5/100\n",
      "254/254 [==============================] - 0s 134us/step - loss: 0.6717 - acc: 0.7008\n",
      "Epoch 6/100\n",
      "254/254 [==============================] - 0s 126us/step - loss: 0.6598 - acc: 0.7008\n",
      "Epoch 7/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.6475 - acc: 0.7008\n",
      "Epoch 8/100\n",
      "254/254 [==============================] - 0s 106us/step - loss: 0.6326 - acc: 0.7008\n",
      "Epoch 9/100\n",
      "254/254 [==============================] - 0s 138us/step - loss: 0.6193 - acc: 0.7008\n",
      "Epoch 10/100\n",
      "254/254 [==============================] - 0s 114us/step - loss: 0.6137 - acc: 0.7008\n",
      "Epoch 11/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.6062 - acc: 0.7008\n",
      "Epoch 12/100\n",
      "254/254 [==============================] - 0s 142us/step - loss: 0.6038 - acc: 0.7008\n",
      "Epoch 13/100\n",
      "254/254 [==============================] - 0s 106us/step - loss: 0.6016 - acc: 0.7008\n",
      "Epoch 14/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.5999 - acc: 0.7008\n",
      "Epoch 15/100\n",
      "254/254 [==============================] - 0s 185us/step - loss: 0.5983 - acc: 0.7008\n",
      "Epoch 16/100\n",
      "254/254 [==============================] - 0s 118us/step - loss: 0.5966 - acc: 0.7008\n",
      "Epoch 17/100\n",
      "254/254 [==============================] - 0s 240us/step - loss: 0.5946 - acc: 0.7008\n",
      "Epoch 18/100\n",
      "254/254 [==============================] - 0s 146us/step - loss: 0.5924 - acc: 0.7008\n",
      "Epoch 19/100\n",
      "254/254 [==============================] - 0s 138us/step - loss: 0.5899 - acc: 0.7008\n",
      "Epoch 20/100\n",
      "254/254 [==============================] - 0s 146us/step - loss: 0.5868 - acc: 0.7008\n",
      "Epoch 21/100\n",
      "254/254 [==============================] - 0s 142us/step - loss: 0.5831 - acc: 0.7008\n",
      "Epoch 22/100\n",
      "254/254 [==============================] - 0s 209us/step - loss: 0.5792 - acc: 0.7008\n",
      "Epoch 23/100\n",
      "254/254 [==============================] - 0s 209us/step - loss: 0.5742 - acc: 0.7008\n",
      "Epoch 24/100\n",
      "254/254 [==============================] - 0s 366us/step - loss: 0.5687 - acc: 0.7008\n",
      "Epoch 25/100\n",
      "254/254 [==============================] - 0s 118us/step - loss: 0.5619 - acc: 0.7008\n",
      "Epoch 26/100\n",
      "254/254 [==============================] - 0s 205us/step - loss: 0.5543 - acc: 0.7008\n",
      "Epoch 27/100\n",
      "254/254 [==============================] - 0s 177us/step - loss: 0.5454 - acc: 0.7047\n",
      "Epoch 28/100\n",
      "254/254 [==============================] - 0s 114us/step - loss: 0.5347 - acc: 0.7165\n",
      "Epoch 29/100\n",
      "254/254 [==============================] - 0s 114us/step - loss: 0.5241 - acc: 0.7244\n",
      "Epoch 30/100\n",
      "254/254 [==============================] - 0s 118us/step - loss: 0.5121 - acc: 0.7362\n",
      "Epoch 31/100\n",
      "254/254 [==============================] - 0s 118us/step - loss: 0.4987 - acc: 0.7520\n",
      "Epoch 32/100\n",
      "254/254 [==============================] - 0s 165us/step - loss: 0.4852 - acc: 0.7677\n",
      "Epoch 33/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.4721 - acc: 0.7874\n",
      "Epoch 34/100\n",
      "254/254 [==============================] - 0s 144us/step - loss: 0.4590 - acc: 0.7992\n",
      "Epoch 35/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.4477 - acc: 0.8071\n",
      "Epoch 36/100\n",
      "254/254 [==============================] - 0s 118us/step - loss: 0.4344 - acc: 0.8228\n",
      "Epoch 37/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.4250 - acc: 0.8189\n",
      "Epoch 38/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.4141 - acc: 0.8228\n",
      "Epoch 39/100\n",
      "254/254 [==============================] - 0s 138us/step - loss: 0.4092 - acc: 0.8268\n",
      "Epoch 40/100\n",
      "254/254 [==============================] - 0s 150us/step - loss: 0.3987 - acc: 0.8268\n",
      "Epoch 41/100\n",
      "254/254 [==============================] - 0s 165us/step - loss: 0.3914 - acc: 0.8268\n",
      "Epoch 42/100\n",
      "254/254 [==============================] - 0s 185us/step - loss: 0.3868 - acc: 0.8386\n",
      "Epoch 43/100\n",
      "254/254 [==============================] - 0s 118us/step - loss: 0.3803 - acc: 0.8307\n",
      "Epoch 44/100\n",
      "254/254 [==============================] - 0s 106us/step - loss: 0.3754 - acc: 0.8425\n",
      "Epoch 45/100\n",
      "254/254 [==============================] - 0s 157us/step - loss: 0.3714 - acc: 0.8386\n",
      "Epoch 46/100\n",
      "254/254 [==============================] - 0s 189us/step - loss: 0.3676 - acc: 0.8386\n",
      "Epoch 47/100\n",
      "254/254 [==============================] - 0s 106us/step - loss: 0.3650 - acc: 0.8386\n",
      "Epoch 48/100\n",
      "254/254 [==============================] - 0s 138us/step - loss: 0.3625 - acc: 0.8465\n",
      "Epoch 49/100\n",
      "254/254 [==============================] - 0s 134us/step - loss: 0.3599 - acc: 0.8465\n",
      "Epoch 50/100\n",
      "254/254 [==============================] - 0s 106us/step - loss: 0.3571 - acc: 0.8504\n",
      "Epoch 51/100\n",
      "254/254 [==============================] - 0s 122us/step - loss: 0.3561 - acc: 0.8504\n",
      "Epoch 52/100\n",
      "254/254 [==============================] - 0s 209us/step - loss: 0.3544 - acc: 0.8465\n",
      "Epoch 53/100\n",
      "254/254 [==============================] - 0s 275us/step - loss: 0.3531 - acc: 0.8425\n",
      "Epoch 54/100\n",
      "254/254 [==============================] - 0s 114us/step - loss: 0.3507 - acc: 0.8465\n",
      "Epoch 55/100\n",
      "254/254 [==============================] - 0s 118us/step - loss: 0.3503 - acc: 0.8504\n",
      "Epoch 56/100\n",
      "254/254 [==============================] - 0s 110us/step - loss: 0.3489 - acc: 0.8504\n",
      "Epoch 57/100\n",
      "254/254 [==============================] - 0s 126us/step - loss: 0.3475 - acc: 0.8504\n",
      "Epoch 58/100\n",
      "254/254 [==============================] - 0s 122us/step - loss: 0.3467 - acc: 0.8543\n",
      "Epoch 59/100\n",
      "254/254 [==============================] - 0s 126us/step - loss: 0.3463 - acc: 0.8543\n",
      "Epoch 60/100\n",
      "254/254 [==============================] - 0s 94us/step - loss: 0.3457 - acc: 0.8583\n",
      "Epoch 61/100\n",
      "254/254 [==============================] - 0s 114us/step - loss: 0.3454 - acc: 0.8504\n",
      "Epoch 62/100\n",
      "254/254 [==============================] - 0s 106us/step - loss: 0.3435 - acc: 0.8583\n",
      "Epoch 63/100\n",
      "254/254 [==============================] - 0s 138us/step - loss: 0.3436 - acc: 0.8543\n",
      "Epoch 64/100\n",
      "254/254 [==============================] - 0s 134us/step - loss: 0.3434 - acc: 0.8504\n",
      "Epoch 65/100\n",
      "254/254 [==============================] - 0s 157us/step - loss: 0.3426 - acc: 0.8583\n",
      "Epoch 66/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.3429 - acc: 0.8543\n",
      "Epoch 67/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.3425 - acc: 0.8622\n",
      "Epoch 68/100\n",
      "254/254 [==============================] - 0s 122us/step - loss: 0.3416 - acc: 0.8661\n",
      "Epoch 69/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.3412 - acc: 0.8622\n",
      "Epoch 70/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.3413 - acc: 0.8583\n",
      "Epoch 71/100\n",
      "254/254 [==============================] - 0s 181us/step - loss: 0.3411 - acc: 0.8583\n",
      "Epoch 72/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.3405 - acc: 0.8661\n",
      "Epoch 73/100\n",
      "254/254 [==============================] - 0s 118us/step - loss: 0.3399 - acc: 0.8622\n",
      "Epoch 74/100\n",
      "254/254 [==============================] - 0s 130us/step - loss: 0.3408 - acc: 0.8661\n",
      "Epoch 75/100\n",
      "254/254 [==============================] - 0s 106us/step - loss: 0.3398 - acc: 0.8543\n",
      "Epoch 76/100\n",
      "254/254 [==============================] - 0s 98us/step - loss: 0.3409 - acc: 0.8583\n",
      "Epoch 77/100\n",
      "254/254 [==============================] - 0s 87us/step - loss: 0.3397 - acc: 0.8701\n",
      "Epoch 78/100\n",
      "254/254 [==============================] - 0s 98us/step - loss: 0.3397 - acc: 0.8661\n",
      "Epoch 79/100\n",
      "254/254 [==============================] - 0s 110us/step - loss: 0.3397 - acc: 0.8543\n",
      "Epoch 80/100\n",
      "254/254 [==============================] - 0s 102us/step - loss: 0.3391 - acc: 0.8543\n",
      "Epoch 81/100\n",
      "254/254 [==============================] - 0s 114us/step - loss: 0.3387 - acc: 0.8622\n",
      "Epoch 82/100\n",
      "254/254 [==============================] - 0s 110us/step - loss: 0.3400 - acc: 0.8740\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 106us/step - loss: 0.3386 - acc: 0.8661\n",
      "Epoch 84/100\n",
      "254/254 [==============================] - 0s 122us/step - loss: 0.3396 - acc: 0.8504\n",
      "Epoch 85/100\n",
      "254/254 [==============================] - 0s 136us/step - loss: 0.3389 - acc: 0.8583\n",
      "Epoch 86/100\n",
      "254/254 [==============================] - 0s 173us/step - loss: 0.3385 - acc: 0.8780\n",
      "Epoch 87/100\n",
      "254/254 [==============================] - 0s 134us/step - loss: 0.3386 - acc: 0.8701\n",
      "Epoch 88/100\n",
      "254/254 [==============================] - 0s 150us/step - loss: 0.3385 - acc: 0.8701\n",
      "Epoch 89/100\n",
      "254/254 [==============================] - 0s 118us/step - loss: 0.3379 - acc: 0.8661\n",
      "Epoch 90/100\n",
      "254/254 [==============================] - 0s 173us/step - loss: 0.3383 - acc: 0.8661\n",
      "Epoch 91/100\n",
      "254/254 [==============================] - 0s 114us/step - loss: 0.3388 - acc: 0.8740\n",
      "Epoch 92/100\n",
      "254/254 [==============================] - 0s 307us/step - loss: 0.3380 - acc: 0.8701\n",
      "Epoch 93/100\n",
      "254/254 [==============================] - 0s 126us/step - loss: 0.3383 - acc: 0.8661\n",
      "Epoch 94/100\n",
      "254/254 [==============================] - 0s 142us/step - loss: 0.3378 - acc: 0.8661\n",
      "Epoch 95/100\n",
      "254/254 [==============================] - 0s 150us/step - loss: 0.3387 - acc: 0.8701\n",
      "Epoch 96/100\n",
      "254/254 [==============================] - 0s 315us/step - loss: 0.3376 - acc: 0.8740\n",
      "Epoch 97/100\n",
      "254/254 [==============================] - 0s 126us/step - loss: 0.3377 - acc: 0.8661\n",
      "Epoch 98/100\n",
      "254/254 [==============================] - 0s 138us/step - loss: 0.3376 - acc: 0.8622\n",
      "Epoch 99/100\n",
      "254/254 [==============================] - 0s 158us/step - loss: 0.3380 - acc: 0.8661\n",
      "Epoch 100/100\n",
      "254/254 [==============================] - 0s 110us/step - loss: 0.3378 - acc: 0.8701\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(x_train,y_train)\n",
    "y_head = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:05:12.812728Z",
     "iopub.status.busy": "2020-10-01T18:05:12.811931Z",
     "iopub.status.idle": "2020-10-01T18:05:12.815638Z",
     "shell.execute_reply": "2020-10-01T18:05:12.815015Z"
    },
    "papermill": {
     "duration": 0.469882,
     "end_time": "2020-10-01T18:05:12.815779",
     "exception": false,
     "start_time": "2020-10-01T18:05:12.345897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # I am in love with scikit learn <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T18:05:13.735823Z",
     "iopub.status.busy": "2020-10-01T18:05:13.734900Z",
     "iopub.status.idle": "2020-10-01T18:05:13.740032Z",
     "shell.execute_reply": "2020-10-01T18:05:13.739381Z"
    },
    "papermill": {
     "duration": 0.466727,
     "end_time": "2020-10-01T18:05:13.740175",
     "exception": false,
     "start_time": "2020-10-01T18:05:13.273448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model:  0.7111111111111111\n"
     ]
    }
   ],
   "source": [
    "print(\"Akurasi model: \",accuracy_score(y_test,y_head))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.506486,
     "end_time": "2020-10-01T18:05:14.700720",
     "exception": false,
     "start_time": "2020-10-01T18:05:14.194234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Result\n",
    "\n",
    "Pada awal kernel ini, dibuat model ANN dari awal dan menghasilkan skor yang cukup rendah yaitu 70%. Tapi pada akhir kernel ini dibuat model ANN menggunakan keras dan hasil skornya adalah 71%\n",
    "\n",
    "Jadi kita dapat membuat model ANN dari awal, tanpa menggunakan library, untuk memahami logika dibelakang ANN. Tapi kita seharusnya menggunakan library Keras untuk membuat model ANN karena lebih mudah dan hasilnya lebih baik dari model yang dibuat dari awal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source : https://www.kaggle.com/mehmetlaudatekman/ann-exercise-with-heart-failure-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "papermill": {
   "duration": 42.338843,
   "end_time": "2020-10-01T18:05:16.195969",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-01T18:04:33.857126",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
